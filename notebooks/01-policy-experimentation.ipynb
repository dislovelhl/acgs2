{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Policy Experimentation with OPA\n",
    "\n",
    "Welcome to interactive policy experimentation with ACGS-2! This notebook guides you through:\n",
    "\n",
    "1. **Connecting to OPA** - Setting up communication with the policy engine\n",
    "2. **Basic Policy Queries** - Evaluating your first policies\n",
    "3. **Role-Based Access Control** - Understanding RBAC patterns\n",
    "4. **Debugging Policies** - Using denial reasons for troubleshooting\n",
    "5. **Batch Evaluation** - Testing multiple scenarios efficiently\n",
    "6. **Visualization** - Graphing policy decisions\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure OPA is running:\n",
    "\n",
    "```bash\n",
    "# From project root\n",
    "docker compose up opa -d\n",
    "\n",
    "# Verify OPA is healthy\n",
    "curl http://localhost:8181/health\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's import the required libraries and configure the environment for Docker compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set headless backend BEFORE importing matplotlib (required for Docker)\n",
    "import os  # noqa: I001\n",
    "\n",
    "os.environ[\"MPLBACKEND\"] = \"Agg\"\n",
    "\n",
    "# Standard library\n",
    "from typing import Any\n",
    "\n",
    "# Data manipulation and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "# Enable inline plots\n",
    "%matplotlib inline\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to OPA\n",
    "\n",
    "The Open Policy Agent (OPA) exposes a REST API on port 8181. We'll create helper functions to interact with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPA URL configuration\n",
    "# - Docker: uses internal network name 'opa'\n",
    "# - Local: uses localhost\n",
    "OPA_URL = os.getenv(\"OPA_URL\", \"http://localhost:8181\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_opa_health() -> bool:\n",
    "    \"\"\"Check if OPA is running and healthy.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{OPA_URL}/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except RequestException:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Verify OPA connection\n",
    "opa_healthy = check_opa_health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(policy_path: str, input_data: dict[str, Any]) -> dict[str, Any]:\n",
    "    \"\"\"Evaluate an OPA policy with the given input data.\n",
    "\n",
    "    Args:\n",
    "        policy_path: Path to the policy rule (e.g., 'hello/allow')\n",
    "        input_data: Dictionary of input values for the policy\n",
    "\n",
    "    Returns:\n",
    "        The policy evaluation result\n",
    "\n",
    "    Raises:\n",
    "        RequestException: If OPA is unreachable or returns an error\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        f\"{OPA_URL}/v1/data/{policy_path}\",\n",
    "        json={\"input\": input_data},\n",
    "        timeout=10,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def safe_evaluate(policy_path: str, input_data: dict[str, Any]) -> dict[str, Any] | None:\n",
    "    \"\"\"Evaluate a policy with error handling.\n",
    "\n",
    "    Returns None if evaluation fails (instead of raising an exception).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return evaluate_policy(policy_path, input_data)\n",
    "    except RequestException:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Policy Queries\n",
    "\n",
    "Let's start with the \"hello world\" policy from Example 01. This policy implements simple role-based access control:\n",
    "\n",
    "- **Admins**: Can perform any action\n",
    "- **Developers**: Can only read resources\n",
    "- **Others**: Denied by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1: Admin user trying to delete a resource\n",
    "admin_delete = {\n",
    "    \"user\": {\"role\": \"admin\"},\n",
    "    \"action\": \"delete\",\n",
    "    \"resource\": \"policy\",\n",
    "}\n",
    "\n",
    "result = safe_evaluate(\"hello/allow\", admin_delete)\n",
    "if result:\n",
    "    allowed = result.get(\"result\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2: Developer user trying to read a resource\n",
    "developer_read = {\n",
    "    \"user\": {\"role\": \"developer\"},\n",
    "    \"action\": \"read\",\n",
    "    \"resource\": \"policy\",\n",
    "}\n",
    "\n",
    "result = safe_evaluate(\"hello/allow\", developer_read)\n",
    "if result:\n",
    "    allowed = result.get(\"result\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3: Developer user trying to delete a resource (should be denied!)\n",
    "developer_delete = {\n",
    "    \"user\": {\"role\": \"developer\"},\n",
    "    \"action\": \"delete\",\n",
    "    \"resource\": \"policy\",\n",
    "}\n",
    "\n",
    "result = safe_evaluate(\"hello/allow\", developer_delete)\n",
    "if result:\n",
    "    allowed = result.get(\"result\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Debugging with Denial Reasons\n",
    "\n",
    "When a request is denied, it's helpful to know **why**. The hello policy includes `denial_reasons` that explain the cause of denial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_decision(input_data: dict[str, Any]) -> None:\n",
    "    \"\"\"Evaluate a policy and explain the decision.\"\"\"\n",
    "    # Get both the allow decision and denial reasons\n",
    "    allow_result = safe_evaluate(\"hello/allow\", input_data)\n",
    "    reasons_result = safe_evaluate(\"hello/denial_reasons\", input_data)\n",
    "\n",
    "    if allow_result is None or reasons_result is None:\n",
    "        return\n",
    "\n",
    "    allowed = allow_result.get(\"result\", False)\n",
    "    reasons = reasons_result.get(\"result\", [])\n",
    "\n",
    "    # Pretty print the input\n",
    "    for _key, _value in input_data.items():\n",
    "        pass\n",
    "\n",
    "    # Print the decision\n",
    "    if allowed:\n",
    "        pass\n",
    "    else:\n",
    "        if reasons:\n",
    "            for _reason in reasons:\n",
    "                pass\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 1: Unknown role\n",
    "explain_decision(\n",
    "    {\n",
    "        \"user\": {\"role\": \"guest\"},\n",
    "        \"action\": \"read\",\n",
    "        \"resource\": \"data\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 2: Missing role\n",
    "explain_decision(\n",
    "    {\n",
    "        \"user\": {},\n",
    "        \"action\": \"read\",\n",
    "        \"resource\": \"data\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 3: Developer attempting forbidden action\n",
    "explain_decision(\n",
    "    {\n",
    "        \"user\": {\"role\": \"developer\"},\n",
    "        \"action\": \"write\",\n",
    "        \"resource\": \"config\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Evaluation\n",
    "\n",
    "Let's test multiple scenarios at once to understand the policy behavior across different combinations of roles and actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test scenarios\n",
    "scenarios = [\n",
    "    {\"user\": {\"role\": \"admin\"}, \"action\": \"read\", \"resource\": \"policy\"},\n",
    "    {\"user\": {\"role\": \"admin\"}, \"action\": \"write\", \"resource\": \"policy\"},\n",
    "    {\"user\": {\"role\": \"admin\"}, \"action\": \"delete\", \"resource\": \"policy\"},\n",
    "    {\"user\": {\"role\": \"developer\"}, \"action\": \"read\", \"resource\": \"policy\"},\n",
    "    {\"user\": {\"role\": \"developer\"}, \"action\": \"write\", \"resource\": \"policy\"},\n",
    "    {\"user\": {\"role\": \"developer\"}, \"action\": \"delete\", \"resource\": \"policy\"},\n",
    "    {\"user\": {\"role\": \"guest\"}, \"action\": \"read\", \"resource\": \"policy\"},\n",
    "    {\"user\": {\"role\": \"guest\"}, \"action\": \"write\", \"resource\": \"policy\"},\n",
    "    {\"user\": {}, \"action\": \"read\", \"resource\": \"policy\"},\n",
    "]\n",
    "\n",
    "# Evaluate all scenarios\n",
    "results = []\n",
    "for scenario in scenarios:\n",
    "    result = safe_evaluate(\"hello/allow\", scenario)\n",
    "    if result:\n",
    "        results.append(\n",
    "            {\n",
    "                \"role\": scenario.get(\"user\", {}).get(\"role\", \"(none)\"),\n",
    "                \"action\": scenario.get(\"action\", \"(none)\"),\n",
    "                \"allowed\": result.get(\"result\", False),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Create DataFrame for easy viewing\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization\n",
    "\n",
    "Let's visualize the policy decisions to better understand access patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table for the heatmap\n",
    "if len(df) > 0:\n",
    "    pivot_df = (\n",
    "        df.pivot_table(\n",
    "            index=\"role\",\n",
    "            columns=\"action\",\n",
    "            values=\"allowed\",\n",
    "            aggfunc=\"first\",\n",
    "        )\n",
    "        .fillna(False)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "    # Create heatmap\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.heatmap(\n",
    "        pivot_df,\n",
    "        annot=True,\n",
    "        cmap=\"RdYlGn\",\n",
    "        cbar_kws={\"label\": \"Allowed (1) / Denied (0)\"},\n",
    "        fmt=\"d\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(\"RBAC Policy Decisions: Role vs Action\")\n",
    "    ax.set_xlabel(\"Action\")\n",
    "    ax.set_ylabel(\"Role\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Close figure to prevent memory leaks\n",
    "    plt.close(fig)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart showing allow/deny counts by role\n",
    "if len(df) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    role_counts = df.groupby([\"role\", \"allowed\"]).size().unstack(fill_value=0)\n",
    "    role_counts.columns = [\"Denied\", \"Allowed\"]\n",
    "\n",
    "    role_counts.plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        color=[\"#E74C3C\", \"#27AE60\"],\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(\"Policy Decisions by Role\")\n",
    "    ax.set_xlabel(\"Role\")\n",
    "    ax.set_ylabel(\"Number of Decisions\")\n",
    "    ax.legend(title=\"Decision\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Close figure to prevent memory leaks\n",
    "    plt.close(fig)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Experimentation\n",
    "\n",
    "Now it's your turn! Use the cells below to experiment with different policy inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 1: Try different role/action combinations\n",
    "# Modify the values below and run the cell to see the result\n",
    "\n",
    "my_input = {\n",
    "    \"user\": {\"role\": \"developer\"},  # Try: admin, developer, guest, viewer\n",
    "    \"action\": \"read\",  # Try: read, write, delete, update\n",
    "    \"resource\": \"policy\",  # Try: policy, config, data\n",
    "}\n",
    "\n",
    "explain_decision(my_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 2: Create your own test scenarios\n",
    "# Add more scenarios to the list and run batch evaluation\n",
    "\n",
    "custom_scenarios = [\n",
    "    # Add your test cases here\n",
    "    {\"user\": {\"role\": \"admin\"}, \"action\": \"audit\", \"resource\": \"logs\"},\n",
    "    {\"user\": {\"role\": \"viewer\"}, \"action\": \"read\", \"resource\": \"reports\"},\n",
    "    # Add more...\n",
    "]\n",
    "\n",
    "for scenario in custom_scenarios:\n",
    "    explain_decision(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Working with AI Model Approval Policy\n",
    "\n",
    "If you have Example 02 running, you can also experiment with the AI model approval policy. This demonstrates more complex governance scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the AI model approval policy is loaded\n",
    "test_model = {\n",
    "    \"model\": {\n",
    "        \"id\": \"test-model-001\",\n",
    "        \"risk_score\": 0.3,\n",
    "        \"environment\": \"staging\",\n",
    "    },\n",
    "    \"compliance\": {\n",
    "        \"bias_tested\": True,\n",
    "        \"documentation_complete\": True,\n",
    "        \"security_reviewed\": True,\n",
    "    },\n",
    "    \"deployment\": {\n",
    "        \"environment\": \"staging\",\n",
    "    },\n",
    "}\n",
    "\n",
    "result = safe_evaluate(\"ai/model_approval/allow\", test_model)\n",
    "if result:\n",
    "    allowed = result.get(\"result\", False)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare low-risk vs high-risk models\n",
    "\n",
    "# Define compliance status (shared across scenarios)\n",
    "full_compliance = {\n",
    "    \"bias_tested\": True,\n",
    "    \"documentation_complete\": True,\n",
    "    \"security_reviewed\": True,\n",
    "}\n",
    "\n",
    "risk_scenarios = [\n",
    "    {\n",
    "        \"name\": \"Low-risk model (staging)\",\n",
    "        \"input\": {\n",
    "            \"model\": {\n",
    "                \"id\": \"low-risk-001\",\n",
    "                \"risk_score\": 0.2,\n",
    "                \"environment\": \"staging\",\n",
    "            },\n",
    "            \"compliance\": full_compliance,\n",
    "            \"deployment\": {\"environment\": \"staging\"},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Medium-risk model (staging)\",\n",
    "        \"input\": {\n",
    "            \"model\": {\n",
    "                \"id\": \"medium-risk-001\",\n",
    "                \"risk_score\": 0.5,\n",
    "                \"environment\": \"staging\",\n",
    "            },\n",
    "            \"compliance\": full_compliance,\n",
    "            \"deployment\": {\"environment\": \"staging\"},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"High-risk model (production, no reviewer)\",\n",
    "        \"input\": {\n",
    "            \"model\": {\n",
    "                \"id\": \"high-risk-001\",\n",
    "                \"risk_score\": 0.8,\n",
    "                \"environment\": \"production\",\n",
    "            },\n",
    "            \"compliance\": full_compliance,\n",
    "            \"deployment\": {\"environment\": \"production\"},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"High-risk model (production, with reviewer)\",\n",
    "        \"input\": {\n",
    "            \"model\": {\n",
    "                \"id\": \"high-risk-002\",\n",
    "                \"risk_score\": 0.8,\n",
    "                \"environment\": \"production\",\n",
    "            },\n",
    "            \"compliance\": full_compliance,\n",
    "            \"deployment\": {\"environment\": \"production\"},\n",
    "            \"reviewer\": {\"id\": \"reviewer-001\", \"role\": \"senior_engineer\"},\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "for scenario in risk_scenarios:\n",
    "    result = safe_evaluate(\"ai/model_approval/allow\", scenario[\"input\"])\n",
    "    if result:\n",
    "        allowed = result.get(\"result\", False)\n",
    "        status = \"APPROVED\" if allowed else \"DENIED\"\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Statistics\n",
    "\n",
    "Let's generate some summary statistics from our policy evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate extended test scenarios for statistics\n",
    "extended_scenarios = []\n",
    "roles = [\"admin\", \"developer\", \"guest\", \"viewer\", \"operator\"]\n",
    "actions = [\"read\", \"write\", \"delete\", \"update\", \"execute\"]\n",
    "\n",
    "for role in roles:\n",
    "    for action in actions:\n",
    "        extended_scenarios.append(\n",
    "            {\n",
    "                \"user\": {\"role\": role},\n",
    "                \"action\": action,\n",
    "                \"resource\": \"data\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Evaluate all scenarios\n",
    "extended_results = []\n",
    "for scenario in extended_scenarios:\n",
    "    result = safe_evaluate(\"hello/allow\", scenario)\n",
    "    if result:\n",
    "        extended_results.append(\n",
    "            {\n",
    "                \"role\": scenario[\"user\"][\"role\"],\n",
    "                \"action\": scenario[\"action\"],\n",
    "                \"allowed\": result.get(\"result\", False),\n",
    "            }\n",
    "        )\n",
    "\n",
    "if extended_results:\n",
    "    ext_df = pd.DataFrame(extended_results)\n",
    "\n",
    "    allowed_pct = ext_df[\"allowed\"].mean() * 100\n",
    "    denied_pct = (~ext_df[\"allowed\"]).mean() * 100\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize approval rates\n",
    "if extended_results:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Pie chart: Overall allow/deny\n",
    "    allowed_count = ext_df[\"allowed\"].sum()\n",
    "    denied_count = (~ext_df[\"allowed\"]).sum()\n",
    "\n",
    "    axes[0].pie(\n",
    "        [allowed_count, denied_count],\n",
    "        labels=[\"Allowed\", \"Denied\"],\n",
    "        colors=[\"#27AE60\", \"#E74C3C\"],\n",
    "        autopct=\"%1.1f%%\",\n",
    "        startangle=90,\n",
    "    )\n",
    "    axes[0].set_title(\"Overall Policy Decisions\")\n",
    "\n",
    "    # Bar chart: Approval rate by role\n",
    "    approval_rates = ext_df.groupby(\"role\")[\"allowed\"].mean()\n",
    "    approval_rates = approval_rates.sort_values(ascending=True)\n",
    "    colors = [\"#27AE60\" if rate > 0.5 else \"#E74C3C\" for rate in approval_rates]\n",
    "\n",
    "    approval_rates.plot(\n",
    "        kind=\"barh\",\n",
    "        color=colors,\n",
    "        ax=axes[1],\n",
    "    )\n",
    "    axes[1].set_title(\"Approval Rate by Role\")\n",
    "    axes[1].set_xlabel(\"Approval Rate\")\n",
    "    axes[1].set_ylabel(\"Role\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Close figure to prevent memory leaks\n",
    "    plt.close(fig)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup\n",
    "\n",
    "Always clean up resources to prevent memory leaks, especially in Docker environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close all matplotlib figures\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "You've completed the policy experimentation notebook! Here's what to explore next:\n",
    "\n",
    "1. **Notebook 02**: Governance Visualization - More advanced charts and dashboards\n",
    "2. **Example Projects**: Try the examples in `/examples/` directory\n",
    "3. **Custom Policies**: Write your own Rego policies and test them here\n",
    "4. **OPA Documentation**: [openpolicyagent.org/docs](https://www.openpolicyagent.org/docs/)\n",
    "\n",
    "### Feedback\n",
    "\n",
    "Did this notebook help you understand OPA policy evaluation? We'd love your feedback!\n",
    "\n",
    "- [Submit Feedback](../docs/feedback.md)\n",
    "- [Report Issues](https://github.com/your-org/acgs2/issues)\n",
    "\n",
    "---\n",
    "\n",
    "*ACGS-2 Developer Onboarding - Policy Experimentation Notebook*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
