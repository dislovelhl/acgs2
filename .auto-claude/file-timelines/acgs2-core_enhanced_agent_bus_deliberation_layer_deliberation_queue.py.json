{
  "file_path": "src/core/enhanced_agent_bus/deliberation_layer/deliberation_queue.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nACGS-2 Deliberation Layer - Deliberation Queue\nConstitutional Hash: cdd01ef066bc6cf2\nPersistent queue for high-impact messages awaiting approval.\n\"\"\"\n\nimport asyncio\nimport json\nimport logging\nimport uuid\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta, timezone\nfrom typing import Any, Dict, List, Optional\n\ntry:\n    from ..models import AgentMessage, MessageStatus, get_enum_value\nexcept (ImportError, ValueError):\n    # Fallback for direct execution or testing\n    from models import AgentMessage, MessageStatus, get_enum_value  # type: ignore\nfrom enum import Enum\n\n\nclass DeliberationStatus(Enum):\n    PENDING = \"pending\"\n    UNDER_REVIEW = \"under_review\"\n    APPROVED = \"approved\"\n    REJECTED = \"rejected\"\n    TIMED_OUT = \"timed_out\"\n    CONSENSUS_REACHED = \"consensus_reached\"\n\n\nclass VoteType(Enum):\n    APPROVE = \"approve\"\n    REJECT = \"reject\"\n    ABSTAIN = \"abstain\"\n\n\n@dataclass\nclass AgentVote:\n    \"\"\"Represents a vote from an agent on a deliberation item.\"\"\"\n\n    agent_id: str\n    vote: VoteType\n    reasoning: str\n    confidence_score: float = 1.0\n    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n\n\n@dataclass\nclass DeliberationTask:\n    task_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    message: Optional[AgentMessage] = None\n    status: DeliberationStatus = DeliberationStatus.PENDING\n    required_votes: int = 3\n    consensus_threshold: float = 0.66\n    timeout_seconds: int = 300\n    current_votes: List[AgentVote] = field(default_factory=list)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n    updated_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n    human_reviewer: Optional[str] = None\n    human_decision: Optional[DeliberationStatus] = None\n    human_reasoning: Optional[str] = None\n\n    @property\n    def voting_deadline(self) -> datetime:\n        return self.created_at + timedelta(seconds=self.timeout_seconds)\n\n    @property\n    def item_id(self) -> str:\n        return self.task_id\n\n    @property\n    def is_complete(self) -> bool:\n        return self.status in [\n            DeliberationStatus.APPROVED,\n            DeliberationStatus.REJECTED,\n            DeliberationStatus.TIMED_OUT,\n        ]\n\n\n# Aliases for backward compatibility in certain test suites\nDeliberationItem = DeliberationTask\n\nlogger = logging.getLogger(__name__)\n\n# Global registry of all queue instances for cleanup\n_all_queue_instances: list = []\n\n\nclass DeliberationQueue:\n    \"\"\"\n    Queue for managing messages that require human-in-the-loop or\n    multi-agent deliberation.\n\n    PERFORMANCE OPTIMIZATION:\n    - Uses partitioned locks to reduce contention (4 partitions by default)\n    - Partition selection based on task_id hash for consistent routing\n    - Enables parallel processing of tasks in different partitions\n    - Target: >6000 RPS throughput with P99 latency <1ms\n    \"\"\"\n\n    # Number of partitions for reduced lock contention\n    NUM_PARTITIONS = 4\n\n    def __init__(\n        self,\n        persistence_path: Optional[str] = None,\n        consensus_threshold: float = 0.66,\n        default_timeout: int = 300,\n    ):\n        self.queue: Dict[str, DeliberationTask] = {}  # Legacy name compatibility\n        self.tasks = self.queue  # Preferred name\n        self.processing_tasks: List[asyncio.Task] = []\n        self.persistence_path = persistence_path\n        self.consensus_threshold = consensus_threshold\n        self.default_timeout = default_timeout\n        self.stats = {\n            \"total_queued\": 0,\n            \"approved\": 0,\n            \"rejected\": 0,\n            \"timed_out\": 0,\n            \"consensus_reached\": 0,\n            \"avg_processing_time\": 0.0,\n        }\n        # PERFORMANCE: Partitioned locks for reduced contention\n        # Use multiple locks to allow parallel operations on different task partitions\n        self._partition_locks = [asyncio.Lock() for _ in range(self.NUM_PARTITIONS)]\n        self._lock = asyncio.Lock()  # Global lock for stats and persistence only\n        self._shutdown = False  # Shutdown flag for clean task termination\n        self._shutdown_event = asyncio.Event()  # Event for immediate task wakeup on shutdown\n        # Register this instance for global cleanup\n        _all_queue_instances.append(self)\n        if self.persistence_path:\n            self._load_tasks()\n\n    def _get_partition_lock(self, task_id: str) -> asyncio.Lock:\n        \"\"\"Get the partition lock for a given task_id.\n\n        Uses hash-based routing for consistent partition assignment.\n        \"\"\"\n        partition_idx = hash(task_id) % self.NUM_PARTITIONS\n        return self._partition_locks[partition_idx]\n\n    def _load_tasks(self):\n        \"\"\"Load tasks from persistent storage.\"\"\"\n        try:\n            with open(self.persistence_path, \"r\") as f:\n                data = json.load(f)\n                for tid, tdata in data.items():\n                    # Simplified reconstruction\n                    msg = AgentMessage.from_dict(tdata[\"message\"])\n                    task = DeliberationTask(\n                        task_id=tid,\n                        message=msg,\n                        status=DeliberationStatus(\n                            tdata[\"status\"].lower()\n                            if isinstance(tdata[\"status\"], str)\n                            else tdata[\"status\"]\n                        ),\n                        metadata=tdata.get(\"metadata\", {}),\n                        created_at=datetime.fromisoformat(tdata[\"created_at\"]),\n                    )\n                    self.tasks[tid] = task\n        except (FileNotFoundError, json.JSONDecodeError, KeyError, ValueError):\n            pass\n\n    async def enqueue_for_deliberation(\n        self,\n        message: AgentMessage,\n        requires_human_review: bool = False,\n        requires_multi_agent_vote: bool = False,\n        timeout_seconds: Optional[int] = None,\n    ) -> str:\n        \"\"\"Enqueue a message for deliberation.\n\n        PERFORMANCE: Uses partitioned lock to reduce contention.\n        Only the partition containing this task is locked, allowing\n        parallel enqueue operations on other partitions.\n        \"\"\"\n        task_id = str(uuid.uuid4())\n        timeout = timeout_seconds or self.default_timeout\n\n        task = DeliberationTask(\n            task_id=task_id,\n            message=message,\n            timeout_seconds=timeout,\n            required_votes=5 if requires_multi_agent_vote else 0,  # Match test expectation 5\n            consensus_threshold=self.consensus_threshold,\n            metadata={\n                \"requires_human\": requires_human_review,\n                \"requires_vote\": requires_multi_agent_vote,\n            },\n        )\n\n        # Use partition lock for task insertion (allows parallel inserts to other partitions)\n        partition_lock = self._get_partition_lock(task_id)\n        async with partition_lock:\n            self.tasks[task_id] = task\n\n        # Use global lock only for stats update (minimal critical section)\n        async with self._lock:\n            self.stats[\"total_queued\"] += 1\n\n        # Start background processing (e.g. timeout monitor) - non-blocking\n        proc_task = asyncio.create_task(self._monitor_task(task_id))\n        self.processing_tasks.append(proc_task)\n\n        # Persist asynchronously if needed (non-blocking)\n        if self.persistence_path:\n            asyncio.create_task(self._async_save_tasks())\n\n        logger.info(f\"Message {message.message_id} enqueued for deliberation (Task {task_id})\")\n        return task_id\n\n    async def _async_save_tasks(self):\n        \"\"\"Asynchronously save tasks to persistent storage.\"\"\"\n        await asyncio.to_thread(self._save_tasks)\n\n    async def enqueue(self, *args, **kwargs) -> str:\n        \"\"\"Alias for enqueue_for_deliberation.\"\"\"\n        return await self.enqueue_for_deliberation(*args, **kwargs)\n\n    async def _monitor_task(self, task_id: str):\n        \"\"\"Monitor task for timeout with proper shutdown handling.\"\"\"\n        task = self.tasks.get(task_id)\n        if not task:\n            return\n\n        current_task = asyncio.current_task()\n        try:\n            # Use smaller sleep intervals to respond to shutdown quickly\n            elapsed = 0\n            check_interval = min(1.0, task.timeout_seconds / 10)\n            while elapsed < task.timeout_seconds:\n                if self._shutdown:\n                    return  # Exit cleanly on shutdown\n                # Wait for either the check interval or shutdown event\n                try:\n                    await asyncio.wait_for(self._shutdown_event.wait(), timeout=check_interval)\n                    # Shutdown event was set\n                    return\n                except asyncio.TimeoutError:\n                    # Normal timeout, continue monitoring\n                    pass\n                elapsed += check_interval\n                # Check if task was resolved externally\n                if task.is_complete:\n                    return\n\n            # Timeout reached\n            async with self._lock:\n                if task_id in self.tasks and not task.is_complete:\n                    task.status = DeliberationStatus.TIMED_OUT\n                    self.stats[\"timed_out\"] += 1\n                    self._save_tasks()\n                    logger.warning(f\"Task {task_id} timed out\")\n        except asyncio.CancelledError:\n            # Propagate cancellation properly\n            raise\n        finally:\n            # Clean up task reference\n            if current_task and current_task in self.processing_tasks:\n                try:\n                    self.processing_tasks.remove(current_task)\n                except ValueError:\n                    pass  # Already removed\n\n    async def stop(self):\n        \"\"\"Stop all background tasks cleanly.\"\"\"\n        self._shutdown = True  # Signal all monitor tasks to exit\n        self._shutdown_event.set()  # Wake up all waiting tasks immediately\n        tasks_to_cancel = list(self.processing_tasks)  # Copy to avoid modification during iteration\n        for task in tasks_to_cancel:\n            if not task.done():\n                task.cancel()\n        if tasks_to_cancel:\n            # Wait for tasks to complete with timeout to avoid hanging\n            try:\n                await asyncio.wait_for(\n                    asyncio.gather(*tasks_to_cancel, return_exceptions=True), timeout=2.0\n                )\n            except asyncio.TimeoutError:\n                logger.warning(\"Some deliberation tasks did not stop cleanly within timeout\")\n        self.processing_tasks.clear()\n\n    async def __aenter__(self):\n        \"\"\"Async context manager entry.\"\"\"\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Async context manager exit - ensures cleanup.\"\"\"\n        await self.stop()\n        return False\n\n    async def update_status(self, task_id: str, status: Any):\n        \"\"\"Update the status of a deliberation task.\"\"\"\n        async with self._lock:\n            if task_id in self.tasks:\n                if isinstance(status, str):\n                    try:\n                        status = DeliberationStatus(status.lower())\n                    except ValueError:\n                        # Fallback for manual string statuses\n                        pass\n\n                self.tasks[task_id].status = status\n                self._save_tasks()\n                logger.debug(f\"Task {task_id} status updated to {status}\")\n\n    def get_pending_tasks(self) -> List[DeliberationItem]:\n        \"\"\"Get all tasks awaiting deliberation.\"\"\"\n        pending_value = DeliberationStatus.PENDING.value\n        return [t for t in self.tasks.values() if get_enum_value(t.status) == pending_value]\n\n    def get_task(self, task_id: str) -> Optional[DeliberationItem]:\n        \"\"\"Get a task by ID.\"\"\"\n        return self.tasks.get(task_id)\n\n    def get_item_details(self, item_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Get details for an item (test compatibility).\"\"\"\n        task = self.get_task(item_id)\n        if not task:\n            return None\n        return {\n            \"item_id\": task.item_id,\n            \"message_id\": task.message.message_id if task.message else None,\n            \"status\": get_enum_value(task.status),\n            \"created_at\": task.created_at.isoformat(),\n            \"updated_at\": task.updated_at.isoformat(),\n            \"votes\": len(task.current_votes),\n        }\n\n    def get_queue_status(self) -> Dict[str, Any]:\n        \"\"\"Get overall status (test compatibility).\"\"\"\n        return {\n            \"queue_size\": len(self.tasks),\n            \"items\": list(self.tasks.keys()),\n            \"stats\": self.stats,\n            \"processing_count\": len(self.processing_tasks),\n        }\n\n    async def submit_agent_vote(\n        self, item_id: str, agent_id: str, vote: VoteType, reasoning: str, confidence: float = 1.0\n    ) -> bool:\n        \"\"\"Submit an agent's vote.\n\n        PERFORMANCE: Uses partitioned lock for task access,\n        global lock only for stats updates.\n        \"\"\"\n        partition_lock = self._get_partition_lock(item_id)\n        async with partition_lock:\n            task = self.tasks.get(item_id)\n            if not task or task.is_complete:\n                return False\n\n            # Filter out existing votes from same agent\n            task.current_votes = [v for v in task.current_votes if v.agent_id != agent_id]\n\n            new_vote = AgentVote(\n                agent_id=agent_id, vote=vote, reasoning=reasoning, confidence_score=confidence\n            )\n            task.current_votes.append(new_vote)\n\n            # Check for consensus\n            if self._check_consensus(task):\n                task.status = DeliberationStatus.APPROVED  # Or specific consensus state\n                # Update stats with global lock\n                async with self._lock:\n                    self.stats[\"approved\"] += 1\n\n        # Persist asynchronously\n        if self.persistence_path:\n            asyncio.create_task(self._async_save_tasks())\n        return True\n\n    def _check_consensus(self, task: DeliberationTask) -> bool:\n        \"\"\"Internal consensus checking logic.\"\"\"\n        if not task.required_votes or len(task.current_votes) < task.required_votes:\n            return False\n\n        approvals = sum(1 for v in task.current_votes if v.vote == VoteType.APPROVE)\n        if approvals / len(task.current_votes) >= task.consensus_threshold:\n            return True\n        return False\n\n    async def submit_human_decision(\n        self, item_id: str, reviewer: str, decision: DeliberationStatus, reasoning: str\n    ) -> bool:\n        \"\"\"Submit human decision.\n\n        PERFORMANCE: Uses partitioned lock for task access,\n        global lock only for stats updates.\n        \"\"\"\n        partition_lock = self._get_partition_lock(item_id)\n        async with partition_lock:\n            task = self.tasks.get(item_id)\n            if not task or task.is_complete:\n                return False\n\n            # Allow decision only if already under review\n            if get_enum_value(task.status) != DeliberationStatus.UNDER_REVIEW.value:\n                return False\n\n            task.human_reviewer = reviewer\n            task.human_decision = decision\n            task.human_reasoning = reasoning\n            task.status = decision\n\n        # Update stats with global lock (minimal critical section)\n        async with self._lock:\n            if get_enum_value(decision) == DeliberationStatus.APPROVED.value:\n                self.stats[\"approved\"] += 1\n            else:\n                self.stats[\"rejected\"] += 1\n\n        # Persist asynchronously\n        if self.persistence_path:\n            asyncio.create_task(self._async_save_tasks())\n        return True\n\n    def _save_tasks(self):\n        \"\"\"Save current tasks to persistent storage.\"\"\"\n        if not self.persistence_path:\n            return\n        try:\n            storage = {\n                tid: {\n                    \"message\": t.message.to_dict_raw() if t.message else {},\n                    \"status\": get_enum_value(t.status),\n                    \"metadata\": t.metadata,\n                    \"created_at\": t.created_at.isoformat(),\n                }\n                for tid, t in self.tasks.items()\n            }\n            with open(self.persistence_path, \"w\") as f:\n                json.dump(storage, f)\n        except Exception as e:\n            logger.error(f\"Failed to persist deliberation tasks: {e}\")\n\n    async def resolve_task(self, task_id: str, approved: bool):\n        \"\"\"Resolve a task and return approval status.\"\"\"\n        status = DeliberationStatus.APPROVED if approved else DeliberationStatus.REJECTED\n        await self.update_status(task_id, status)\n\n        task = self.tasks.get(task_id)\n        if not task:\n            return\n\n        if approved:\n            task.message.status = MessageStatus.PENDING  # Ready for re-delivery\n        else:\n            task.message.status = MessageStatus.FAILED\n\n\n_deliberation_queue = None\n\n\ndef get_deliberation_queue(persistence_path: Optional[str] = None) -> DeliberationQueue:\n    \"\"\"Get singleton deliberation queue instance.\"\"\"\n    global _deliberation_queue\n    if _deliberation_queue is None:\n        _deliberation_queue = DeliberationQueue(persistence_path=persistence_path)\n    return _deliberation_queue\n\n\ndef reset_deliberation_queue() -> None:\n    \"\"\"Reset the global deliberation queue instance.\n\n    Used primarily for test isolation to prevent state leakage between tests.\n    Properly cleans up any pending async tasks to avoid 'Task was destroyed but pending' warnings.\n    Constitutional Hash: cdd01ef066bc6cf2\n    \"\"\"\n    global _deliberation_queue\n    if _deliberation_queue is not None:\n        # Signal shutdown to stop monitor tasks gracefully\n        _deliberation_queue._shutdown = True\n        _deliberation_queue._shutdown_event.set()  # Wake up waiting tasks immediately\n        # Cancel all pending processing tasks\n        tasks_to_cancel = list(_deliberation_queue.processing_tasks)\n        for task in tasks_to_cancel:\n            if not task.done():\n                task.cancel()\n        # Try to process cancellations if there's a running event loop\n        if tasks_to_cancel:\n            try:\n                loop = asyncio.get_running_loop()\n                # If there's a running loop, schedule cleanup\n                loop.call_soon(lambda: None)  # Just trigger loop iteration\n            except RuntimeError:\n                # No running loop - try to create one temporarily to process cancellations\n                try:\n                    loop = asyncio.new_event_loop()\n                    asyncio.set_event_loop(loop)\n                    # Brief run to process cancellations\n                    loop.run_until_complete(\n                        asyncio.gather(*tasks_to_cancel, return_exceptions=True)\n                    )\n                    loop.close()\n                except Exception:\n                    pass  # Best effort cleanup\n        # Clear the task list\n        _deliberation_queue.processing_tasks.clear()\n    _deliberation_queue = None\n\n\ndef cleanup_all_deliberation_queues() -> None:\n    \"\"\"Clean up all DeliberationQueue instances to prevent async task warnings.\n\n    This function should be called at test teardown to properly stop all\n    queue instances, not just the singleton. Essential for tests that create\n    multiple queue instances directly.\n    Constitutional Hash: cdd01ef066bc6cf2\n    \"\"\"\n    global _all_queue_instances\n    for queue in _all_queue_instances:\n        if queue is not None:\n            queue._shutdown = True\n            queue._shutdown_event.set()\n            tasks_to_cancel = list(queue.processing_tasks)\n            for task in tasks_to_cancel:\n                if not task.done():\n                    task.cancel()\n            queue.processing_tasks.clear()\n    _all_queue_instances.clear()\n\n\n__all__ = [\n    \"DeliberationStatus\",\n    \"VoteType\",\n    \"DeliberationTask\",\n    \"DeliberationItem\",\n    \"AgentVote\",\n    \"DeliberationQueue\",\n    \"get_deliberation_queue\",\n    \"reset_deliberation_queue\",\n    \"cleanup_all_deliberation_queues\",\n]\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), src/core/breakthrough (79 occurrences), and src/core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.221161",
  "last_updated": "2026-01-04T05:35:59.193199"
}