{
  "file_path": "acgs2-core/enhanced_agent_bus/ai_assistant/context.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nACGS-2 AI Assistant - Context Management\nConstitutional Hash: cdd01ef066bc6cf2\n\nSophisticated context management with constitutional validation,\nentity tracking, and conversation state management.\n\"\"\"\n\nimport hashlib\nimport json\nimport logging\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta, timezone\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Union\n\n# Optional torch import for Mamba processing\ntry:\n    import torch\n    TORCH_AVAILABLE = True\nexcept ImportError:\n    TORCH_AVAILABLE = False\n    logger.warning(\"PyTorch not available - Mamba-2 processing disabled\")\n\n# Import Mamba-2 Hybrid Processor for long context\ntry:\n    from .mamba_hybrid_processor import (\n        MambaConfig,\n        get_mamba_hybrid_processor,\n        initialize_mamba_processor,\n    )\n    MAMBA_AVAILABLE = True\nexcept ImportError:\n    MAMBA_AVAILABLE = False\n    logger.warning(\"Mamba-2 Hybrid Processor not available - using standard context processing\")\n\n# Import centralized constitutional hash with fallback\ntry:\n    from shared.constants import CONSTITUTIONAL_HASH\nexcept ImportError:\n    CONSTITUTIONAL_HASH = \"cdd01ef066bc6cf2\"\n\nlogger = logging.getLogger(__name__)\n\n\nclass ConversationState(Enum):\n    \"\"\"Conversation state enumeration.\"\"\"\n\n    INITIALIZED = \"initialized\"\n    ACTIVE = \"active\"\n    AWAITING_INPUT = \"awaiting_input\"\n    WAITING_INPUT = \"waiting_input\"  # Alias for compatibility\n    AWAITING_CONFIRMATION = \"awaiting_confirmation\"\n    PROCESSING = \"processing\"\n    COMPLETED = \"completed\"\n    ESCALATED = \"escalated\"\n    FAILED = \"failed\"\n    ERROR = \"error\"\n\n\nclass MessageRole(Enum):\n    \"\"\"Message role enumeration.\"\"\"\n\n    USER = \"user\"\n    ASSISTANT = \"assistant\"\n    SYSTEM = \"system\"\n\n\n@dataclass\nclass Message:\n    \"\"\"Represents a single message in the conversation.\"\"\"\n\n    role: MessageRole\n    content: str\n    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    intent: Optional[str] = None\n    entities: List[Dict[str, Any]] = field(default_factory=list)\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert message to dictionary.\"\"\"\n        return {\n            \"role\": self.role.value if isinstance(self.role, MessageRole) else self.role,\n            \"content\": self.content,\n            \"timestamp\": self.timestamp.isoformat(),\n            \"metadata\": self.metadata,\n            \"intent\": self.intent,\n            \"entities\": self.entities,\n            \"constitutional_hash\": self.constitutional_hash,\n        }\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> \"Message\":\n        \"\"\"Create message from dictionary.\"\"\"\n        timestamp = data.get(\"timestamp\")\n        if isinstance(timestamp, str):\n            timestamp = datetime.fromisoformat(timestamp)\n        elif timestamp is None:\n            timestamp = datetime.now(timezone.utc)\n\n        role = data[\"role\"]\n        if isinstance(role, str):\n            role = MessageRole(role)\n\n        return cls(\n            role=role,\n            content=data[\"content\"],\n            timestamp=timestamp,\n            metadata=data.get(\"metadata\", {}),\n            intent=data.get(\"intent\"),\n            entities=data.get(\"entities\", []),\n            constitutional_hash=data.get(\"constitutional_hash\", CONSTITUTIONAL_HASH),\n        )\n\n\n@dataclass\nclass UserProfile:\n    \"\"\"User profile for personalization.\"\"\"\n\n    user_id: str\n    name: Optional[str] = None\n    email: Optional[str] = None\n    preferences: Dict[str, Any] = field(default_factory=dict)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    history_summary: str = \"\"\n    language: str = \"en\"\n    timezone: str = \"UTC\"\n    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n    last_active: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert profile to dictionary.\"\"\"\n        return {\n            \"user_id\": self.user_id,\n            \"name\": self.name,\n            \"email\": self.email,\n            \"preferences\": self.preferences,\n            \"metadata\": self.metadata,\n            \"history_summary\": self.history_summary,\n            \"language\": self.language,\n            \"timezone\": self.timezone,\n            \"created_at\": self.created_at.isoformat(),\n            \"last_active\": self.last_active.isoformat(),\n            \"constitutional_hash\": self.constitutional_hash,\n        }\n\n\n@dataclass\nclass ConversationContext:\n    \"\"\"\n    Maintains conversation state and context with constitutional validation.\n\n    This is the central context object that tracks:\n    - User identity and profile\n    - Session state\n    - Message history\n    - Entity states\n    - Conversation flow state\n    \"\"\"\n\n    user_id: str\n    session_id: str\n    messages: List[Message] = field(default_factory=list)\n    user_profile: Optional[UserProfile] = None\n    conversation_state: ConversationState = ConversationState.INITIALIZED\n    state_data: Dict[str, Any] = field(default_factory=dict)\n    entities: Dict[str, Any] = field(default_factory=dict)\n    slots: Dict[str, Any] = field(default_factory=dict)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n    updated_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n    tenant_id: Optional[str] = None\n    max_history: int = 100\n\n    def __post_init__(self):\n        \"\"\"Enforce max_history constraint after initialization.\"\"\"\n        if len(self.messages) > self.max_history:\n            self.messages = self.messages[-self.max_history :]\n\n    def add_message(\n        self,\n        message_or_role: Union[Message, str, MessageRole],\n        content: Optional[str] = None,\n        **kwargs,\n    ) -> Message:\n        \"\"\"\n        Add a message to the conversation history.\n\n        Can be called with:\n        - add_message(Message) - adds an existing Message object\n        - add_message(role, content, **kwargs) - creates and adds a new Message\n        - add_message(MessageRole, content, **kwargs) - creates and adds a new Message\n        \"\"\"\n        if isinstance(message_or_role, Message):\n            message = message_or_role\n        else:\n            # Handle both string role and MessageRole enum\n            if isinstance(message_or_role, MessageRole):\n                role = message_or_role\n            else:\n                # Convert string to MessageRole\n                role = (\n                    MessageRole(message_or_role)\n                    if message_or_role in [r.value for r in MessageRole]\n                    else MessageRole.USER\n                )\n            message = Message(\n                role=role,\n                content=content or \"\",\n                constitutional_hash=self.constitutional_hash,\n                **kwargs,\n            )\n        self.messages.append(message)\n        # Enforce max_history\n        if len(self.messages) > self.max_history:\n            self.messages = self.messages[-self.max_history :]\n        self.updated_at = datetime.now(timezone.utc)\n        return message\n\n    def get_last_user_message(self) -> Optional[Message]:\n        \"\"\"Get the last user message.\"\"\"\n        for msg in reversed(self.messages):\n            if msg.role == MessageRole.USER:\n                return msg\n        return None\n\n    def get_last_assistant_message(self) -> Optional[Message]:\n        \"\"\"Get the last assistant message.\"\"\"\n        for msg in reversed(self.messages):\n            if msg.role == MessageRole.ASSISTANT:\n                return msg\n        return None\n\n    def get_recent_messages(self, count: int = 10) -> List[Message]:\n        \"\"\"Get the most recent messages.\"\"\"\n        return self.messages[-count:] if self.messages else []\n\n    def get_context_hash(self) -> str:\n        \"\"\"Generate a hash of the current context for caching.\"\"\"\n        context_str = json.dumps(\n            {\n                \"user_id\": self.user_id,\n                \"session_id\": self.session_id,\n                \"state\": self.conversation_state.value,\n                \"entities\": self.entities,\n                \"slots\": self.slots,\n                \"message_count\": len(self.messages),\n            },\n            sort_keys=True,\n        )\n        return hashlib.sha256(context_str.encode()).hexdigest()[:16]\n\n    def update_entity(self, entity_type: str, entity_value: Any, **metadata) -> None:\n        \"\"\"Update an entity in the context.\"\"\"\n        self.entities[entity_type] = {\n            \"value\": entity_value,\n            \"updated_at\": datetime.now(timezone.utc).isoformat(),\n            \"metadata\": metadata,\n        }\n        self.updated_at = datetime.now(timezone.utc)\n\n    def get_entity(self, entity_type: str) -> Optional[Any]:\n        \"\"\"Get an entity value from context.\"\"\"\n        entity_data = self.entities.get(entity_type)\n        if entity_data:\n            return entity_data.get(\"value\")\n        return None\n\n    def has_entity(self, entity_type: str) -> bool:\n        \"\"\"Check if an entity exists in the context.\"\"\"\n        return entity_type in self.entities\n\n    def set_slot(self, slot_name: str, value: Any) -> None:\n        \"\"\"Set a slot value for slot-filling dialogs.\"\"\"\n        self.slots[slot_name] = {\n            \"value\": value,\n            \"filled_at\": datetime.now(timezone.utc).isoformat(),\n        }\n        self.updated_at = datetime.now(timezone.utc)\n\n    def get_slot(self, slot_name: str, default: Any = None) -> Optional[Any]:\n        \"\"\"Get a slot value, returning default if not found.\"\"\"\n        slot_data = self.slots.get(slot_name)\n        if slot_data:\n            return slot_data.get(\"value\")\n        return default\n\n    def clear_slots(self) -> None:\n        \"\"\"Clear all slots.\"\"\"\n        self.slots.clear()\n        self.updated_at = datetime.now(timezone.utc)\n\n    def transition_state(self, new_state: ConversationState) -> None:\n        \"\"\"Transition to a new conversation state.\"\"\"\n        logger.debug(\n            f\"Context state transition: {self.conversation_state.value} -> {new_state.value}\"\n        )\n        self.conversation_state = new_state\n        self.updated_at = datetime.now(timezone.utc)\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert context to dictionary for serialization.\"\"\"\n        return {\n            \"user_id\": self.user_id,\n            \"session_id\": self.session_id,\n            \"messages\": [m.to_dict() for m in self.messages],\n            \"user_profile\": self.user_profile.to_dict() if self.user_profile else None,\n            \"conversation_state\": self.conversation_state.value,\n            \"state_data\": self.state_data,\n            \"entities\": self.entities,\n            \"slots\": self.slots,\n            \"metadata\": self.metadata,\n            \"created_at\": self.created_at.isoformat(),\n            \"updated_at\": self.updated_at.isoformat(),\n            \"constitutional_hash\": self.constitutional_hash,\n            \"tenant_id\": self.tenant_id,\n        }\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> \"ConversationContext\":\n        \"\"\"Create context from dictionary.\"\"\"\n        messages = [Message.from_dict(m) for m in data.get(\"messages\", [])]\n        user_profile = None\n        if data.get(\"user_profile\"):\n            user_profile = UserProfile(**data[\"user_profile\"])\n\n        return cls(\n            user_id=data[\"user_id\"],\n            session_id=data[\"session_id\"],\n            messages=messages,\n            user_profile=user_profile,\n            conversation_state=ConversationState(data.get(\"conversation_state\", \"initialized\")),\n            state_data=data.get(\"state_data\", {}),\n            entities=data.get(\"entities\", {}),\n            slots=data.get(\"slots\", {}),\n            metadata=data.get(\"metadata\", {}),\n            created_at=(\n                datetime.fromisoformat(data[\"created_at\"])\n                if data.get(\"created_at\")\n                else datetime.now(timezone.utc)\n            ),\n            updated_at=(\n                datetime.fromisoformat(data[\"updated_at\"])\n                if data.get(\"updated_at\")\n                else datetime.now(timezone.utc)\n            ),\n            constitutional_hash=data.get(\"constitutional_hash\", CONSTITUTIONAL_HASH),\n            tenant_id=data.get(\"tenant_id\"),\n        )\n\n\nclass ContextManager:\n    \"\"\"\n    Manages conversation context with sophisticated features.\n\n    Provides:\n    - Reference resolution (pronouns, temporal)\n    - Topic tracking and shift detection\n    - Entity state management\n    - Context pruning for long conversations\n    - Constitutional validation\n    \"\"\"\n\n    def __init__(\n        self,\n        max_context_length: int = 50,\n        max_entity_age_turns: int = 10,\n        constitutional_hash: str = CONSTITUTIONAL_HASH,\n    ):\n        self.max_context_length = max_context_length\n        self.max_entity_age_turns = max_entity_age_turns\n        self.constitutional_hash = constitutional_hash\n        self._reference_patterns = self._compile_reference_patterns()\n        self._sessions: Dict[str, ConversationContext] = {}\n\n    def create_context(self, user_id: str, session_id: str, **kwargs) -> ConversationContext:\n        \"\"\"Create and store a new conversation context.\"\"\"\n        context = ConversationContext(\n            user_id=user_id,\n            session_id=session_id,\n            constitutional_hash=self.constitutional_hash,\n            **kwargs,\n        )\n        self._sessions[session_id] = context\n        return context\n\n    def get_context(self, session_id: str) -> Optional[ConversationContext]:\n        \"\"\"Retrieve a conversation context by session ID.\"\"\"\n        return self._sessions.get(session_id)\n\n    def delete_context(self, session_id: str) -> bool:\n        \"\"\"Delete a conversation context by session ID.\"\"\"\n        if session_id in self._sessions:\n            del self._sessions[session_id]\n            return True\n        return False\n\n    def list_user_contexts(self, user_id: str) -> List[ConversationContext]:\n        \"\"\"List all contexts for a given user.\"\"\"\n        return [ctx for ctx in self._sessions.values() if ctx.user_id == user_id]\n\n    def _compile_reference_patterns(self) -> Dict[str, List[str]]:\n        \"\"\"Compile patterns for reference resolution.\"\"\"\n        return {\n            \"pronouns\": {\n                \"it\": [\"object\", \"thing\", \"topic\"],\n                \"they\": [\"people\", \"group\", \"items\"],\n                \"he\": [\"male_person\"],\n                \"she\": [\"female_person\"],\n                \"that\": [\"previous_topic\", \"object\"],\n                \"this\": [\"current_topic\", \"object\"],\n                \"there\": [\"location\"],\n            },\n            \"temporal\": {\n                \"today\": \"current_date\",\n                \"tomorrow\": \"next_day\",\n                \"yesterday\": \"previous_day\",\n                \"next week\": \"next_week\",\n                \"last week\": \"previous_week\",\n                \"now\": \"current_time\",\n                \"later\": \"future_time\",\n            },\n        }\n\n    async def update_context(\n        self,\n        context: ConversationContext,\n        user_message: str,\n        nlu_result: Optional[Dict[str, Any]] = None,\n    ) -> ConversationContext:\n        \"\"\"\n        Update context with new user message and NLU results.\n\n        Args:\n            context: Current conversation context\n            user_message: Raw user message\n            nlu_result: NLU processing results (intent, entities, etc.)\n\n        Returns:\n            Updated conversation context\n        \"\"\"\n        # Add user message\n        message = context.add_message(\n            role=\"user\",\n            content=user_message,\n            intent=nlu_result.get(\"intent\") if nlu_result else None,\n            entities=nlu_result.get(\"entities\", []) if nlu_result else [],\n        )\n\n        # Resolve references in the message\n        resolved_message = await self.resolve_references(user_message, context)\n        if resolved_message != user_message:\n            message.metadata[\"resolved_content\"] = resolved_message\n\n        # Update entities from NLU\n        if nlu_result and nlu_result.get(\"entities\"):\n            for entity in nlu_result[\"entities\"]:\n                context.update_entity(\n                    entity_type=entity[\"type\"],\n                    entity_value=entity[\"value\"],\n                    confidence=entity.get(\"confidence\", 1.0),\n                    source_turn=len(context.messages),\n                )\n\n        # Detect topic shift\n        topic_shift = self._detect_topic_shift(nlu_result, context)\n        if topic_shift:\n            context.metadata[\"topic_shift\"] = {\n                \"detected_at\": datetime.now(timezone.utc).isoformat(),\n                \"from_topic\": topic_shift.get(\"from\"),\n                \"to_topic\": topic_shift.get(\"to\"),\n            }\n\n        # Prune old context if needed\n        if len(context.messages) > self.max_context_length:\n            context = self._prune_context(context)\n\n        # Transition state to active\n        if context.conversation_state == ConversationState.INITIALIZED:\n            context.transition_state(ConversationState.ACTIVE)\n\n        return context\n\n    async def resolve_references(\n        self,\n        text: str,\n        context: ConversationContext,\n    ) -> str:\n        \"\"\"\n        Resolve pronouns and references in text using context.\n\n        Args:\n            text: Text with potential references\n            context: Conversation context for resolution\n\n        Returns:\n            Text with resolved references\n        \"\"\"\n        resolved = text.lower()\n\n        # Resolve pronouns\n        for pronoun, entity_types in self._reference_patterns[\"pronouns\"].items():\n            if pronoun in resolved:\n                # Find matching entity in context\n                for entity_type in entity_types:\n                    entity_value = context.get_entity(entity_type)\n                    if entity_value:\n                        resolved = resolved.replace(pronoun, str(entity_value))\n                        break\n\n        # Resolve temporal references\n        for temporal_ref, ref_type in self._reference_patterns[\"temporal\"].items():\n            if temporal_ref in resolved:\n                resolved_time = self._resolve_temporal(ref_type)\n                resolved = resolved.replace(temporal_ref, str(resolved_time))\n\n        return resolved\n\n    def _resolve_temporal(self, ref_type: str) -> str:\n        \"\"\"Resolve temporal reference to actual value.\"\"\"\n        now = datetime.now(timezone.utc)\n\n        resolutions = {\n            \"current_date\": now.strftime(\"%Y-%m-%d\"),\n            \"next_day\": (now.replace(hour=0, minute=0, second=0) + timedelta(days=1)).strftime(\n                \"%Y-%m-%d\"\n            ),\n            \"previous_day\": (now.replace(hour=0, minute=0, second=0) - timedelta(days=1)).strftime(\n                \"%Y-%m-%d\"\n            ),\n            \"current_time\": now.strftime(\"%H:%M\"),\n            \"next_week\": (now + timedelta(weeks=1)).strftime(\"%Y-%m-%d\"),\n            \"previous_week\": (now - timedelta(weeks=1)).strftime(\"%Y-%m-%d\"),\n        }\n\n        return resolutions.get(ref_type, ref_type)\n\n    async def process_long_context(\n        self,\n        context: ConversationContext,\n        max_tokens: int = 1_000_000,\n        use_attention: bool = False\n    ) -> ConversationContext:\n        \"\"\"\n        Process conversation context using Mamba-2 Hybrid Processor for long contexts.\n\n        This enables processing of conversations with millions of tokens while maintaining\n        constitutional compliance and context understanding.\n\n        Args:\n            context: Conversation context to process\n            max_tokens: Maximum tokens to process (up to 4M)\n            use_attention: Whether to use attention layer for critical reasoning\n\n        Returns:\n            Enhanced conversation context with long-term understanding\n        \"\"\"\n        if not MAMBA_AVAILABLE:\n            logger.warning(\"Mamba-2 processor not available, using standard processing\")\n            return context\n\n        try:\n            # Get Mamba processor\n            mamba_manager = get_mamba_hybrid_processor()\n\n            # Ensure model is loaded\n            if not mamba_manager.is_loaded:\n                config = MambaConfig(max_context_length=min(max_tokens, 4_000_000))\n                if not initialize_mamba_processor(config):\n                    logger.error(\"Failed to initialize Mamba processor\")\n                    return context\n\n            # Convert conversation to tensor format\n            # This is a simplified conversion - in practice would use proper embeddings\n            messages_text = [msg.content for msg in context.messages[-100:]]  # Last 100 messages\n            context_text = \" \".join(messages_text)\n\n            # Create dummy embeddings (in practice, use proper tokenizer and embeddings)\n            # This is placeholder - actual implementation would use real embeddings\n            seq_len = min(len(context_text.split()), max_tokens // 10)  # Rough token estimation\n            d_model = 512  # Match Mamba config\n\n            # Create input tensor (dummy embeddings for now)\n            input_tensor = torch.randn(1, seq_len, d_model)\n\n            # Process through Mamba hybrid processor\n            processed_tensor = mamba_manager.process_context(\n                input_tensor=input_tensor,\n                use_attention=use_attention\n            )\n\n            # Extract insights from processed tensor\n            # This would be enhanced with actual embedding analysis\n            context_strength = float(processed_tensor.norm().item())\n            context.metadata[\"mamba_processed\"] = True\n            context.metadata[\"context_strength\"] = context_strength\n            context.metadata[\"processed_at\"] = datetime.now(timezone.utc).isoformat()\n            context.metadata[\"mamba_config\"] = {\n                \"max_tokens\": max_tokens,\n                \"attention_used\": use_attention,\n                \"constitutional_hash\": CONSTITUTIONAL_HASH\n            }\n\n            logger.info(f\"Processed long context with Mamba-2: strength={context_strength:.2f}\")\n\n            return context\n\n        except Exception as e:\n            logger.error(f\"Failed to process long context with Mamba-2: {e}\")\n            context.metadata[\"mamba_error\"] = str(e)\n            return context\n\n    def _detect_topic_shift(\n        self,\n        nlu_result: Optional[Dict[str, Any]],\n        context: ConversationContext,\n    ) -> Optional[Dict[str, str]]:\n        \"\"\"Detect if there's a topic shift in the conversation.\"\"\"\n        if not nlu_result or not context.messages:\n            return None\n\n        current_intent = nlu_result.get(\"intent\")\n        if not current_intent:\n            return None\n\n        # Get previous intent\n        previous_messages = [m for m in context.messages[-5:] if m.role == \"user\" and m.intent]\n\n        if not previous_messages:\n            return None\n\n        previous_intent = previous_messages[-1].intent\n\n        # Check for significant topic change\n        topic_indicators = {\n            \"greeting\": [\"greeting\", \"farewell\"],\n            \"order\": [\"order\", \"purchase\", \"buy\"],\n            \"support\": [\"help\", \"issue\", \"problem\"],\n            \"information\": [\"question\", \"inquiry\", \"ask\"],\n        }\n\n        def get_topic(intent: str) -> Optional[str]:\n            for topic, intents in topic_indicators.items():\n                if any(i in intent.lower() for i in intents):\n                    return topic\n            return None\n\n        previous_topic = get_topic(previous_intent)\n        current_topic = get_topic(current_intent)\n\n        if previous_topic and current_topic and previous_topic != current_topic:\n            return {\"from\": previous_topic, \"to\": current_topic}\n\n        return None\n\n    def _prune_context(self, context: ConversationContext) -> ConversationContext:\n        \"\"\"\n        Prune old context to manage memory.\n\n        Keeps:\n        - Most recent messages\n        - Important entities\n        - Summarizes old context\n        \"\"\"\n        # Keep system messages and recent messages\n        system_messages = [m for m in context.messages if m.role == \"system\"]\n        recent_messages = context.messages[-self.max_context_length :]\n\n        # Combine, avoiding duplicates\n        context.messages = system_messages + [\n            m for m in recent_messages if m not in system_messages\n        ]\n\n        # Prune old entities\n        current_turn = len(context.messages)\n        entities_to_remove = []\n\n        for entity_type, entity_data in context.entities.items():\n            source_turn = entity_data.get(\"metadata\", {}).get(\"source_turn\", 0)\n            if current_turn - source_turn > self.max_entity_age_turns:\n                entities_to_remove.append(entity_type)\n\n        for entity_type in entities_to_remove:\n            del context.entities[entity_type]\n\n        logger.debug(f\"Pruned context: {len(entities_to_remove)} entities removed\")\n        return context\n\n    def get_context_summary(self, context: ConversationContext) -> str:\n        \"\"\"Generate a summary of the conversation context.\"\"\"\n        summary_parts = []\n\n        # User info\n        if context.user_profile:\n            summary_parts.append(f\"User: {context.user_id}\")\n\n        # Conversation state\n        summary_parts.append(f\"State: {context.conversation_state.value}\")\n\n        # Message count\n        summary_parts.append(f\"Messages: {len(context.messages)}\")\n\n        # Active entities\n        if context.entities:\n            entity_list = \", \".join(f\"{k}={v.get('value')}\" for k, v in context.entities.items())\n            summary_parts.append(f\"Entities: {entity_list}\")\n\n        # Filled slots\n        if context.slots:\n            slot_list = \", \".join(f\"{k}={v.get('value')}\" for k, v in context.slots.items())\n            summary_parts.append(f\"Slots: {slot_list}\")\n\n        return \" | \".join(summary_parts)\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), acgs2-core/breakthrough (79 occurrences), and acgs2-core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.264529",
  "last_updated": "2026-01-04T05:35:58.575254"
}