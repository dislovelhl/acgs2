{
  "file_path": "src/core/enhanced_agent_bus/runtime_security.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nACGS-2 Enhanced Agent Bus - Runtime Security Scanner\nConstitutional Hash: cdd01ef066bc6cf2\n\nUnified runtime security scanning and validation that aggregates all security features:\n- Prompt injection detection\n- Tenant validation\n- Permission scoping\n- Constitutional hash validation\n- Rate limiting checks\n- Security event logging\n- Anomaly detection\n\"\"\"\n\nimport asyncio\nimport logging\nimport re\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional\n\ntry:\n    from shared.constants import CONSTITUTIONAL_HASH\nexcept ImportError:\n    CONSTITUTIONAL_HASH = \"cdd01ef066bc6cf2\"\n\ntry:\n    from .constitutional_classifier import ComplianceResult, get_constitutional_classifier\n    from .security.tenant_validator import TenantValidator\n    from .security_helpers import detect_prompt_injection\n    from .validators import validate_constitutional_hash\nexcept ImportError:\n    # Fallback for standalone usage\n    detect_prompt_injection = None  # type: ignore\n    TenantValidator = None  # type: ignore\n    from validators import validate_constitutional_hash  # type: ignore\n    get_constitutional_classifier = None  # type: ignore\n    ComplianceResult = None  # type: ignore\n\nlogger = logging.getLogger(__name__)\n\n\nclass SecurityEventType(Enum):\n    \"\"\"Types of security events for monitoring and alerting.\"\"\"\n\n    PROMPT_INJECTION_ATTEMPT = \"prompt_injection_attempt\"\n    TENANT_VIOLATION = \"tenant_violation\"\n    RATE_LIMIT_EXCEEDED = \"rate_limit_exceeded\"\n    CONSTITUTIONAL_HASH_MISMATCH = \"constitutional_hash_mismatch\"\n    PERMISSION_DENIED = \"permission_denied\"\n    INVALID_INPUT = \"invalid_input\"\n    ANOMALY_DETECTED = \"anomaly_detected\"\n    AUTHENTICATION_FAILURE = \"authentication_failure\"\n    AUTHORIZATION_FAILURE = \"authorization_failure\"\n    SUSPICIOUS_PATTERN = \"suspicious_pattern\"\n    CONSTITUTIONAL_VIOLATION = \"constitutional_violation\"\n\n\nclass SecuritySeverity(Enum):\n    \"\"\"Severity levels for security events.\"\"\"\n\n    INFO = \"info\"\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\n\n@dataclass\nclass SecurityEvent:\n    \"\"\"Represents a security event for logging and alerting.\"\"\"\n\n    event_type: SecurityEventType\n    severity: SecuritySeverity\n    message: str\n    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n    source: str = \"runtime_security_scanner\"\n    tenant_id: Optional[str] = None\n    agent_id: Optional[str] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary for serialization.\"\"\"\n        return {\n            \"event_type\": self.event_type.value,\n            \"severity\": self.severity.value,\n            \"message\": self.message,\n            \"timestamp\": self.timestamp.isoformat(),\n            \"source\": self.source,\n            \"tenant_id\": self.tenant_id,\n            \"agent_id\": self.agent_id,\n            \"metadata\": self.metadata,\n            \"constitutional_hash\": self.constitutional_hash,\n        }\n\n\n@dataclass\nclass SecurityScanResult:\n    \"\"\"Result of a comprehensive security scan.\"\"\"\n\n    is_secure: bool = True\n    events: List[SecurityEvent] = field(default_factory=list)\n    blocked: bool = False\n    block_reason: Optional[str] = None\n    scan_duration_ms: float = 0.0\n    checks_performed: List[str] = field(default_factory=list)\n    warnings: List[str] = field(default_factory=list)\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n\n    def add_event(self, event: SecurityEvent) -> None:\n        \"\"\"Add a security event to the result.\"\"\"\n        self.events.append(event)\n        if event.severity in (SecuritySeverity.HIGH, SecuritySeverity.CRITICAL):\n            self.is_secure = False\n\n    def add_blocking_event(self, event: SecurityEvent, reason: str) -> None:\n        \"\"\"Add a blocking security event.\"\"\"\n        self.add_event(event)\n        self.blocked = True\n        self.block_reason = reason\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary for serialization.\"\"\"\n        return {\n            \"is_secure\": self.is_secure,\n            \"events\": [e.to_dict() for e in self.events],\n            \"blocked\": self.blocked,\n            \"block_reason\": self.block_reason,\n            \"scan_duration_ms\": self.scan_duration_ms,\n            \"checks_performed\": self.checks_performed,\n            \"warnings\": self.warnings,\n            \"constitutional_hash\": self.constitutional_hash,\n        }\n\n\n@dataclass\nclass RuntimeSecurityConfig:\n    \"\"\"Configuration for runtime security scanning.\"\"\"\n\n    # Enable/disable specific checks\n    enable_prompt_injection_detection: bool = True\n    enable_tenant_validation: bool = True\n    enable_rate_limit_check: bool = True\n    enable_constitutional_validation: bool = True\n    enable_anomaly_detection: bool = True\n    enable_input_sanitization: bool = True\n    enable_constitutional_classifier: bool = True\n\n    # Thresholds\n    rate_limit_qps: int = 100\n    rate_limit_burst: int = 200\n    max_input_length: int = 100000\n    max_nested_depth: int = 50\n    constitutional_classifier_threshold: float = 0.85\n\n    # Anomaly detection settings\n    anomaly_window_seconds: int = 60\n    anomaly_threshold_events: int = 10\n\n    # Security event retention\n    event_retention_seconds: int = 3600\n    max_events_retained: int = 10000\n\n    # Fail-closed behavior (deny on error)\n    fail_closed: bool = True\n\n\nclass RuntimeSecurityScanner:\n    \"\"\"\n    Unified runtime security scanner for ACGS-2.\n\n    Provides comprehensive runtime security scanning and validation by\n    aggregating all security features into a single, easy-to-use interface.\n\n    Features:\n    - Prompt injection detection\n    - Tenant ID validation\n    - Rate limiting checks\n    - Constitutional hash validation\n    - Input sanitization\n    - Anomaly detection\n    - Security event logging\n\n    Constitutional Hash: cdd01ef066bc6cf2\n    \"\"\"\n\n    # Additional suspicious patterns beyond prompt injection\n    SUSPICIOUS_PATTERNS = [\n        r\"<script[^>]*>\",  # XSS attempts\n        r\"javascript:\",  # JavaScript protocol\n        r\"on\\w+\\s*=\",  # Event handlers\n        r\"(?:union|select|insert|update|delete|drop)\\s+\",  # SQL injection\n        r\"\\.\\./\",  # Path traversal\n        r\"\\\\x[0-9a-fA-F]{2}\",  # Hex escapes\n        r\"\\\\u[0-9a-fA-F]{4}\",  # Unicode escapes used maliciously\n        r\"base64_decode\",  # Base64 decode attempts\n        r\"eval\\s*\\(\",  # Eval calls\n        r\"exec\\s*\\(\",  # Exec calls\n        r\"__import__\",  # Python import injection\n        r\"subprocess\\.\",  # Subprocess access\n        r\"os\\.system\",  # OS command execution\n    ]\n\n    def __init__(self, config: Optional[RuntimeSecurityConfig] = None):\n        \"\"\"\n        Initialize the runtime security scanner.\n\n        Args:\n            config: Security configuration (uses defaults if not provided)\n        \"\"\"\n        self.config = config or RuntimeSecurityConfig()\n        self._compiled_patterns = [re.compile(p, re.IGNORECASE) for p in self.SUSPICIOUS_PATTERNS]\n        self._event_buffer: List[SecurityEvent] = []\n        self._rate_counters: Dict[str, List[float]] = {}\n        self._lock = asyncio.Lock()\n\n        # Metrics\n        self._total_scans = 0\n        self._blocked_requests = 0\n        self._events_detected = 0\n\n        logger.info(\n            f\"RuntimeSecurityScanner initialized with constitutional hash: {CONSTITUTIONAL_HASH}\"\n        )\n\n    async def scan(\n        self,\n        content: Any,\n        tenant_id: Optional[str] = None,\n        agent_id: Optional[str] = None,\n        constitutional_hash: Optional[str] = None,\n        context: Optional[Dict[str, Any]] = None,\n    ) -> SecurityScanResult:\n        \"\"\"\n        Perform comprehensive security scan on content.\n\n        Args:\n            content: Content to scan (string, dict, or any)\n            tenant_id: Tenant identifier for validation\n            agent_id: Agent identifier for tracking\n            constitutional_hash: Constitutional hash to validate\n            context: Additional context for scanning\n\n        Returns:\n            SecurityScanResult with scan results and any events\n        \"\"\"\n        start_time = time.monotonic()\n        result = SecurityScanResult()\n        context = context or {}\n\n        try:\n            # Track scan\n            self._total_scans += 1\n\n            # 1. Constitutional hash validation\n            if self.config.enable_constitutional_validation and constitutional_hash:\n                result.checks_performed.append(\"constitutional_hash_validation\")\n                await self._check_constitutional_hash(\n                    result, constitutional_hash, tenant_id, agent_id\n                )\n\n            # 2. Tenant validation\n            if self.config.enable_tenant_validation and tenant_id is not None:\n                result.checks_performed.append(\"tenant_validation\")\n                await self._check_tenant(result, tenant_id, agent_id)\n\n            # 3. Rate limiting\n            if self.config.enable_rate_limit_check:\n                result.checks_performed.append(\"rate_limit_check\")\n                await self._check_rate_limit(result, tenant_id, agent_id)\n\n            # 4. Input sanitization and validation\n            if self.config.enable_input_sanitization:\n                result.checks_performed.append(\"input_sanitization\")\n                await self._check_input(result, content, tenant_id, agent_id)\n\n            # 5. Prompt injection detection\n            if self.config.enable_prompt_injection_detection:\n                result.checks_performed.append(\"prompt_injection_detection\")\n                await self._check_prompt_injection(result, content, tenant_id, agent_id)\n\n            # 6. Suspicious pattern detection\n            result.checks_performed.append(\"suspicious_pattern_detection\")\n            await self._check_suspicious_patterns(result, content, tenant_id, agent_id)\n\n            # 7. Anomaly detection\n            if self.config.enable_anomaly_detection:\n                result.checks_performed.append(\"anomaly_detection\")\n                await self._check_anomalies(result, tenant_id, agent_id)\n\n            # 8. Constitutional classification (Phase 2 Breakthrough)\n            if self.config.enable_constitutional_classifier:\n                result.checks_performed.append(\"constitutional_classification\")\n                await self._check_constitutional_compliance(result, content, tenant_id, agent_id)\n\n        except Exception as e:\n            logger.error(f\"Security scan error: {e}\")\n            if self.config.fail_closed:\n                result.blocked = True\n                result.block_reason = f\"Security scan error: {str(e)}\"\n                result.is_secure = False\n\n        # Calculate scan duration\n        result.scan_duration_ms = (time.monotonic() - start_time) * 1000\n\n        # Update metrics\n        if result.blocked:\n            self._blocked_requests += 1\n        self._events_detected += len(result.events)\n\n        # Store events\n        await self._store_events(result.events)\n\n        return result\n\n    async def _check_constitutional_hash(\n        self,\n        result: SecurityScanResult,\n        hash_value: str,\n        tenant_id: Optional[str],\n        agent_id: Optional[str],\n    ) -> None:\n        \"\"\"Validate constitutional hash.\"\"\"\n        validation = validate_constitutional_hash(hash_value)\n        if not validation.is_valid:\n            event = SecurityEvent(\n                event_type=SecurityEventType.CONSTITUTIONAL_HASH_MISMATCH,\n                severity=SecuritySeverity.CRITICAL,\n                message=\"Constitutional hash mismatch detected\",\n                tenant_id=tenant_id,\n                agent_id=agent_id,\n                metadata={\"provided_hash_prefix\": hash_value[:8] if hash_value else \"\"},\n            )\n            result.add_blocking_event(event, \"Constitutional hash validation failed\")\n\n    async def _check_tenant(\n        self,\n        result: SecurityScanResult,\n        tenant_id: str,\n        agent_id: Optional[str],\n    ) -> None:\n        \"\"\"Validate tenant ID.\"\"\"\n        if TenantValidator is None:\n            result.warnings.append(\"TenantValidator not available\")\n            return\n\n        normalized, is_valid = TenantValidator.sanitize_and_validate(tenant_id)\n        if not is_valid:\n            event = SecurityEvent(\n                event_type=SecurityEventType.TENANT_VIOLATION,\n                severity=SecuritySeverity.HIGH,\n                message=\"Invalid tenant ID format\",\n                tenant_id=tenant_id,\n                agent_id=agent_id,\n                metadata={\"normalized\": normalized},\n            )\n            result.add_blocking_event(event, \"Tenant validation failed\")\n\n    async def _check_rate_limit(\n        self,\n        result: SecurityScanResult,\n        tenant_id: Optional[str],\n        agent_id: Optional[str],\n    ) -> None:\n        \"\"\"Check rate limiting.\"\"\"\n        key = f\"{tenant_id or 'global'}:{agent_id or 'unknown'}\"\n        now = time.monotonic()\n\n        async with self._lock:\n            if key not in self._rate_counters:\n                self._rate_counters[key] = []\n\n            # Clean old entries\n            window_start = now - 1.0  # 1 second window\n            self._rate_counters[key] = [t for t in self._rate_counters[key] if t > window_start]\n\n            # Check rate\n            current_rate = len(self._rate_counters[key])\n            if current_rate >= self.config.rate_limit_qps:\n                event = SecurityEvent(\n                    event_type=SecurityEventType.RATE_LIMIT_EXCEEDED,\n                    severity=SecuritySeverity.MEDIUM,\n                    message=f\"Rate limit exceeded: {current_rate} QPS\",\n                    tenant_id=tenant_id,\n                    agent_id=agent_id,\n                    metadata={\n                        \"current_rate\": current_rate,\n                        \"limit\": self.config.rate_limit_qps,\n                    },\n                )\n                result.add_event(event)\n                result.warnings.append(f\"Rate limit exceeded: {current_rate} QPS\")\n\n            # Record this request\n            self._rate_counters[key].append(now)\n\n    async def _check_input(\n        self,\n        result: SecurityScanResult,\n        content: Any,\n        tenant_id: Optional[str],\n        agent_id: Optional[str],\n    ) -> None:\n        \"\"\"Validate and sanitize input.\"\"\"\n        content_str = str(content) if content is not None else \"\"\n\n        # Check length\n        if len(content_str) > self.config.max_input_length:\n            event = SecurityEvent(\n                event_type=SecurityEventType.INVALID_INPUT,\n                severity=SecuritySeverity.MEDIUM,\n                message=\"Input exceeds maximum length\",\n                tenant_id=tenant_id,\n                agent_id=agent_id,\n                metadata={\n                    \"length\": len(content_str),\n                    \"max_length\": self.config.max_input_length,\n                },\n            )\n            result.add_event(event)\n            result.warnings.append(\"Input exceeds maximum length\")\n\n        # Check nested depth for dicts\n        if isinstance(content, dict):\n            depth = self._get_nested_depth(content)\n            if depth > self.config.max_nested_depth:\n                event = SecurityEvent(\n                    event_type=SecurityEventType.INVALID_INPUT,\n                    severity=SecuritySeverity.MEDIUM,\n                    message=\"Input exceeds maximum nesting depth\",\n                    tenant_id=tenant_id,\n                    agent_id=agent_id,\n                    metadata={\n                        \"depth\": depth,\n                        \"max_depth\": self.config.max_nested_depth,\n                    },\n                )\n                result.add_event(event)\n                result.warnings.append(\"Input exceeds maximum nesting depth\")\n\n    async def _check_prompt_injection(\n        self,\n        result: SecurityScanResult,\n        content: Any,\n        tenant_id: Optional[str],\n        agent_id: Optional[str],\n    ) -> None:\n        \"\"\"Check for prompt injection attempts.\"\"\"\n        if detect_prompt_injection is None:\n            result.warnings.append(\"Prompt injection detection not available\")\n            return\n\n        content_str = str(content) if content is not None else \"\"\n        if detect_prompt_injection(content_str):\n            event = SecurityEvent(\n                event_type=SecurityEventType.PROMPT_INJECTION_ATTEMPT,\n                severity=SecuritySeverity.HIGH,\n                message=\"Potential prompt injection attempt detected\",\n                tenant_id=tenant_id,\n                agent_id=agent_id,\n                metadata={\"content_length\": len(content_str)},\n            )\n            result.add_blocking_event(event, \"Prompt injection detected\")\n\n    async def _check_suspicious_patterns(\n        self,\n        result: SecurityScanResult,\n        content: Any,\n        tenant_id: Optional[str],\n        agent_id: Optional[str],\n    ) -> None:\n        \"\"\"Check for suspicious patterns.\"\"\"\n        content_str = str(content) if content is not None else \"\"\n\n        for pattern in self._compiled_patterns:\n            if pattern.search(content_str):\n                event = SecurityEvent(\n                    event_type=SecurityEventType.SUSPICIOUS_PATTERN,\n                    severity=SecuritySeverity.MEDIUM,\n                    message=f\"Suspicious pattern detected: {pattern.pattern[:30]}...\",\n                    tenant_id=tenant_id,\n                    agent_id=agent_id,\n                    metadata={\"pattern\": pattern.pattern},\n                )\n                result.add_event(event)\n\n    async def _check_anomalies(\n        self,\n        result: SecurityScanResult,\n        tenant_id: Optional[str],\n        agent_id: Optional[str],\n    ) -> None:\n        \"\"\"Check for security anomalies based on event history.\"\"\"\n        now = datetime.now(timezone.utc)\n        window_start = now.timestamp() - self.config.anomaly_window_seconds\n\n        # Count recent events for this tenant/agent\n        recent_events = [\n            e\n            for e in self._event_buffer\n            if e.timestamp.timestamp() > window_start\n            and e.tenant_id == tenant_id\n            and (agent_id is None or e.agent_id == agent_id)\n        ]\n\n        if len(recent_events) >= self.config.anomaly_threshold_events:\n            event = SecurityEvent(\n                event_type=SecurityEventType.ANOMALY_DETECTED,\n                severity=SecuritySeverity.HIGH,\n                message=f\"Anomaly detected: {len(recent_events)} events in {self.config.anomaly_window_seconds}s\",\n                tenant_id=tenant_id,\n                agent_id=agent_id,\n                metadata={\n                    \"event_count\": len(recent_events),\n                    \"window_seconds\": self.config.anomaly_window_seconds,\n                    \"threshold\": self.config.anomaly_threshold_events,\n                },\n            )\n            result.add_event(event)\n\n    async def _check_constitutional_compliance(\n        self,\n        result: SecurityScanResult,\n        content: Any,\n        tenant_id: Optional[str],\n        agent_id: Optional[str],\n    ) -> None:\n        \"\"\"Check content for constitutional compliance using neural classification.\"\"\"\n        if get_constitutional_classifier is None:\n            result.warnings.append(\"Constitutional classifier not available\")\n            return\n\n        classifier = get_constitutional_classifier(\n            threshold=self.config.constitutional_classifier_threshold\n        )\n\n        # Ensure initialized (lazy initialization)\n        if not classifier._initialized:\n            await classifier.initialize()\n\n        content_str = str(content) if content is not None else \"\"\n        classification = await classifier.classify(content_str)\n\n        if not classification.compliant:\n            event = SecurityEvent(\n                event_type=SecurityEventType.CONSTITUTIONAL_VIOLATION,\n                severity=SecuritySeverity.HIGH if classification.confidence > 0.9 else SecuritySeverity.MEDIUM,\n                message=f\"Constitutional violation detected: {classification.reason}\",\n                tenant_id=tenant_id,\n                agent_id=agent_id,\n                metadata={\n                    \"confidence\": classification.confidence,\n                    \"reason\": classification.reason,\n                    \"classifier_metadata\": classification.metadata\n                },\n            )\n\n            # Block if confidence is high or reason is severe\n            if classification.confidence > 0.9 or \"pattern\" in classification.reason:\n                result.add_blocking_event(event, f\"Constitutional compliance check failed: {classification.reason}\")\n            else:\n                result.add_event(event)\n                result.warnings.append(f\"Constitutional compliance warning: {classification.reason}\")\n\n    def _get_nested_depth(self, obj: Any, current_depth: int = 0) -> int:\n        \"\"\"Calculate nested depth of an object.\"\"\"\n        if current_depth > self.config.max_nested_depth:\n            return current_depth\n\n        if isinstance(obj, dict):\n            if not obj:\n                return current_depth\n            return max(self._get_nested_depth(v, current_depth + 1) for v in obj.values())\n        elif isinstance(obj, (list, tuple)):\n            if not obj:\n                return current_depth\n            return max(self._get_nested_depth(v, current_depth + 1) for v in obj)\n        return current_depth\n\n    async def _store_events(self, events: List[SecurityEvent]) -> None:\n        \"\"\"Store security events for anomaly detection and auditing.\"\"\"\n        async with self._lock:\n            self._event_buffer.extend(events)\n\n            # Trim old events\n            if len(self._event_buffer) > self.config.max_events_retained:\n                self._event_buffer = self._event_buffer[-self.config.max_events_retained :]\n\n            # Remove expired events\n            cutoff = datetime.now(timezone.utc).timestamp() - self.config.event_retention_seconds\n            self._event_buffer = [e for e in self._event_buffer if e.timestamp.timestamp() > cutoff]\n\n    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get security scanner metrics.\"\"\"\n        return {\n            \"total_scans\": self._total_scans,\n            \"blocked_requests\": self._blocked_requests,\n            \"events_detected\": self._events_detected,\n            \"block_rate\": (\n                self._blocked_requests / self._total_scans if self._total_scans > 0 else 0.0\n            ),\n            \"events_buffered\": len(self._event_buffer),\n            \"constitutional_hash\": CONSTITUTIONAL_HASH,\n        }\n\n    def get_recent_events(\n        self,\n        limit: int = 100,\n        severity_filter: Optional[SecuritySeverity] = None,\n        event_type_filter: Optional[SecurityEventType] = None,\n    ) -> List[SecurityEvent]:\n        \"\"\"Get recent security events with optional filtering.\"\"\"\n        events = self._event_buffer[-limit:]\n\n        if severity_filter:\n            events = [e for e in events if e.severity == severity_filter]\n\n        if event_type_filter:\n            events = [e for e in events if e.event_type == event_type_filter]\n\n        return events\n\n\n# Global scanner instance\n_scanner: Optional[RuntimeSecurityScanner] = None\n\n\ndef get_runtime_security_scanner(\n    config: Optional[RuntimeSecurityConfig] = None,\n) -> RuntimeSecurityScanner:\n    \"\"\"Get or create the global runtime security scanner instance.\"\"\"\n    global _scanner\n    if _scanner is None:\n        _scanner = RuntimeSecurityScanner(config)\n    return _scanner\n\n\nasync def scan_content(\n    content: Any,\n    tenant_id: Optional[str] = None,\n    agent_id: Optional[str] = None,\n    constitutional_hash: Optional[str] = None,\n) -> SecurityScanResult:\n    \"\"\"\n    Convenience function to perform a security scan.\n\n    Args:\n        content: Content to scan\n        tenant_id: Tenant identifier\n        agent_id: Agent identifier\n        constitutional_hash: Constitutional hash to validate\n\n    Returns:\n        SecurityScanResult with scan results\n    \"\"\"\n    scanner = get_runtime_security_scanner()\n    return await scanner.scan(\n        content=content,\n        tenant_id=tenant_id,\n        agent_id=agent_id,\n        constitutional_hash=constitutional_hash,\n    )\n\n\n__all__ = [\n    \"CONSTITUTIONAL_HASH\",\n    \"RuntimeSecurityConfig\",\n    \"RuntimeSecurityScanner\",\n    \"SecurityEvent\",\n    \"SecurityEventType\",\n    \"SecurityScanResult\",\n    \"SecuritySeverity\",\n    \"get_runtime_security_scanner\",\n    \"scan_content\",\n]\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), src/core/breakthrough (79 occurrences), and src/core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.288204",
  "last_updated": "2026-01-04T05:35:58.813621"
}