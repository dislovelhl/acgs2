{
  "file_path": "integration-service/src/integrations/sentinel_adapter.py",
  "main_branch_history": [],
  "task_views": {
    "037-add-batch-event-processing-to-baseintegration": {
      "task_id": "037-add-batch-event-processing-to-baseintegration",
      "branch_point": {
        "commit_hash": "2fb699cec90aaf3419af3108057ed29ae4213e1b",
        "content": "\"\"\"\nMicrosoft Sentinel Integration Adapter\n\nProvides integration with Microsoft Sentinel SIEM using the Azure Monitor Ingestion\nAPI for real-time governance event ingestion.\n\nFeatures:\n- Azure AD Service Principal authentication with automatic token refresh\n- Data Collection Rule (DCR) based log ingestion\n- High-performance batch event processing (respects Azure limits)\n- Single event and batch API support\n- Automatic event formatting for Log Analytics custom tables\n- Rate limit handling with Retry-After support\n- Azure cloud environment support (public, government, china)\n- Configurable batch size (default 100, max 500 events per batch)\n\nBatch Processing:\nThis adapter implements native batch processing using Azure Monitor Ingestion API.\nBatches are sent as a single HTTP request containing a JSON array of events,\nrespecting Azure's limits (1MB max payload, 500 records max). Use send_events_batch()\nfor optimal performance when sending multiple events.\n\nAzure Limits:\n- Maximum batch size: 500 records\n- Maximum payload size: 1MB (1,000,000 bytes)\n- All-or-nothing batch semantics: entire batch succeeds or fails together\n- Automatic retry with exponential backoff for transient failures\n\nPerformance:\n- Batch processing can reduce API calls by up to 100x (for batch_size=100)\n- Lower authentication overhead (one token refresh check per batch)\n- Improved throughput for high-volume event ingestion\n\"\"\"\n\nimport json\nimport logging\nfrom datetime import datetime, timedelta, timezone\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional\n\nimport httpx\nfrom pydantic import Field, SecretStr, field_validator, model_validator\n\n# Import exceptions from centralized exceptions module\nfrom exceptions.auth import AuthenticationError\nfrom exceptions.delivery import DeliveryError\nfrom exceptions.integration import RateLimitError\n\n# Import base integration classes and models\nfrom .base import (\n    BaseIntegration,\n    EventSeverity,\n    IntegrationCredentials,\n    IntegrationEvent,\n    IntegrationResult,\n    IntegrationType,\n)\n\nlogger = logging.getLogger(__name__)\n\n\nclass AzureCloud(str, Enum):\n    \"\"\"Azure cloud environments\"\"\"\n\n    PUBLIC = \"public\"\n    GOVERNMENT = \"government\"\n    CHINA = \"china\"\n    GERMANY = \"germany\"\n\n\n# Azure AD endpoints by cloud environment\nAZURE_AD_ENDPOINTS: Dict[AzureCloud, str] = {\n    AzureCloud.PUBLIC: \"https://login.microsoftonline.com\",\n    AzureCloud.GOVERNMENT: \"https://login.microsoftonline.us\",\n    AzureCloud.CHINA: \"https://login.chinacloudapi.cn\",\n    AzureCloud.GERMANY: \"https://login.microsoftonline.de\",\n}\n\n# Azure Monitor scopes by cloud environment\nAZURE_MONITOR_SCOPES: Dict[AzureCloud, str] = {\n    AzureCloud.PUBLIC: \"https://monitor.azure.com/.default\",\n    AzureCloud.GOVERNMENT: \"https://monitor.azure.us/.default\",\n    AzureCloud.CHINA: \"https://monitor.azure.cn/.default\",\n    AzureCloud.GERMANY: \"https://monitor.azure.com/.default\",\n}\n\n\nclass SentinelCredentials(IntegrationCredentials):\n    \"\"\"\n    Credentials for Microsoft Sentinel integration using Azure Monitor Ingestion.\n\n    Requires a Service Principal with the following permissions:\n    - Monitoring Metrics Publisher role on the Data Collection Rule\n    - Access to the Log Analytics workspace\n\n    Prerequisites:\n    - Data Collection Endpoint (DCE) must be created\n    - Data Collection Rule (DCR) must be configured with the custom table schema\n    - Custom table must exist in Log Analytics workspace\n    \"\"\"\n\n    integration_type: IntegrationType = Field(\n        default=IntegrationType.SIEM,\n        description=\"Integration type (always SIEM for Sentinel)\",\n    )\n\n    # Azure AD / Service Principal credentials\n    tenant_id: str = Field(\n        ...,\n        description=\"Azure AD tenant ID (GUID)\",\n    )\n    client_id: str = Field(\n        ...,\n        description=\"Service Principal application (client) ID\",\n    )\n    client_secret: SecretStr = Field(\n        ...,\n        description=\"Service Principal client secret\",\n    )\n\n    # Data Collection Endpoint (DCE)\n    dce_endpoint: str = Field(\n        ...,\n        description=\"Data Collection Endpoint URL (e.g., https://<name>.<region>.ingest.monitor.azure.com)\",\n    )\n\n    # Data Collection Rule (DCR)\n    dcr_immutable_id: str = Field(\n        ...,\n        description=\"Data Collection Rule immutable ID (e.g., dcr-xxxxxxxx)\",\n    )\n\n    # Log Analytics settings\n    stream_name: str = Field(\n        default=\"Custom-GovernanceEvents_CL\",\n        description=\"Stream name matching DCR schema (Custom-<name>_CL format)\",\n    )\n\n    # Azure cloud settings\n    azure_cloud: AzureCloud = Field(\n        default=AzureCloud.PUBLIC,\n        description=\"Azure cloud environment\",\n    )\n\n    # Performance settings\n    batch_size: int = Field(\n        default=100,\n        ge=1,\n        le=500,\n        description=\"Maximum events per batch submission (Azure limit: 500)\",\n    )\n    batch_timeout_seconds: float = Field(\n        default=5.0,\n        ge=0.1,\n        le=60.0,\n        description=\"Maximum seconds to wait before sending incomplete batch\",\n    )\n    max_batch_size_bytes: int = Field(\n        default=1_000_000,\n        ge=1000,\n        le=1_000_000,\n        description=\"Maximum batch size in bytes (Azure limit: 1MB)\",\n    )\n\n    @field_validator(\"tenant_id\", \"client_id\")\n    @classmethod\n    def validate_guid_format(cls, v: str) -> str:\n        \"\"\"Validate GUID format for Azure IDs\"\"\"\n        if not v:\n            raise ValueError(\"Value is required\")\n        # Basic GUID format check (8-4-4-4-12)\n        v = v.strip().lower()\n        if len(v) == 36 and v.count(\"-\") == 4:\n            parts = v.split(\"-\")\n            if [len(p) for p in parts] == [8, 4, 4, 4, 12]:\n                try:\n                    int(v.replace(\"-\", \"\"), 16)\n                    return v\n                except ValueError:\n                    pass\n        # Also accept 32-char hex without dashes\n        if len(v) == 32:\n            try:\n                int(v, 16)\n                return f\"{v[:8]}-{v[8:12]}-{v[12:16]}-{v[16:20]}-{v[20:]}\"\n            except ValueError:\n                pass\n        raise ValueError(f\"Invalid GUID format: {v}\")\n\n    @field_validator(\"dce_endpoint\")\n    @classmethod\n    def validate_dce_endpoint(cls, v: str) -> str:\n        \"\"\"Validate DCE endpoint URL format\"\"\"\n        if not v:\n            raise ValueError(\"DCE endpoint is required\")\n        if not v.startswith(\"https://\"):\n            raise ValueError(\"DCE endpoint must use HTTPS\")\n        if \".ingest.monitor.azure\" not in v:\n            raise ValueError(\"DCE endpoint must be an Azure Monitor ingestion endpoint\")\n        return v.rstrip(\"/\")\n\n    @field_validator(\"dcr_immutable_id\")\n    @classmethod\n    def validate_dcr_id(cls, v: str) -> str:\n        \"\"\"Validate DCR immutable ID format\"\"\"\n        if not v:\n            raise ValueError(\"DCR immutable ID is required\")\n        # DCR IDs typically start with \"dcr-\" but can vary\n        return v.strip()\n\n    @field_validator(\"stream_name\")\n    @classmethod\n    def validate_stream_name(cls, v: str) -> str:\n        \"\"\"Validate stream name format\"\"\"\n        if not v:\n            raise ValueError(\"Stream name is required\")\n        # Custom tables should have Custom- prefix and _CL suffix\n        if not v.startswith(\"Custom-\") and not v.endswith(\"_CL\"):\n            logger.warning(\n                f\"Stream name '{v}' may not follow Azure custom table naming convention \"\n                \"(expected Custom-<name>_CL format)\"\n            )\n        return v\n\n    @model_validator(mode=\"after\")\n    def validate_cloud_endpoint_match(self) -> \"SentinelCredentials\":\n        \"\"\"Validate that DCE endpoint matches the selected Azure cloud\"\"\"\n        endpoint_patterns = {\n            AzureCloud.PUBLIC: \".ingest.monitor.azure.com\",\n            AzureCloud.GOVERNMENT: \".ingest.monitor.azure.us\",\n            AzureCloud.CHINA: \".ingest.monitor.azure.cn\",\n            AzureCloud.GERMANY: \".ingest.monitor.azure.de\",\n        }\n        expected_pattern = endpoint_patterns.get(self.azure_cloud)\n        if expected_pattern and expected_pattern not in self.dce_endpoint:\n            logger.warning(\n                f\"DCE endpoint '{self.dce_endpoint}' may not match the selected \"\n                f\"Azure cloud '{self.azure_cloud.value}' (expected pattern: {expected_pattern})\"\n            )\n        return self\n\n\nclass SentinelAdapter(BaseIntegration):\n    \"\"\"\n    Microsoft Sentinel SIEM integration adapter using Azure Monitor Ingestion API.\n\n    This adapter sends governance events to Microsoft Sentinel via the Logs Ingestion\n    API, supporting both single event submission and high-performance batch processing.\n    Implements native Azure Monitor batch format (JSON array) for optimal throughput\n    while respecting Azure service limits.\n\n    Single Event Usage:\n        credentials = SentinelCredentials(\n            integration_name=\"Production Sentinel\",\n            tenant_id=\"your-tenant-id\",\n            client_id=\"your-client-id\",\n            client_secret=SecretStr(\"your-client-secret\"),\n            dce_endpoint=\"https://dce-name.region.ingest.monitor.azure.com\",\n            dcr_immutable_id=\"dcr-xxxxxxxx\",\n        )\n        adapter = SentinelAdapter(credentials)\n        await adapter.authenticate()\n        result = await adapter.send_event(event)\n\n    Batch Processing Usage:\n        # Send multiple events in a single API call\n        events = [event1, event2, event3]\n        results = await adapter.send_events_batch(events)\n\n        # Check batch metrics\n        metrics = adapter.metrics\n        print(f\"Batches sent: {metrics['batches_sent']}\")\n        print(f\"Events via batch: {metrics['batch_events_total']}\")\n\n    Features:\n        - Azure AD OAuth2 authentication with automatic token refresh\n        - Native Azure Monitor batch processing (JSON array format)\n        - All-or-nothing batch semantics for data consistency\n        - Azure service limits enforcement (1MB max, 500 records max)\n        - Rate limit handling with Retry-After header support\n        - DCR/DCE validation\n        - Comprehensive error reporting with Azure-specific error codes\n        - Multi-cloud support (public, government, china, germany)\n        - Configurable batch size (default 100, max 500)\n        - Automatic retry with exponential backoff\n\n    Batch Performance:\n        - Reduces API calls by batch_size factor (e.g., 100x for batch_size=100)\n        - Lower authentication overhead (one token refresh check per batch)\n        - Improved throughput for high-volume event ingestion\n        - Maintains event order within batches\n\n    Azure Limits:\n        - Maximum 500 records per batch\n        - Maximum 1MB (1,000,000 bytes) payload size per batch\n        - Batches exceeding limits will log warnings\n\n    Note:\n        This adapter overrides _do_send_events_batch() to provide native Azure\n        Monitor batch support. The base class handles authentication, retry logic,\n        and metrics tracking.\n    \"\"\"\n\n    # Azure Monitor Ingestion API path\n    INGESTION_API_PATH = \"/dataCollectionRules/{dcr_id}/streams/{stream_name}\"\n    INGESTION_API_VERSION = \"2023-01-01\"\n\n    # Severity mapping from ACGS-2 to Sentinel severity levels\n    # Using numeric severity for Log Analytics (1=Critical, 5=Info)\n    SEVERITY_MAP: Dict[EventSeverity, int] = {\n        EventSeverity.CRITICAL: 1,\n        EventSeverity.HIGH: 2,\n        EventSeverity.MEDIUM: 3,\n        EventSeverity.LOW: 4,\n        EventSeverity.INFO: 5,\n    }\n\n    # Severity name mapping for Sentinel\n    SEVERITY_NAME_MAP: Dict[EventSeverity, str] = {\n        EventSeverity.CRITICAL: \"Critical\",\n        EventSeverity.HIGH: \"High\",\n        EventSeverity.MEDIUM: \"Medium\",\n        EventSeverity.LOW: \"Low\",\n        EventSeverity.INFO: \"Informational\",\n    }\n\n    def __init__(\n        self,\n        credentials: SentinelCredentials,\n        max_retries: int = BaseIntegration.DEFAULT_MAX_RETRIES,\n        timeout: float = BaseIntegration.DEFAULT_TIMEOUT,\n    ):\n        \"\"\"\n        Initialize Sentinel adapter.\n\n        Args:\n            credentials: Sentinel credentials and configuration\n            max_retries: Maximum retry attempts for failed operations\n            timeout: HTTP request timeout in seconds\n        \"\"\"\n        super().__init__(credentials, max_retries, timeout)\n        self._sentinel_credentials = credentials\n        self._access_token: Optional[str] = None\n        self._token_expires_at: Optional[datetime] = None\n        self._event_batch: List[Dict[str, Any]] = []\n        self._batch_start_time: Optional[datetime] = None\n\n    @property\n    def sentinel_credentials(self) -> SentinelCredentials:\n        \"\"\"Get typed Sentinel credentials\"\"\"\n        return self._sentinel_credentials\n\n    def _get_azure_ad_endpoint(self) -> str:\n        \"\"\"Get Azure AD endpoint for the configured cloud\"\"\"\n        return AZURE_AD_ENDPOINTS.get(\n            self.sentinel_credentials.azure_cloud,\n            AZURE_AD_ENDPOINTS[AzureCloud.PUBLIC],\n        )\n\n    def _get_monitor_scope(self) -> str:\n        \"\"\"Get Azure Monitor scope for the configured cloud\"\"\"\n        return AZURE_MONITOR_SCOPES.get(\n            self.sentinel_credentials.azure_cloud,\n            AZURE_MONITOR_SCOPES[AzureCloud.PUBLIC],\n        )\n\n    def _is_token_valid(self) -> bool:\n        \"\"\"Check if the current access token is still valid\"\"\"\n        if not self._access_token or not self._token_expires_at:\n            return False\n        # Consider token expired 5 minutes before actual expiration\n        buffer = timedelta(minutes=5)\n        return datetime.now(timezone.utc) < (self._token_expires_at - buffer)\n\n    async def _get_access_token(self) -> str:\n        \"\"\"\n        Get a valid access token, refreshing if necessary.\n\n        Returns:\n            Valid access token string\n\n        Raises:\n            AuthenticationError: If token acquisition fails\n        \"\"\"\n        if self._is_token_valid():\n            return self._access_token\n\n        logger.debug(\"Acquiring new Azure AD access token\")\n\n        try:\n            client = await self.get_http_client()\n\n            # Build token request\n            token_url = (\n                f\"{self._get_azure_ad_endpoint()}/{self.sentinel_credentials.tenant_id}\"\n                \"/oauth2/v2.0/token\"\n            )\n\n            token_data = {\n                \"grant_type\": \"client_credentials\",\n                \"client_id\": self.sentinel_credentials.client_id,\n                \"client_secret\": self.sentinel_credentials.client_secret.get_secret_value(),\n                \"scope\": self._get_monitor_scope(),\n            }\n\n            response = await client.post(\n                token_url,\n                data=token_data,\n                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            )\n\n            if response.status_code == 200:\n                token_response = response.json()\n                self._access_token = token_response[\"access_token\"]\n                expires_in = token_response.get(\"expires_in\", 3600)\n                self._token_expires_at = datetime.now(timezone.utc) + timedelta(seconds=expires_in)\n                logger.debug(\n                    f\"Acquired access token, expires at {self._token_expires_at.isoformat()}\"\n                )\n                return self._access_token\n\n            elif response.status_code == 400:\n                error_data = response.json()\n                error_desc = error_data.get(\"error_description\", \"Invalid request\")\n                raise AuthenticationError(\n                    f\"Token request failed: {error_desc}\",\n                    self.name,\n                    details={\"azure_error\": error_data.get(\"error\")},\n                )\n\n            elif response.status_code == 401:\n                error_data = response.json()\n                error_desc = error_data.get(\"error_description\", \"Authentication failed\")\n                raise AuthenticationError(\n                    f\"Invalid credentials: {error_desc}\",\n                    self.name,\n                    details={\"azure_error\": error_data.get(\"error\")},\n                )\n\n            else:\n                raise AuthenticationError(\n                    f\"Unexpected token response: HTTP {response.status_code}\",\n                    self.name,\n                    details={\"status_code\": response.status_code},\n                )\n\n        except httpx.TimeoutException as e:\n            raise AuthenticationError(\n                f\"Token request timed out: {str(e)}\",\n                self.name,\n            ) from e\n\n        except httpx.NetworkError as e:\n            raise AuthenticationError(\n                f\"Network error during token request: {str(e)}\",\n                self.name,\n            ) from e\n\n    def _get_ingestion_headers(self, access_token: str) -> Dict[str, str]:\n        \"\"\"Get headers for ingestion API requests\"\"\"\n        return {\n            \"Authorization\": f\"Bearer {access_token}\",\n            \"Content-Type\": \"application/json\",\n            \"x-ms-client-request-id\": self.credentials.integration_id,\n        }\n\n    def _get_ingestion_url(self) -> str:\n        \"\"\"Build the full ingestion API URL\"\"\"\n        path = self.INGESTION_API_PATH.format(\n            dcr_id=self.sentinel_credentials.dcr_immutable_id,\n            stream_name=self.sentinel_credentials.stream_name,\n        )\n        return (\n            f\"{self.sentinel_credentials.dce_endpoint}\"\n            f\"{path}?api-version={self.INGESTION_API_VERSION}\"\n        )\n\n    async def _do_authenticate(self) -> IntegrationResult:\n        \"\"\"\n        Authenticate with Azure AD to obtain access token.\n\n        Verifies the Service Principal credentials are valid by acquiring\n        an access token from Azure AD.\n\n        Returns:\n            IntegrationResult indicating authentication success/failure\n        \"\"\"\n        logger.debug(f\"Authenticating with Azure AD for '{self.name}'\")\n\n        try:\n            # Try to get an access token - this validates credentials\n            access_token = await self._get_access_token()\n\n            if access_token:\n                logger.info(f\"Sentinel authentication successful for '{self.name}'\")\n                return IntegrationResult(\n                    success=True,\n                    integration_name=self.name,\n                    operation=\"authenticate\",\n                )\n\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"authenticate\",\n                error_code=\"NO_TOKEN\",\n                error_message=\"Failed to acquire access token\",\n            )\n\n        except AuthenticationError as e:\n            logger.error(f\"Sentinel authentication failed: {e.message}\")\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"authenticate\",\n                error_code=\"AUTH_FAILED\",\n                error_message=e.message,\n                error_details=e.details,\n            )\n\n        except Exception as e:\n            error_msg = f\"Unexpected error during authentication: {str(e)}\"\n            logger.error(f\"Sentinel authentication error: {error_msg}\")\n            raise AuthenticationError(error_msg, self.name) from e\n\n    async def _do_validate(self) -> IntegrationResult:\n        \"\"\"\n        Validate Sentinel configuration and prerequisites.\n\n        Checks:\n        - Azure AD token can be acquired\n        - DCE endpoint is accessible\n        - DCR exists and is accessible\n        - Stream name is valid\n\n        Returns:\n            IntegrationResult with validation status and any issues found\n        \"\"\"\n        logger.debug(f\"Validating Sentinel integration '{self.name}'\")\n\n        validation_issues: List[str] = []\n\n        try:\n            # Test 1: Verify we can get an access token\n            try:\n                access_token = await self._get_access_token()\n            except AuthenticationError as e:\n                validation_issues.append(f\"Authentication failed: {e.message}\")\n                return IntegrationResult(\n                    success=False,\n                    integration_name=self.name,\n                    operation=\"validate\",\n                    error_code=\"AUTH_FAILED\",\n                    error_message=\"; \".join(validation_issues),\n                    error_details={\"issues\": validation_issues},\n                )\n\n            client = await self.get_http_client()\n\n            # Test 2: Send a test event to validate DCR/DCE configuration\n            test_event = {\n                \"TimeGenerated\": datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n                \"EventType\": \"validation_test\",\n                \"Message\": \"ACGS-2 integration validation test\",\n                \"Severity\": \"Informational\",\n                \"SeverityLevel\": 5,\n                \"Source\": \"acgs2\",\n            }\n\n            ingestion_url = self._get_ingestion_url()\n\n            response = await client.post(\n                ingestion_url,\n                headers=self._get_ingestion_headers(access_token),\n                json=[test_event],  # Azure Monitor expects array\n            )\n\n            if response.status_code in (200, 204):\n                logger.info(f\"Sentinel validation successful for '{self.name}'\")\n                return IntegrationResult(\n                    success=True,\n                    integration_name=self.name,\n                    operation=\"validate\",\n                )\n\n            elif response.status_code == 400:\n                # Parse Azure error response\n                try:\n                    error_data = response.json()\n                    error_msg = error_data.get(\"error\", {}).get(\"message\", \"Bad request\")\n                except json.JSONDecodeError:\n                    error_msg = response.text or \"Bad request\"\n                validation_issues.append(f\"Invalid request: {error_msg}\")\n\n            elif response.status_code == 401:\n                validation_issues.append(\"Authentication failed - token may be invalid\")\n\n            elif response.status_code == 403:\n                validation_issues.append(\n                    \"Access denied - Service Principal may lack Monitoring Metrics Publisher role\"\n                )\n\n            elif response.status_code == 404:\n                dcr_id = self.sentinel_credentials.dcr_immutable_id\n                stream = self.sentinel_credentials.stream_name\n                validation_issues.append(\n                    f\"DCR or stream not found - verify DCR ID '{dcr_id}' \"\n                    f\"and stream name '{stream}'\"\n                )\n\n            elif response.status_code == 413:\n                validation_issues.append(\"Payload too large (exceeded 1MB limit)\")\n\n            elif response.status_code == 429:\n                validation_issues.append(\"Rate limited - too many requests\")\n\n            elif response.status_code == 503:\n                validation_issues.append(\"Azure Monitor service temporarily unavailable\")\n\n            else:\n                validation_issues.append(f\"Unexpected response: HTTP {response.status_code}\")\n\n        except httpx.TimeoutException:\n            validation_issues.append(\"Connection timed out\")\n\n        except httpx.NetworkError as e:\n            validation_issues.append(f\"Network error: {str(e)}\")\n\n        except Exception as e:\n            validation_issues.append(f\"Validation error: {str(e)}\")\n\n        if validation_issues:\n            error_msg = \"; \".join(validation_issues)\n            logger.warning(f\"Sentinel validation failed for '{self.name}': {error_msg}\")\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"validate\",\n                error_code=\"VALIDATION_FAILED\",\n                error_message=error_msg,\n                error_details={\"issues\": validation_issues},\n            )\n\n        return IntegrationResult(\n            success=True,\n            integration_name=self.name,\n            operation=\"validate\",\n        )\n\n    async def _do_send_event(self, event: IntegrationEvent) -> IntegrationResult:\n        \"\"\"\n        Send a governance event to Microsoft Sentinel.\n\n        Formats the event for Azure Monitor Logs Ingestion API and submits it.\n        Handles rate limiting, retries, and provides detailed error reporting.\n\n        Args:\n            event: The governance event to send\n\n        Returns:\n            IntegrationResult with delivery status\n\n        Raises:\n            DeliveryError: If delivery fails after retries\n            RateLimitError: If rate limited by Azure\n        \"\"\"\n        logger.debug(f\"Sending event {event.event_id} to Sentinel\")\n\n        try:\n            # Ensure we have a valid token\n            access_token = await self._get_access_token()\n\n            client = await self.get_http_client()\n\n            # Format event for Azure Monitor\n            sentinel_event = self._format_event_for_sentinel(event)\n\n            ingestion_url = self._get_ingestion_url()\n\n            response = await client.post(\n                ingestion_url,\n                headers=self._get_ingestion_headers(access_token),\n                json=[sentinel_event],  # Azure Monitor expects array\n            )\n\n            # Handle rate limiting\n            if response.status_code == 429:\n                retry_after = int(response.headers.get(\"Retry-After\", 60))\n                raise RateLimitError(\n                    \"Azure Monitor rate limit exceeded\",\n                    self.name,\n                    retry_after=retry_after,\n                )\n\n            # Handle success (200 or 204)\n            if response.status_code in (200, 204):\n                logger.debug(f\"Event {event.event_id} sent to Sentinel\")\n                return IntegrationResult(\n                    success=True,\n                    integration_name=self.name,\n                    operation=\"send_event\",\n                    external_id=event.event_id,\n                    external_url=self._build_log_analytics_url(event),\n                )\n\n            # Handle errors\n            if response.status_code == 400:\n                try:\n                    error_data = response.json()\n                    error_msg = error_data.get(\"error\", {}).get(\"message\", \"Bad request\")\n                except json.JSONDecodeError:\n                    error_msg = \"Invalid event format\"\n                raise DeliveryError(\n                    f\"Invalid event data: {error_msg}\",\n                    self.name,\n                    details={\"status_code\": 400},\n                )\n\n            elif response.status_code == 401:\n                # Token may have expired - clear it and retry will refresh\n                self._access_token = None\n                self._token_expires_at = None\n                raise AuthenticationError(\n                    \"Access token expired or invalid\",\n                    self.name,\n                )\n\n            elif response.status_code == 403:\n                raise DeliveryError(\n                    \"Access denied - Service Principal lacks required permissions\",\n                    self.name,\n                    details={\"status_code\": 403},\n                )\n\n            elif response.status_code == 404:\n                raise DeliveryError(\n                    f\"DCR or stream not found: {self.sentinel_credentials.dcr_immutable_id}\",\n                    self.name,\n                    details={\"status_code\": 404},\n                )\n\n            elif response.status_code == 413:\n                raise DeliveryError(\n                    \"Event payload too large (exceeded 1MB limit)\",\n                    self.name,\n                    details={\"status_code\": 413},\n                )\n\n            elif response.status_code == 503:\n                raise DeliveryError(\n                    \"Azure Monitor service temporarily unavailable\",\n                    self.name,\n                    details={\"status_code\": 503, \"should_retry\": True},\n                )\n\n            else:\n                raise DeliveryError(\n                    f\"Unexpected response: HTTP {response.status_code}\",\n                    self.name,\n                    details={\"status_code\": response.status_code},\n                )\n\n        except (RateLimitError, AuthenticationError):\n            # Re-raise these specific exceptions\n            raise\n\n        except DeliveryError:\n            # Re-raise delivery errors\n            raise\n\n        except httpx.TimeoutException as e:\n            raise DeliveryError(\n                f\"Request timed out: {str(e)}\",\n                self.name,\n                details={\"should_retry\": True},\n            ) from e\n\n        except httpx.NetworkError as e:\n            raise DeliveryError(\n                f\"Network error: {str(e)}\",\n                self.name,\n                details={\"should_retry\": True},\n            ) from e\n\n        except Exception as e:\n            raise DeliveryError(\n                f\"Unexpected error: {str(e)}\",\n                self.name,\n            ) from e\n\n    def _format_event_for_sentinel(self, event: IntegrationEvent) -> Dict[str, Any]:\n        \"\"\"\n        Format an IntegrationEvent for Azure Monitor Logs Ingestion.\n\n        Converts the governance event to Azure Monitor's expected format with\n        proper field mapping, severity translation, and metadata.\n\n        Args:\n            event: The governance event to format\n\n        Returns:\n            Dictionary formatted for Azure Monitor Logs Ingestion\n        \"\"\"\n        # TimeGenerated is required by Azure Monitor and must be ISO 8601 format\n        sentinel_event = {\n            # Required field - must be ISO 8601 format\n            \"TimeGenerated\": event.timestamp.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n            # Core event fields\n            \"EventId\": event.event_id,\n            \"EventType\": event.event_type,\n            \"Severity\": self.SEVERITY_NAME_MAP.get(event.severity, \"Informational\"),\n            \"SeverityLevel\": self.SEVERITY_MAP.get(event.severity, 5),\n            \"Source\": event.source,\n            # Content\n            \"Title\": event.title,\n            \"Description\": event.description or \"\",\n            # Context\n            \"PolicyId\": event.policy_id or \"\",\n            \"ResourceId\": event.resource_id or \"\",\n            \"ResourceType\": event.resource_type or \"\",\n            \"Action\": event.action or \"\",\n            \"Outcome\": event.outcome or \"\",\n            # Metadata\n            \"UserId\": event.user_id or \"\",\n            \"TenantId\": event.tenant_id or \"\",\n            \"CorrelationId\": event.correlation_id or \"\",\n            \"Tags\": json.dumps(event.tags) if event.tags else \"[]\",\n            # Additional details as JSON\n            \"Details\": json.dumps(event.details) if event.details else \"{}\",\n        }\n\n        return sentinel_event\n\n    def _build_log_analytics_url(self, event: IntegrationEvent) -> Optional[str]:\n        \"\"\"\n        Build a URL to view the event in Log Analytics (if possible).\n\n        Note: This is a best-effort URL that may not work depending on user permissions.\n        Cannot reliably construct without workspace ID.\n        \"\"\"\n        # Log Analytics query URL format requires workspace ID which we don't have\n        # Would be: {stream_name} | where EventId == \"{event_id}\"\n        _ = event  # Reference event to avoid unused parameter warning\n        return None\n\n    async def _do_send_events_batch(\n        self,\n        events: List[IntegrationEvent],\n    ) -> List[IntegrationResult]:\n        \"\"\"\n        Send multiple events to Sentinel in a batch using Azure Monitor Ingestion API.\n\n        Implements Sentinel-specific batch delivery using Azure Monitor's native JSON\n        array format. This is the recommended way to send multiple events for optimal\n        performance and compliance with Azure service limits.\n\n        Batch Format:\n            Events are sent as a JSON array to the Azure Monitor Ingestion API:\n            [\n              {\"TimeGenerated\": \"...\", \"EventId\": \"...\", ...},\n              {\"TimeGenerated\": \"...\", \"EventId\": \"...\", ...},\n              {\"TimeGenerated\": \"...\", \"EventId\": \"...\", ...}\n            ]\n\n        Batch Semantics:\n            All-or-nothing: If Azure Monitor accepts the batch (HTTP 200/204),\n            all events are considered successfully ingested. If the batch fails,\n            all events are marked as failed. There is no partial success in Azure\n            Monitor batch processing.\n\n        Azure Service Limits:\n            - Maximum 500 records per batch (enforced by Azure)\n            - Maximum 1MB (1,000,000 bytes) payload size (enforced by Azure)\n            - Exceeding limits results in HTTP 413 error\n            - Batch size is configurable via credentials.batch_size (default 100)\n\n        Performance:\n            - Sends all events in a single HTTP POST request\n            - Reduces OAuth token refresh checks (one per batch vs N per event)\n            - Significantly lower latency for multiple events\n            - Better throughput for high-volume ingestion\n\n        Args:\n            events: List of governance events to send (recommended: 10-100 events,\n                   max: 500 events per Azure limits)\n\n        Returns:\n            List of IntegrationResults, one per event. All will have same success\n            status due to all-or-nothing semantics.\n\n        Raises:\n            RateLimitError: If rate limited by Azure Monitor (HTTP 429)\n            DeliveryError: If batch delivery fails (invalid data, permissions, size limits, etc.)\n            AuthenticationError: If access token is invalid or expired (HTTP 401)\n\n        Note:\n            This method is called by BaseIntegration.send_events_batch() which\n            handles authentication checks, retry logic, and metrics tracking.\n            Do not call this method directly.\n\n        See Also:\n            - BaseIntegration.send_events_batch() - Public batch API\n            - BaseIntegration._do_send_events_batch() - Default implementation\n            - Azure Monitor Ingestion API limits: https://learn.microsoft.com/en-us/azure/azure-monitor/logs/logs-ingestion-api-overview\n        \"\"\"\n        if not events:\n            return []\n\n        logger.debug(f\"Sending batch of {len(events)} events to Sentinel\")\n\n        try:\n            # Ensure we have a valid token\n            access_token = await self._get_access_token()\n            client = await self.get_http_client()\n\n            # Format all events for Sentinel\n            sentinel_events = [self._format_event_for_sentinel(e) for e in events]\n\n            # Check batch size limits\n            batch_json = json.dumps(sentinel_events)\n            if len(batch_json.encode(\"utf-8\")) > self.sentinel_credentials.max_batch_size_bytes:\n                logger.warning(\n                    f\"Batch size exceeds {self.sentinel_credentials.max_batch_size_bytes} bytes, \"\n                    \"consider reducing batch_size\"\n                )\n\n            ingestion_url = self._get_ingestion_url()\n\n            response = await client.post(\n                ingestion_url,\n                headers=self._get_ingestion_headers(access_token),\n                json=sentinel_events,\n            )\n\n            # Handle rate limiting\n            if response.status_code == 429:\n                retry_after = int(response.headers.get(\"Retry-After\", 60))\n                raise RateLimitError(\n                    \"Azure Monitor rate limit exceeded\",\n                    self.name,\n                    retry_after=retry_after,\n                )\n\n            # Handle success (200 or 204)\n            if response.status_code in (200, 204):\n                # All events succeeded\n                logger.debug(f\"Batch of {len(events)} events sent to Sentinel successfully\")\n                return [\n                    IntegrationResult(\n                        success=True,\n                        integration_name=self.name,\n                        operation=\"send_event\",\n                        external_id=event.event_id,\n                    )\n                    for event in events\n                ]\n\n            # Handle errors\n            if response.status_code == 400:\n                # Parse Azure error response\n                try:\n                    error_data = response.json()\n                    error_msg = error_data.get(\"error\", {}).get(\"message\", \"Bad request\")\n                except json.JSONDecodeError:\n                    error_msg = \"Invalid batch data format\"\n                raise DeliveryError(\n                    f\"Invalid batch data: {error_msg}\",\n                    self.name,\n                    details={\"status_code\": 400},\n                )\n\n            elif response.status_code == 401:\n                # Token may have expired - clear it and retry will refresh\n                self._access_token = None\n                self._token_expires_at = None\n                raise AuthenticationError(\n                    \"Access token expired or invalid\",\n                    self.name,\n                )\n\n            elif response.status_code == 403:\n                raise DeliveryError(\n                    \"Access denied - Service Principal lacks required permissions\",\n                    self.name,\n                    details={\"status_code\": 403},\n                )\n\n            elif response.status_code == 404:\n                raise DeliveryError(\n                    f\"DCR or stream not found: {self.sentinel_credentials.dcr_immutable_id}\",\n                    self.name,\n                    details={\"status_code\": 404},\n                )\n\n            elif response.status_code == 413:\n                raise DeliveryError(\n                    \"Batch payload too large (exceeded 1MB limit)\",\n                    self.name,\n                    details={\"status_code\": 413},\n                )\n\n            elif response.status_code == 503:\n                raise DeliveryError(\n                    \"Azure Monitor service temporarily unavailable\",\n                    self.name,\n                    details={\"status_code\": 503, \"should_retry\": True},\n                )\n\n            else:\n                # Unexpected error\n                try:\n                    error_data = response.json()\n                    error_msg = error_data.get(\"error\", {}).get(\"message\", \"Batch delivery failed\")\n                except json.JSONDecodeError:\n                    error_msg = f\"Batch delivery failed: HTTP {response.status_code}\"\n                raise DeliveryError(\n                    error_msg,\n                    self.name,\n                    details={\"status_code\": response.status_code},\n                )\n\n        except (RateLimitError, AuthenticationError):\n            # Re-raise these specific exceptions\n            raise\n\n        except DeliveryError:\n            # Re-raise delivery errors\n            raise\n\n        except httpx.TimeoutException as e:\n            raise DeliveryError(\n                f\"Request timed out: {str(e)}\",\n                self.name,\n                details={\"should_retry\": True},\n            ) from e\n\n        except httpx.NetworkError as e:\n            raise DeliveryError(\n                f\"Network error: {str(e)}\",\n                self.name,\n                details={\"should_retry\": True},\n            ) from e\n\n        except Exception as e:\n            raise DeliveryError(\n                f\"Unexpected error: {str(e)}\",\n                self.name,\n            ) from e\n\n    async def _do_test_connection(self) -> IntegrationResult:\n        \"\"\"\n        Test connection to Azure AD and DCE endpoint.\n\n        Performs a lightweight check to verify connectivity without\n        authenticating or sending events.\n\n        Returns:\n            IntegrationResult indicating connection status\n        \"\"\"\n        logger.debug(f\"Testing Sentinel connection for '{self.name}'\")\n\n        try:\n            client = await self.get_http_client()\n\n            # Test Azure AD endpoint connectivity\n            tenant = self.sentinel_credentials.tenant_id\n            azure_ad_url = (\n                f\"{self._get_azure_ad_endpoint()}/{tenant}/.well-known/openid-configuration\"\n            )\n\n            try:\n                ad_response = await client.get(azure_ad_url)\n                if ad_response.status_code != 200:\n                    return IntegrationResult(\n                        success=False,\n                        integration_name=self.name,\n                        operation=\"test_connection\",\n                        error_code=\"AZURE_AD_ERROR\",\n                        error_message=f\"Azure AD returned status {ad_response.status_code}\",\n                    )\n            except Exception as e:\n                return IntegrationResult(\n                    success=False,\n                    integration_name=self.name,\n                    operation=\"test_connection\",\n                    error_code=\"AZURE_AD_UNREACHABLE\",\n                    error_message=f\"Cannot reach Azure AD: {str(e)}\",\n                )\n\n            # Test DCE endpoint connectivity (just a HEAD request)\n            # The actual endpoint may not respond to HEAD, so we accept various status codes\n            try:\n                dce_response = await client.head(\n                    self.sentinel_credentials.dce_endpoint,\n                    follow_redirects=True,\n                )\n                # Any response (even 400/401) indicates the endpoint is reachable\n                if dce_response.status_code < 500:\n                    return IntegrationResult(\n                        success=True,\n                        integration_name=self.name,\n                        operation=\"test_connection\",\n                    )\n                else:\n                    return IntegrationResult(\n                        success=False,\n                        integration_name=self.name,\n                        operation=\"test_connection\",\n                        error_code=f\"HTTP_{dce_response.status_code}\",\n                        error_message=f\"DCE server error: {dce_response.status_code}\",\n                    )\n            except Exception as e:\n                return IntegrationResult(\n                    success=False,\n                    integration_name=self.name,\n                    operation=\"test_connection\",\n                    error_code=\"DCE_UNREACHABLE\",\n                    error_message=f\"Cannot reach DCE endpoint: {str(e)}\",\n                )\n\n        except httpx.TimeoutException:\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=\"TIMEOUT\",\n                error_message=f\"Connection timed out after {self.timeout}s\",\n            )\n\n        except httpx.NetworkError as e:\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=\"NETWORK_ERROR\",\n                error_message=str(e),\n            )\n\n        except Exception as e:\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=\"UNKNOWN_ERROR\",\n                error_message=str(e),\n            )\n\n    async def close(self) -> None:\n        \"\"\"Close the integration and cleanup resources\"\"\"\n        self._access_token = None\n        self._token_expires_at = None\n        await super().close()\n",
        "timestamp": "2026-01-04T00:39:57.715547"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "037-add-batch-event-processing-to-baseintegration",
        "description": "Extend BaseIntegration with send_events_batch() method to efficiently send multiple events in a single API call where supported. Reduces API calls and improves throughput for high-volume governance event scenarios.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-04T00:39:57.749605",
  "last_updated": "2026-01-04T00:39:57.752317"
}