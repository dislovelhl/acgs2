{
  "file_path": "src/core/services/core/code-analysis/code_analysis_service/app/middleware/performance.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nACGS Code Analysis Engine - Performance Monitoring Middleware\nRequest timing, metrics collection, and P99 latency monitoring with constitutional compliance.\n\nConstitutional Hash: cdd01ef066bc6cf2\n\"\"\"\n\nimport logging\nimport re\nimport time\nimport uuid\nfrom collections import defaultdict, deque\nfrom typing import Any, Callable\n\nimport psutil\nfrom fastapi import Request, Response\nfrom prometheus_client import Counter, Gauge, Histogram\nfrom starlette.middleware.base import BaseHTTPMiddleware\n\nlogger = logging.getLogger(__name__)\n\n# Constitutional hash constant\nCONSTITUTIONAL_HASH = \"cdd01ef066bc6cf2\"\n\n# Prometheus metrics\nREQUEST_COUNT = Counter(\n    \"acgs_code_analysis_requests_total\",\n    \"Total number of requests\",\n    [\"method\", \"endpoint\", \"status_code\"],\n)\n\nREQUEST_DURATION = Histogram(\n    \"acgs_code_analysis_request_duration_seconds\",\n    \"Request duration in seconds\",\n    [\"method\", \"endpoint\"],\n)\n\nACTIVE_REQUESTS = Gauge(\n    \"acgs_code_analysis_active_requests\",\n    \"Number of active requests\",\n)\n\nCACHE_HITS = Counter(\n    \"acgs_code_analysis_cache_hits_total\",\n    \"Total number of cache hits\",\n    [\"cache_type\"],\n)\n\nCACHE_MISSES = Counter(\n    \"acgs_code_analysis_cache_misses_total\",\n    \"Total number of cache misses\",\n    [\"cache_type\"],\n)\n\nMEMORY_USAGE = Gauge(\n    \"acgs_code_analysis_memory_usage_bytes\",\n    \"Memory usage in bytes\",\n)\n\nCPU_USAGE = Gauge(\n    \"acgs_code_analysis_cpu_usage_percent\",\n    \"CPU usage percentage\",\n)\n\n\nclass PerformanceLogger:\n    \"\"\"Performance logging utility.\"\"\"\n\n    def start_operation(\n        self,\n        operation_id: str,\n        operation_type: str,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Start tracking an operation.\"\"\"\n        logger.debug(\n            f\"Starting {operation_type}: {operation_id}\",\n            extra={\"operation_id\": operation_id, **kwargs},\n        )\n\n    def end_operation(\n        self,\n        operation_id: str,\n        success: bool,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"End tracking an operation.\"\"\"\n        logger.debug(\n            f\"Completed operation: {operation_id} (success={success})\",\n            extra={\"operation_id\": operation_id, \"success\": success, **kwargs},\n        )\n\n    def log_cache_operation(\n        self,\n        operation: str,\n        cache_hit: bool,\n        key: str,\n        request_id: str,\n    ) -> None:\n        \"\"\"Log cache operation.\"\"\"\n        logger.debug(\n            f\"Cache {operation}: hit={cache_hit}\",\n            extra={\"key\": key, \"request_id\": request_id, \"cache_hit\": cache_hit},\n        )\n\n\nperformance_logger = PerformanceLogger()\n\n\nclass PerformanceMiddleware(BaseHTTPMiddleware):\n    \"\"\"Performance monitoring middleware for ACGS Code Analysis Engine.\n\n    Tracks request timing, resource usage, and constitutional compliance metrics.\n    \"\"\"\n\n    def __init__(\n        self,\n        app,\n        latency_target_ms: float = 10.0,\n        slow_request_threshold_ms: float = 100.0,\n        enable_detailed_metrics: bool = True,\n    ):\n        \"\"\"Initialize performance middleware.\n\n        Args:\n            app: FastAPI application\n            latency_target_ms: Target P99 latency in milliseconds\n            slow_request_threshold_ms: Threshold for slow request logging\n            enable_detailed_metrics: Whether to collect detailed metrics\n        \"\"\"\n        super().__init__(app)\n        self.latency_target_ms = latency_target_ms\n        self.slow_request_threshold_ms = slow_request_threshold_ms\n        self.enable_detailed_metrics = enable_detailed_metrics\n\n        # Performance tracking\n        self.request_times: dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))\n        self.active_requests: dict[str, float] = {}\n\n        # Resource monitoring\n        self.process = psutil.Process()\n\n        logger.info(\n            \"Performance middleware initialized\",\n            extra={\n                \"latency_target_ms\": latency_target_ms,\n                \"slow_request_threshold_ms\": slow_request_threshold_ms,\n                \"constitutional_hash\": CONSTITUTIONAL_HASH,\n            },\n        )\n\n    async def dispatch(self, request: Request, call_next: Callable) -> Response:\n        \"\"\"Process request through performance middleware.\"\"\"\n        # Generate request ID for tracking\n        request_id = str(uuid.uuid4())\n        request.state.request_id = request_id\n\n        # Start timing\n        start_time = time.time()\n        start_cpu_time = time.process_time()\n\n        # Track active request\n        ACTIVE_REQUESTS.inc()\n        self.active_requests[request_id] = start_time\n\n        # Get initial resource usage\n        initial_memory = self.process.memory_info().rss if self.enable_detailed_metrics else 0\n\n        try:\n            # Log request start\n            performance_logger.start_operation(\n                operation_id=request_id,\n                operation_type=\"http_request\",\n                method=request.method,\n                path=request.url.path,\n                user_id=getattr(request.state, \"user_id\", None),\n            )\n\n            # Process request\n            response = await call_next(request)\n\n            # Calculate timing metrics\n            end_time = time.time()\n            end_cpu_time = time.process_time()\n            duration_seconds = end_time - start_time\n            duration_ms = duration_seconds * 1000\n            cpu_time_ms = (end_cpu_time - start_cpu_time) * 1000\n\n            # Update metrics\n            self._update_metrics(request, response, duration_seconds, duration_ms)\n\n            # Add performance headers\n            self._add_performance_headers(response, duration_ms, request_id)\n\n            # Log performance data\n            self._log_performance_data(\n                request, response, duration_ms, cpu_time_ms, initial_memory, request_id\n            )\n\n            # Check for performance violations\n            self._check_performance_violations(request, duration_ms)\n\n            return response\n\n        except Exception as e:\n            # Log error with performance context\n            duration_ms = (time.time() - start_time) * 1000\n\n            logger.error(\n                f\"Request failed with error: {e}\",\n                extra={\n                    \"request_id\": request_id,\n                    \"method\": request.method,\n                    \"path\": request.url.path,\n                    \"duration_ms\": round(duration_ms, 2),\n                    \"constitutional_hash\": CONSTITUTIONAL_HASH,\n                },\n                exc_info=True,\n            )\n\n            raise\n\n        finally:\n            # Clean up tracking\n            ACTIVE_REQUESTS.dec()\n            self.active_requests.pop(request_id, None)\n\n            # Update resource usage metrics\n            if self.enable_detailed_metrics:\n                self._update_resource_metrics()\n\n    def _update_metrics(\n        self,\n        request: Request,\n        response: Response,\n        duration_seconds: float,\n        duration_ms: float,\n    ) -> None:\n        \"\"\"Update Prometheus metrics.\"\"\"\n        method = request.method\n        endpoint = self._normalize_endpoint(request.url.path)\n        status_code = str(response.status_code)\n\n        # Update counters and histograms\n        REQUEST_COUNT.labels(method=method, endpoint=endpoint, status_code=status_code).inc()\n\n        REQUEST_DURATION.labels(method=method, endpoint=endpoint).observe(duration_seconds)\n\n        # Track request times for P99 calculation\n        self.request_times[endpoint].append(duration_ms)\n\n    def _add_performance_headers(\n        self, response: Response, duration_ms: float, request_id: str\n    ) -> None:\n        \"\"\"Add performance-related headers to response.\"\"\"\n        response.headers[\"X-Request-ID\"] = request_id\n        response.headers[\"X-Response-Time\"] = f\"{duration_ms:.3f}ms\"\n        response.headers[\"X-Constitutional-Hash\"] = CONSTITUTIONAL_HASH\n\n        # Add performance status\n        if duration_ms <= self.latency_target_ms:\n            response.headers[\"X-Performance-Status\"] = \"optimal\"\n        elif duration_ms <= self.slow_request_threshold_ms:\n            response.headers[\"X-Performance-Status\"] = \"acceptable\"\n        else:\n            response.headers[\"X-Performance-Status\"] = \"slow\"\n\n    def _log_performance_data(\n        self,\n        request: Request,\n        response: Response,\n        duration_ms: float,\n        cpu_time_ms: float,\n        initial_memory: int,\n        request_id: str,\n    ) -> None:\n        \"\"\"Log detailed performance data.\"\"\"\n        user_id = getattr(request.state, \"user_id\", None)\n\n        # Calculate memory usage if detailed metrics enabled\n        memory_delta = 0\n        if self.enable_detailed_metrics:\n            current_memory = self.process.memory_info().rss\n            memory_delta = current_memory - initial_memory\n\n        # Log performance completion\n        performance_logger.end_operation(\n            operation_id=request_id,\n            success=response.status_code < 400,\n            method=request.method,\n            path=request.url.path,\n            status_code=response.status_code,\n            cpu_time_ms=round(cpu_time_ms, 2),\n            memory_delta_bytes=memory_delta,\n            user_id=user_id,\n        )\n\n        # Log cache information if available\n        cache_hit = response.headers.get(\"X-Cache-Hit\", \"false\").lower() == \"true\"\n        if \"X-Cache-Hit\" in response.headers:\n            performance_logger.log_cache_operation(\n                operation=\"lookup\",\n                cache_hit=cache_hit,\n                key=f\"{request.method}:{request.url.path}\",\n                request_id=request_id,\n            )\n\n    def _check_performance_violations(self, request: Request, duration_ms: float) -> None:\n        \"\"\"Check for performance target violations.\"\"\"\n        if duration_ms > self.latency_target_ms:\n            logger.warning(\n                f\"Latency target violation: {duration_ms:.2f}ms > {self.latency_target_ms}ms\",\n                extra={\n                    \"method\": request.method,\n                    \"path\": request.url.path,\n                    \"duration_ms\": round(duration_ms, 2),\n                    \"target_ms\": self.latency_target_ms,\n                    \"violation_type\": \"latency_target\",\n                    \"constitutional_hash\": CONSTITUTIONAL_HASH,\n                },\n            )\n\n        if duration_ms > self.slow_request_threshold_ms:\n            logger.warning(\n                f\"Slow request detected: {duration_ms:.2f}ms\",\n                extra={\n                    \"method\": request.method,\n                    \"path\": request.url.path,\n                    \"duration_ms\": round(duration_ms, 2),\n                    \"threshold_ms\": self.slow_request_threshold_ms,\n                    \"violation_type\": \"slow_request\",\n                    \"constitutional_hash\": CONSTITUTIONAL_HASH,\n                },\n            )\n\n    def _update_resource_metrics(self) -> None:\n        \"\"\"Update system resource metrics.\"\"\"\n        try:\n            # Memory usage\n            memory_info = self.process.memory_info()\n            MEMORY_USAGE.set(memory_info.rss)\n\n            # CPU usage\n            cpu_percent = self.process.cpu_percent()\n            CPU_USAGE.set(cpu_percent)\n\n        except Exception as e:\n            logger.warning(\n                f\"Failed to update resource metrics: {e}\",\n                extra={\"constitutional_hash\": CONSTITUTIONAL_HASH},\n            )\n\n    def _normalize_endpoint(self, path: str) -> str:\n        \"\"\"Normalize endpoint path for metrics.\"\"\"\n        # Replace UUIDs\n        path = re.sub(\n            r\"/[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\",\n            \"/{uuid}\",\n            path,\n        )\n\n        # Replace numeric IDs\n        return re.sub(r\"/\\d+\", \"/{id}\", path)\n\n    async def get_performance_summary(self) -> dict[str, Any]:\n        \"\"\"Get current performance summary.\"\"\"\n        summary: dict[str, Any] = {\n            \"active_requests\": len(self.active_requests),\n            \"constitutional_hash\": CONSTITUTIONAL_HASH,\n            \"performance_targets\": {\n                \"latency_target_ms\": self.latency_target_ms,\n                \"slow_request_threshold_ms\": self.slow_request_threshold_ms,\n            },\n        }\n\n        # Calculate P99 latencies for each endpoint\n        if self.request_times:\n            p99_latencies: dict[str, float] = {}\n            for endpoint, times in self.request_times.items():\n                if times:\n                    sorted_times = sorted(times)\n                    p99_index = int(len(sorted_times) * 0.99)\n                    if p99_index < len(sorted_times):\n                        p99_latencies[endpoint] = sorted_times[p99_index]\n                    else:\n                        p99_latencies[endpoint] = sorted_times[-1]\n\n            summary[\"p99_latencies_ms\"] = p99_latencies\n\n        # Add resource usage if available\n        if self.enable_detailed_metrics:\n            try:\n                memory_info = self.process.memory_info()\n                summary[\"resource_usage\"] = {\n                    \"memory_rss_mb\": round(memory_info.rss / 1024 / 1024, 2),\n                    \"memory_vms_mb\": round(memory_info.vms / 1024 / 1024, 2),\n                    \"cpu_percent\": round(self.process.cpu_percent(), 2),\n                }\n            except Exception:\n                pass\n\n        return summary\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), src/core/breakthrough (79 occurrences), and src/core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.218591",
  "last_updated": "2026-01-04T05:35:59.087135"
}