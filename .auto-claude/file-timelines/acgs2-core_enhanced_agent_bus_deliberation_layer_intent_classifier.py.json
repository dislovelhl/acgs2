{
  "file_path": "acgs2-core/enhanced_agent_bus/deliberation_layer/intent_classifier.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nACGS-2 SDPC - Intent Classifier\nConstitutional Hash: cdd01ef066bc6cf2\n\nCategorizes user intent for dynamic routing and prompt compilation.\nImplements hybrid classification with LLM fallback for ambiguous cases.\n\"\"\"\n\nimport json\nimport logging\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Tuple\n\nimport litellm\n\nfrom ..config import BusConfiguration\n\n\nclass IntentType(Enum):\n    FACTUAL = \"factual\"  # High precision, requires GraphCheck & ASC\n    CREATIVE = \"creative\"  # High fluency, relaxed factual constraints\n    REASONING = \"reasoning\"  # Complex logic, triggers AMPO branching\n    GENERAL = \"general\"  # Default/conversational intent\n\n\nclass RoutingPath(Enum):\n    \"\"\"Enumeration of classification routing paths for hybrid classification.\"\"\"\n\n    RULE_BASED = \"rule_based\"  # Fast path using keyword heuristics\n    LLM = \"llm\"  # Slow path using LLM for ambiguous cases\n    LLM_FALLBACK = \"llm_fallback\"  # LLM failed, fell back to rule-based\n    EMPTY_INPUT = \"empty_input\"  # Empty/whitespace input, returned GENERAL\n\n\n@dataclass\nclass ClassificationResult:\n    \"\"\"Result of intent classification with routing metadata.\n\n    Provides detailed information about the classification decision,\n    including which routing path was used and timing information.\n    \"\"\"\n\n    intent: IntentType\n    confidence: float\n    routing_path: RoutingPath\n    latency_ms: float\n    rule_based_intent: Optional[IntentType] = None\n    rule_based_confidence: Optional[float] = None\n    llm_intent: Optional[IntentType] = None\n    llm_confidence: Optional[float] = None\n    llm_reasoning: Optional[str] = None\n    cached: bool = False\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary for logging/serialization.\"\"\"\n        return {\n            \"intent\": self.intent.value,\n            \"confidence\": self.confidence,\n            \"routing_path\": self.routing_path.value,\n            \"latency_ms\": round(self.latency_ms, 3),\n            \"rule_based_intent\": self.rule_based_intent.value if self.rule_based_intent else None,\n            \"rule_based_confidence\": self.rule_based_confidence,\n            \"llm_intent\": self.llm_intent.value if self.llm_intent else None,\n            \"llm_confidence\": self.llm_confidence,\n            \"llm_reasoning\": self.llm_reasoning,\n            \"cached\": self.cached,\n        }\n\n\nlogger = logging.getLogger(__name__)\n\n# LiteLLM availability flag\nLITELLM_AVAILABLE = False\n\n\n# Mock classes for test friendliness when LiteLLM is missing\nclass MockLiteLLMCache:\n    \"\"\"Mock cache class for when LiteLLM is not available.\"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -> None:\n        pass\n\n\nclass MockLiteLLM:\n    \"\"\"Mock LiteLLM module for when it's not available.\"\"\"\n\n    cache: Optional[Any] = None\n\n    @staticmethod\n    async def acompletion(*args: Any, **kwargs: Any) -> Dict[str, Any]:\n        \"\"\"Mock async completion that returns empty response.\"\"\"\n        return {\"choices\": [{\"message\": {\"content\": \"{}\"}}]}\n\n\n# Attempt to import LiteLLM\ntry:\n    import litellm\n    from litellm import Cache\n\n    LITELLM_AVAILABLE = True\nexcept ImportError:\n    litellm = MockLiteLLM()  # type: ignore[assignment]\n    Cache = MockLiteLLMCache  # type: ignore[assignment, misc]\n\n\nclass IntentClassifier:\n    \"\"\"Classifies user intent to determine optimal processing strategies.\"\"\"\n\n    def __init__(\n        self,\n        model_name: str = \"distilbert-base-uncased\",\n        config: Optional[BusConfiguration] = None\n    ):\n        self.model_name = model_name\n        self.config = config or BusConfiguration()\n        # In a real implementation, we would load a distilled LLM or BERT model here.\n        # For Phase 1, we use dynamic heuristic pattern matching with an LLM fallback hook.\n        logger.info(f\"IntentClassifier initialized with model: {model_name}\")\n\n    def classify(self, content: str) -> IntentType:\n        \"\"\"Determines the intent type of the provided content.\"\"\"\n        content_lower = content.lower()\n\n        # Heuristic Pattern Matching (Fast Path)\n        if any(\n            word in content_lower\n            for word in [\"calculate\", \"prove\", \"reason\", \"step by step\", \"analyze\"]\n        ):\n            return IntentType.REASONING\n\n        if any(\n            word in content_lower\n            for word in [\n                \"tell me about\",\n                \"who is\",\n                \"what is\",\n                \"where is\",\n                \"what happened in\",\n                \"date of\",\n                \"historical\",\n                \"how many\",\n            ]\n        ):\n            return IntentType.FACTUAL\n\n        if any(\n            word in content_lower\n            for word in [\"write a story\", \"poem\", \"joke\", \"creative\", \"imagine\", \"song\"]\n        ):\n            return IntentType.CREATIVE\n\n        # Default to general intent\n        return IntentType.GENERAL\n\n    def _count_keyword_matches(self, content_lower: str, keywords: List[str]) -> int:\n        \"\"\"Count how many keywords from the list appear in the content.\"\"\"\n        return sum(1 for keyword in keywords if keyword in content_lower)\n\n    def _calculate_confidence(self, match_count: int, is_default: bool = False) -> float:\n        \"\"\"Calculate confidence score based on keyword match count.\"\"\"\n        if is_default:\n            return self.DEFAULT_CONFIDENCE\n        if match_count == 0:\n            return self.DEFAULT_CONFIDENCE\n        # Base confidence + boost for each additional match beyond the first\n        confidence = self.BASE_CONFIDENCE + (match_count - 1) * self.CONFIDENCE_BOOST_PER_MATCH\n        return min(confidence, self.MAX_RULE_CONFIDENCE)\n\n    def classify_with_confidence(self, content: str) -> Tuple[IntentType, float]:\n        \"\"\"\n        Determines the intent type and confidence score of the provided content.\n\n        Returns:\n            Tuple of (IntentType, confidence) where confidence is a float between 0 and 1.\n            Higher confidence indicates stronger keyword matches.\n        \"\"\"\n        content_lower = content.lower()\n\n        # Count matches for each intent type\n        reasoning_matches = self._count_keyword_matches(content_lower, self.REASONING_KEYWORDS)\n        factual_matches = self._count_keyword_matches(content_lower, self.FACTUAL_KEYWORDS)\n        creative_matches = self._count_keyword_matches(content_lower, self.CREATIVE_KEYWORDS)\n\n        # Determine intent based on highest match count, with priority order for ties\n        match_counts = [\n            (IntentType.REASONING, reasoning_matches),\n            (IntentType.FACTUAL, factual_matches),\n            (IntentType.CREATIVE, creative_matches),\n        ]\n\n        # Find the intent with the most matches\n        best_intent = IntentType.GENERAL\n        best_count = 0\n\n        for intent_type, count in match_counts:\n            if count > best_count:\n                best_intent = intent_type\n                best_count = count\n\n        # Calculate confidence based on match strength\n        if best_count > 0:\n            confidence = self._calculate_confidence(best_count)\n            return best_intent, confidence\n\n        # Default to general with lower confidence\n        return IntentType.GENERAL, self._calculate_confidence(0, is_default=True)\n\n    # LLM prompt template for intent classification\n    LLM_CLASSIFICATION_PROMPT: str = \"\"\"You are an intent classifier for a governance system. Classify the user's input into exactly one of these categories:\n\n- FACTUAL: Questions seeking specific facts, data, historical information, or verifiable answers.\n  Examples: \"What is the capital of France?\", \"When did World War 2 end?\", \"How many users are in the system?\"\n\n- CREATIVE: Requests for creative content, storytelling, imagination, or artistic output.\n  Examples: \"Write a poem about spring\", \"Tell me a joke\", \"Create a story about a robot\"\n\n- REASONING: Complex analytical tasks requiring step-by-step logic, calculations, or problem-solving.\n  Examples: \"Calculate the derivative of x^2\", \"Explain why the sky is blue step by step\", \"Analyze this data\"\n\n- GENERAL: Conversational inputs, greetings, or anything that doesn't fit the above categories.\n  Examples: \"Hello\", \"How are you?\", \"Thanks for your help\"\n\nUser input: {content}\n\nRespond with ONLY a JSON object in this exact format:\n{{\"intent\": \"FACTUAL|CREATIVE|REASONING|GENERAL\", \"confidence\": 0.0-1.0, \"reasoning\": \"brief explanation\"}}\"\"\"\n\n    # Maximum content length to send to LLM (to control costs)\n    MAX_CONTENT_LENGTH: int = 2000\n\n    async def _invoke_llm_classification(self, content: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Invoke LLM for intent classification.\n\n        Args:\n            content: The user input to classify.\n\n        Returns:\n            Dict with intent, confidence, and reasoning, or None on failure.\n        \"\"\"\n        if not self.is_llm_available():\n            return None\n\n        # Truncate content if too long\n        truncated_content = (\n            content[: self.MAX_CONTENT_LENGTH]\n            if len(content) > self.MAX_CONTENT_LENGTH\n            else content\n        )\n\n        try:\n            # Prepare the prompt\n            prompt = self.LLM_CLASSIFICATION_PROMPT.format(content=truncated_content)\n\n            # Get LLM parameters\n            params = self._get_llm_params()\n\n            # Call LiteLLM acompletion\n            response = await litellm.acompletion(\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                **params,\n            )\n\n            # Extract response content\n            if not response or not response.get(\"choices\"):\n                logger.warning(\"Empty LLM response received\")\n                return None\n\n            response_content = response[\"choices\"][0][\"message\"][\"content\"]\n\n            # Parse JSON response\n            try:\n                result = json.loads(response_content.strip())\n                return result\n            except json.JSONDecodeError as e:\n                logger.warning(f\"Failed to parse LLM response as JSON: {e}\")\n                # Try to extract intent from plain text response\n                response_upper = response_content.upper()\n                for intent_type in IntentType:\n                    if intent_type.name in response_upper:\n                        return {\n                            \"intent\": intent_type.name,\n                            \"confidence\": 0.7,\n                            \"reasoning\": \"Extracted from text\",\n                        }\n                return None\n\n        except Exception as e:\n            logger.error(f\"LLM classification failed: {e}\")\n            return None\n\n    def _parse_llm_intent(self, llm_result: Dict[str, Any]) -> Optional[IntentType]:\n        \"\"\"Parse LLM result to extract IntentType.\n\n        Args:\n            llm_result: Dict containing intent classification from LLM.\n\n        Returns:\n            IntentType if valid intent found, None otherwise.\n        \"\"\"\n        intent_str = llm_result.get(\"intent\", \"\").upper()\n\n        # Map string to IntentType enum\n        intent_map = {\n            \"FACTUAL\": IntentType.FACTUAL,\n            \"CREATIVE\": IntentType.CREATIVE,\n            \"REASONING\": IntentType.REASONING,\n            \"GENERAL\": IntentType.GENERAL,\n        }\n\n        return intent_map.get(intent_str)\n\n    async def classify_async(\n        self, content: str, context: Optional[Dict[str, Any]] = None\n    ) -> IntentType:\n        \"\"\"Asynchronous classification with optional context/LLM fallback.\"\"\"\n        # 1. Try heuristic classification first\n        intent = self.classify(content)\n\n        # 2. If intent is GENERAL (ambiguous), fallback to LLM\n        if intent == IntentType.GENERAL and self.config.llm_model:\n            try:\n                # Prepare prompt for intent classification\n                system_prompt = \"\"\"\n                Classify the following user input into one of these categories:\n                - factual: Question about facts, data, history, or specific entities.\n                - creative: Request for story, poem, song, or creative writing.\n                - reasoning: Complex logical problem, math, or step-by-step analysis.\n                - general: Simple greeting, conversational filler, or ambiguous request.\n\n                Respond with ONLY the category name in lowercase.\n                \"\"\"\n\n                response = await litellm.acompletion(\n                    model=self.config.llm_model,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_prompt},\n                        {\"role\": \"user\", \"content\": content}\n                    ],\n                    max_tokens=self.config.llm_max_tokens,\n                    temperature=0,\n                    caching=self.config.llm_use_cache\n                )\n\n                llm_intent = response.choices[0].message.content.strip().lower()\n\n                # Map LLM response to IntentType\n                for it in IntentType:\n                    if it.value == llm_intent:\n                        logger.info(f\"LLM classified intent as: {llm_intent} (heuristic was GENERAL)\")\n                        return it\n\n                logger.warning(f\"LLM returned unknown intent: {llm_intent}, falling back to GENERAL\")\n\n            except Exception as e:\n                logger.error(f\"LLM intent classification failed: {str(e)}\")\n\n        return intent\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), acgs2-core/breakthrough (79 occurrences), and acgs2-core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.348780",
  "last_updated": "2026-01-04T05:35:59.190255"
}