{
  "file_path": "acgs2-core/shared/structured_logging.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nACGS-2 Structured Logging Module\nConstitutional Hash: cdd01ef066bc6cf2\n\nProvides standardized structured logging with:\n- JSON output for enterprise log aggregation\n- Correlation ID propagation across services\n- RFC 5424 log level compliance\n- Sensitive data redaction\n- Integration with Splunk, ELK, Datadog\n\nUsage:\n    from shared.structured_logging import get_logger, configure_logging\n\n    configure_logging()\n    logger = get_logger(__name__)\n\n    logger.info(\"message_processed\", message_id=\"123\", agent_id=\"agent-1\")\n\"\"\"\n\nimport json\nimport logging\nimport os\nimport sys\nimport traceback\nimport uuid\nfrom contextvars import ContextVar\nfrom datetime import datetime, timezone\nfrom functools import wraps\nfrom typing import Any, Callable, Dict, Optional, Set\n\n# ===== Correlation ID Context =====\n\ncorrelation_id_var: ContextVar[str] = ContextVar(\"correlation_id\", default=\"\")\ntenant_id_var: ContextVar[str] = ContextVar(\"tenant_id\", default=\"\")\nrequest_id_var: ContextVar[str] = ContextVar(\"request_id\", default=\"\")\n\n# ===== Configuration =====\n\n# Sensitive field names to redact\nSENSITIVE_FIELDS: Set[str] = {\n    \"password\",\n    \"secret\",\n    \"token\",\n    \"api_key\",\n    \"apikey\",\n    \"auth\",\n    \"authorization\",\n    \"credential\",\n    \"private_key\",\n    \"privatekey\",\n    \"access_token\",\n    \"refresh_token\",\n    \"client_secret\",\n    \"redis_password\",\n    \"kafka_password\",\n    \"oidc_client_secret\",\n}\n\n# Maximum log message size before truncation\nMAX_LOG_SIZE = 10000  # 10KB\nTRUNCATION_SUFFIX = \" [truncated]\"\n\n# RFC 5424 log level mapping\nLOG_LEVELS = {\n    \"DEBUG\": logging.DEBUG,\n    \"INFO\": logging.INFO,\n    \"WARNING\": logging.WARNING,\n    \"WARN\": logging.WARNING,\n    \"ERROR\": logging.ERROR,\n    \"CRITICAL\": logging.CRITICAL,\n}\n\n# ===== JSON Formatter =====\n\n\nclass StructuredJSONFormatter(logging.Formatter):\n    \"\"\"\n    JSON log formatter for structured logging.\n\n    Outputs logs in JSON format with consistent schema:\n    {\n        \"timestamp\": \"2025-01-03T12:00:00.000Z\",\n        \"level\": \"INFO\",\n        \"logger\": \"module.name\",\n        \"message\": \"Log message\",\n        \"correlation_id\": \"abc-123\",\n        \"tenant_id\": \"tenant-1\",\n        \"extra\": {...}\n    }\n    \"\"\"\n\n    def __init__(\n        self,\n        include_stack_trace: bool = True,\n        redact_sensitive: bool = True,\n    ):\n        super().__init__()\n        self.include_stack_trace = include_stack_trace\n        self.redact_sensitive = redact_sensitive\n\n    def format(self, record: logging.LogRecord) -> str:\n        \"\"\"Format log record as JSON.\"\"\"\n        # Base log structure\n        log_data: Dict[str, Any] = {\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            \"level\": record.levelname,\n            \"logger\": record.name,\n            \"message\": record.getMessage(),\n        }\n\n        # Add context variables\n        correlation_id = correlation_id_var.get()\n        if correlation_id:\n            log_data[\"correlation_id\"] = correlation_id\n\n        tenant_id = tenant_id_var.get()\n        if tenant_id:\n            log_data[\"tenant_id\"] = tenant_id\n\n        request_id = request_id_var.get()\n        if request_id:\n            log_data[\"request_id\"] = request_id\n\n        # Add extra fields from record\n        if hasattr(record, \"extra\") and record.extra:\n            extra = self._process_extra(record.extra)\n            log_data[\"extra\"] = extra\n\n        # Add structured data from record args if dict\n        if isinstance(record.args, dict):\n            extra = self._process_extra(record.args)\n            log_data.setdefault(\"extra\", {}).update(extra)\n\n        # Add exception info\n        if record.exc_info and self.include_stack_trace:\n            log_data[\"exception\"] = {\n                \"type\": record.exc_info[0].__name__ if record.exc_info[0] else \"Unknown\",\n                \"message\": str(record.exc_info[1]) if record.exc_info[1] else \"\",\n            }\n            if self.include_stack_trace:\n                log_data[\"exception\"][\"traceback\"] = traceback.format_exception(\n                    *record.exc_info\n                )\n\n        # Add source location for debugging\n        if record.levelno >= logging.WARNING:\n            log_data[\"source\"] = {\n                \"file\": record.pathname,\n                \"line\": record.lineno,\n                \"function\": record.funcName,\n            }\n\n        # Serialize to JSON\n        json_str = json.dumps(log_data, default=str, ensure_ascii=False)\n\n        # Truncate if too large\n        if len(json_str) > MAX_LOG_SIZE:\n            json_str = json_str[: MAX_LOG_SIZE - len(TRUNCATION_SUFFIX)] + TRUNCATION_SUFFIX\n\n        return json_str\n\n    def _process_extra(self, extra: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Process extra fields with redaction.\"\"\"\n        if not self.redact_sensitive:\n            return extra\n\n        processed = {}\n        for key, value in extra.items():\n            lower_key = key.lower()\n\n            # Check if field name contains sensitive words\n            if any(sensitive in lower_key for sensitive in SENSITIVE_FIELDS):\n                processed[key] = \"[REDACTED]\"\n            elif isinstance(value, dict):\n                processed[key] = self._process_extra(value)\n            elif isinstance(value, str) and len(value) > 1000:\n                # Truncate long strings\n                processed[key] = value[:1000] + \"...\"\n            else:\n                processed[key] = value\n\n        return processed\n\n\nclass TextFormatter(logging.Formatter):\n    \"\"\"\n    Text log formatter for development.\n\n    Outputs human-readable logs with color support.\n    \"\"\"\n\n    COLORS = {\n        \"DEBUG\": \"\\033[36m\",  # Cyan\n        \"INFO\": \"\\033[32m\",   # Green\n        \"WARNING\": \"\\033[33m\",  # Yellow\n        \"ERROR\": \"\\033[31m\",  # Red\n        \"CRITICAL\": \"\\033[35m\",  # Magenta\n    }\n    RESET = \"\\033[0m\"\n\n    def format(self, record: logging.LogRecord) -> str:\n        \"\"\"Format log record as colored text.\"\"\"\n        color = self.COLORS.get(record.levelname, \"\")\n\n        # Build message parts\n        parts = [\n            f\"{color}[{record.levelname}]{self.RESET}\",\n            datetime.now().strftime(\"%H:%M:%S\"),\n            f\"[{record.name}]\",\n            record.getMessage(),\n        ]\n\n        # Add correlation ID if present\n        correlation_id = correlation_id_var.get()\n        if correlation_id:\n            parts.insert(3, f\"[{correlation_id[:8]}]\")\n\n        # Add extra data\n        if hasattr(record, \"extra\") and record.extra:\n            extra_str = \" \".join(f\"{k}={v}\" for k, v in record.extra.items())\n            parts.append(f\"| {extra_str}\")\n\n        message = \" \".join(parts)\n\n        # Add exception info\n        if record.exc_info:\n            message += \"\\n\" + \"\".join(traceback.format_exception(*record.exc_info))\n\n        return message\n\n\n# ===== Structured Logger =====\n\n\nclass StructuredLogger:\n    \"\"\"\n    Structured logger wrapper with convenience methods.\n\n    Provides structured logging with automatic context injection\n    and support for key-value extra data.\n\n    Usage:\n        logger = StructuredLogger(\"my.module\")\n        logger.info(\"User logged in\", user_id=\"123\", action=\"login\")\n    \"\"\"\n\n    def __init__(self, name: str):\n        self._logger = logging.getLogger(name)\n\n    def _log(\n        self,\n        level: int,\n        message: str,\n        exc_info: Any = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Internal log method with extra data handling.\"\"\"\n        if not self._logger.isEnabledFor(level):\n            return\n\n        record = self._logger.makeRecord(\n            name=self._logger.name,\n            level=level,\n            fn=\"\",\n            lno=0,\n            msg=message,\n            args=(),\n            exc_info=exc_info,\n        )\n\n        # Attach extra data\n        record.extra = kwargs\n\n        self._logger.handle(record)\n\n    def debug(self, message: str, **kwargs: Any) -> None:\n        \"\"\"Log debug message with extra data.\"\"\"\n        self._log(logging.DEBUG, message, **kwargs)\n\n    def info(self, message: str, **kwargs: Any) -> None:\n        \"\"\"Log info message with extra data.\"\"\"\n        self._log(logging.INFO, message, **kwargs)\n\n    def warning(self, message: str, **kwargs: Any) -> None:\n        \"\"\"Log warning message with extra data.\"\"\"\n        self._log(logging.WARNING, message, **kwargs)\n\n    def error(self, message: str, exc_info: Any = None, **kwargs: Any) -> None:\n        \"\"\"Log error message with optional exception info.\"\"\"\n        if exc_info is True:\n            exc_info = sys.exc_info()\n        self._log(logging.ERROR, message, exc_info=exc_info, **kwargs)\n\n    def critical(self, message: str, exc_info: Any = None, **kwargs: Any) -> None:\n        \"\"\"Log critical message with optional exception info.\"\"\"\n        if exc_info is True:\n            exc_info = sys.exc_info()\n        self._log(logging.CRITICAL, message, exc_info=exc_info, **kwargs)\n\n    def exception(self, message: str, **kwargs: Any) -> None:\n        \"\"\"Log exception with full traceback.\"\"\"\n        self._log(logging.ERROR, message, exc_info=sys.exc_info(), **kwargs)\n\n    def bind(self, **kwargs: Any) -> \"BoundLogger\":\n        \"\"\"Create a bound logger with preset extra fields.\"\"\"\n        return BoundLogger(self, kwargs)\n\n\nclass BoundLogger:\n    \"\"\"Logger with preset extra fields.\"\"\"\n\n    def __init__(self, logger: StructuredLogger, context: Dict[str, Any]):\n        self._logger = logger\n        self._context = context\n\n    def _merge_context(self, kwargs: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Merge bound context with call-time kwargs.\"\"\"\n        return {**self._context, **kwargs}\n\n    def debug(self, message: str, **kwargs: Any) -> None:\n        self._logger.debug(message, **self._merge_context(kwargs))\n\n    def info(self, message: str, **kwargs: Any) -> None:\n        self._logger.info(message, **self._merge_context(kwargs))\n\n    def warning(self, message: str, **kwargs: Any) -> None:\n        self._logger.warning(message, **self._merge_context(kwargs))\n\n    def error(self, message: str, **kwargs: Any) -> None:\n        self._logger.error(message, **self._merge_context(kwargs))\n\n    def critical(self, message: str, **kwargs: Any) -> None:\n        self._logger.critical(message, **self._merge_context(kwargs))\n\n    def exception(self, message: str, **kwargs: Any) -> None:\n        self._logger.exception(message, **self._merge_context(kwargs))\n\n\n# ===== Configuration Functions =====\n\n\ndef configure_logging(\n    level: Optional[str] = None,\n    format_type: Optional[str] = None,\n    include_stack_trace: bool = True,\n    redact_sensitive: bool = True,\n) -> None:\n    \"\"\"\n    Configure structured logging for the application.\n\n    Args:\n        level: Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n        format_type: Output format (\"json\" or \"text\")\n        include_stack_trace: Include full stack traces in error logs\n        redact_sensitive: Redact sensitive field values\n    \"\"\"\n    # Get configuration from environment if not provided\n    level = level or os.getenv(\"LOG_LEVEL\", \"INFO\").upper()\n    format_type = format_type or os.getenv(\"LOG_FORMAT\", \"json\").lower()\n\n    # Validate log level\n    log_level = LOG_LEVELS.get(level, logging.INFO)\n\n    # Create formatter\n    if format_type == \"json\":\n        formatter = StructuredJSONFormatter(\n            include_stack_trace=include_stack_trace,\n            redact_sensitive=redact_sensitive,\n        )\n    else:\n        formatter = TextFormatter()\n\n    # Configure root logger\n    root_logger = logging.getLogger()\n    root_logger.setLevel(log_level)\n\n    # Remove existing handlers\n    for handler in root_logger.handlers[:]:\n        root_logger.removeHandler(handler)\n\n    # Add console handler\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(log_level)\n    console_handler.setFormatter(formatter)\n    root_logger.addHandler(console_handler)\n\n    # Log configuration\n    logger = get_logger(\"structured_logging\")\n    logger.info(\n        \"Logging configured\",\n        level=level,\n        format=format_type,\n        redact_sensitive=redact_sensitive,\n    )\n\n\ndef get_logger(name: str) -> StructuredLogger:\n    \"\"\"\n    Get a structured logger instance.\n\n    Args:\n        name: Logger name (typically __name__)\n\n    Returns:\n        StructuredLogger instance\n    \"\"\"\n    return StructuredLogger(name)\n\n\n# ===== Context Management =====\n\n\ndef set_correlation_id(correlation_id: Optional[str] = None) -> str:\n    \"\"\"\n    Set correlation ID for current context.\n\n    Args:\n        correlation_id: Optional correlation ID (generated if not provided)\n\n    Returns:\n        The correlation ID that was set\n    \"\"\"\n    cid = correlation_id or str(uuid.uuid4())\n    correlation_id_var.set(cid)\n    return cid\n\n\ndef get_correlation_id() -> str:\n    \"\"\"Get current correlation ID.\"\"\"\n    return correlation_id_var.get()\n\n\ndef set_tenant_id(tenant_id: str) -> None:\n    \"\"\"Set tenant ID for current context.\"\"\"\n    tenant_id_var.set(tenant_id)\n\n\ndef get_tenant_id() -> str:\n    \"\"\"Get current tenant ID.\"\"\"\n    return tenant_id_var.get()\n\n\ndef set_request_id(request_id: str) -> None:\n    \"\"\"Set request ID for current context.\"\"\"\n    request_id_var.set(request_id)\n\n\n# ===== Decorators =====\n\n\ndef log_function_call(logger: Optional[StructuredLogger] = None) -> Callable:\n    \"\"\"\n    Decorator to log function entry and exit.\n\n    Usage:\n        @log_function_call()\n        def my_function(arg1, arg2):\n            ...\n    \"\"\"\n    def decorator(func: Callable) -> Callable:\n        nonlocal logger\n        if logger is None:\n            logger = get_logger(func.__module__)\n\n        @wraps(func)\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            logger.debug(\n                f\"Entering {func.__name__}\",\n                function=func.__name__,\n                args_count=len(args),\n                kwargs_keys=list(kwargs.keys()),\n            )\n            try:\n                result = func(*args, **kwargs)\n                logger.debug(\n                    f\"Exiting {func.__name__}\",\n                    function=func.__name__,\n                    success=True,\n                )\n                return result\n            except Exception as e:\n                logger.error(\n                    f\"Error in {func.__name__}\",\n                    function=func.__name__,\n                    error=str(e),\n                    exc_info=True,\n                )\n                raise\n\n        @wraps(func)\n        async def async_wrapper(*args: Any, **kwargs: Any) -> Any:\n            logger.debug(\n                f\"Entering {func.__name__}\",\n                function=func.__name__,\n                args_count=len(args),\n                kwargs_keys=list(kwargs.keys()),\n            )\n            try:\n                result = await func(*args, **kwargs)\n                logger.debug(\n                    f\"Exiting {func.__name__}\",\n                    function=func.__name__,\n                    success=True,\n                )\n                return result\n            except Exception as e:\n                logger.error(\n                    f\"Error in {func.__name__}\",\n                    function=func.__name__,\n                    error=str(e),\n                    exc_info=True,\n                )\n                raise\n\n        import asyncio\n        if asyncio.iscoroutinefunction(func):\n            return async_wrapper\n        return wrapper\n\n    return decorator\n\n\n# ===== Export =====\n\n__all__ = [\n    # Configuration\n    \"configure_logging\",\n    \"get_logger\",\n    # Context management\n    \"set_correlation_id\",\n    \"get_correlation_id\",\n    \"set_tenant_id\",\n    \"get_tenant_id\",\n    \"set_request_id\",\n    # Context variables\n    \"correlation_id_var\",\n    \"tenant_id_var\",\n    \"request_id_var\",\n    # Formatters\n    \"StructuredJSONFormatter\",\n    \"TextFormatter\",\n    # Loggers\n    \"StructuredLogger\",\n    \"BoundLogger\",\n    # Decorators\n    \"log_function_call\",\n]\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), acgs2-core/breakthrough (79 occurrences), and acgs2-core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.159202",
  "last_updated": "2026-01-04T05:35:59.179235"
}