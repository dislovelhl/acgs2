{
  "file_path": "src/core/services/core/code-analysis/code_analysis_service/app/services/cache_service.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nACGS Code Analysis Engine - Cache Service\nRedis integration with constitutional compliance and performance optimization.\n\"\"\"\n\nimport hashlib\nimport json\nimport time\nfrom datetime import datetime, timezone\nfrom typing import Any\n\nimport redis.asyncio as redis\n\nfrom app.utils.constitutional import (\n    CONSTITUTIONAL_HASH,\n    ensure_constitutional_compliance,\n)\nfrom app.utils.logging import get_logger, performance_logger\n\nlogger = get_logger(\"services.cache\")\n\n\n# Constitutional Hash: cdd01ef066bc6cf2\nclass CacheService:\n    \"\"\"Cache service for ACGS Code Analysis Engine with constitutional compliance.\n\n    Provides Redis-based caching with constitutional hash validation.\"\"\"\n\n    def __init__(\n        self,\n        redis_url: str = \"redis://localhost:6389\",\n        key_prefix: str = \"acgs:code_analysis:\",\n        default_ttl: int = 3600,\n        max_retries: int = 3,\n        retry_delay: float = 1.0,\n    ):\n        \"\"\"Initialize cache service.\n\n        Args:\n            redis_url: Redis connection URL\n            key_prefix: Prefix for all cache keys\n            default_ttl: Default TTL in seconds\n            max_retries: Maximum retry attempts\n            retry_delay: Delay between retries\n        \"\"\"\n        self.redis_url = redis_url\n        self.key_prefix = key_prefix\n        self.default_ttl = default_ttl\n        self.max_retries = max_retries\n        self.retry_delay = retry_delay\n\n        # Redis client\n        self.redis_client: redis.Redis | None = None\n        self.is_connected = False\n\n        # Cache statistics\n        self.cache_hits = 0\n        self.cache_misses = 0\n        self.cache_errors = 0\n\n        logger.info(\n            \"Cache service initialized\",\n            extra={\n                \"redis_url\": redis_url,\n                \"key_prefix\": key_prefix,\n                \"default_ttl\": default_ttl,\n                \"constitutional_hash\": CONSTITUTIONAL_HASH,\n            },\n        )\n\n    async def connect(self) -> bool:\n        \"\"\"Connect to Redis server.\n\n        Returns:\n            bool: True if connection successful\n        \"\"\"\n        if self.is_connected:\n            return True\n\n        try:\n            self.redis_client = redis.from_url(\n                self.redis_url,\n                decode_responses=True,\n                retry_on_timeout=True,\n                socket_keepalive=True,\n                socket_keepalive_options={},\n            )\n\n            # Test connection\n            await self.redis_client.ping()\n            self.is_connected = True\n\n            logger.info(\n                \"Cache service connected to Redis\",\n                extra={\n                    \"redis_url\": self.redis_url,\n                    \"constitutional_hash\": CONSTITUTIONAL_HASH,\n                },\n            )\n\n            return True\n\n        except Exception as e:\n            logger.error(\n                f\"Failed to connect to Redis: {e}\",\n                extra={\n                    \"redis_url\": self.redis_url,\n                    \"constitutional_hash\": CONSTITUTIONAL_HASH,\n                },\n                exc_info=True,\n            )\n            return False\n\n    async def disconnect(self) -> None:\n        \"\"\"Disconnect from Redis server.\"\"\"\n        if self.redis_client:\n            await self.redis_client.close()\n            self.redis_client = None\n            self.is_connected = False\n\n            logger.info(\n                \"Cache service disconnected from Redis\",\n                extra={\"constitutional_hash\": CONSTITUTIONAL_HASH},\n            )\n\n    async def get(self, key: str, default: Any = None) -> Any:\n        \"\"\"Get value from cache.\n\n        Args:\n            key: Cache key\n            default: Default value if key not found\n\n        Returns:\n            Cached value or default\n        \"\"\"\n        if not self.is_connected:\n            try:\n                await self.connect()\n            except Exception as e:\n                logger.error(f\"Operation failed: {e}\")\n                raise\n\n        full_key = self._build_key(key)\n\n        try:\n            start_time = time.time()\n\n            # Get value from Redis\n            cached_data = await self.redis_client.get(full_key)\n\n            if cached_data is not None:\n                # Parse cached data\n                data = json.loads(cached_data)\n\n                # Validate constitutional compliance\n                if not self._validate_cached_data(data):\n                    logger.warning(\n                        f\"Cached data failed constitutional validation: {key}\",\n                        extra={\"constitutional_hash\": CONSTITUTIONAL_HASH},\n                    )\n                    await self.delete(key)  # Remove invalid data\n                    self.cache_misses += 1\n                    return default\n\n                # Extract actual value\n                value = data.get(\"value\")\n\n                # Log cache hit\n                duration_ms = (time.time() - start_time) * 1000\n                performance_logger.log_cache_operation(\n                    operation=\"get\", cache_hit=True, key=key, duration_ms=duration_ms\n                )\n\n                self.cache_hits += 1\n                return value\n            # Log cache miss\n            duration_ms = (time.time() - start_time) * 1000\n            performance_logger.log_cache_operation(\n                operation=\"get\", cache_hit=False, key=key, duration_ms=duration_ms\n            )\n\n            self.cache_misses += 1\n            return default\n\n        except Exception as e:\n            logger.error(\n                f\"Cache get error: {e}\",\n                extra={\"key\": key, \"constitutional_hash\": CONSTITUTIONAL_HASH},\n                exc_info=True,\n            )\n\n            self.cache_errors += 1\n            return default\n\n    async def set(self, key: str, value: Any, ttl: int | None = None) -> bool:\n        \"\"\"Set value in cache.\n\n        Args:\n            key: Cache key\n            value: Value to cache\n            ttl: Time to live in seconds\n\n        Returns:\n            bool: True if successful\n        \"\"\"\n        if not self.is_connected:\n            try:\n                await self.connect()\n            except Exception as e:\n                logger.error(f\"Operation failed: {e}\")\n                raise\n\n        full_key = self._build_key(key)\n        ttl = ttl or self.default_ttl\n\n        try:\n            start_time = time.time()\n\n            # Prepare data with constitutional compliance\n            cached_data = {\n                \"value\": value,\n                \"constitutional_hash\": CONSTITUTIONAL_HASH,\n                \"cached_at\": datetime.now(timezone.utc).isoformat(),\n                \"ttl\": ttl,\n                \"service\": \"acgs-code-analysis-engine\",\n            }\n\n            # Serialize data\n            serialized_data = json.dumps(cached_data, default=str)\n\n            # Set in Redis\n            await self.redis_client.setex(full_key, ttl, serialized_data)\n\n            # Log cache set\n            duration_ms = (time.time() - start_time) * 1000\n            performance_logger.log_cache_operation(\n                operation=\"set\",\n                cache_hit=True,  # Set is always a \"hit\"\n                key=key,\n                duration_ms=duration_ms,\n                ttl=ttl,\n            )\n\n            return True\n\n        except Exception as e:\n            logger.error(\n                f\"Cache set error: {e}\",\n                extra={\n                    \"key\": key,\n                    \"ttl\": ttl,\n                    \"constitutional_hash\": CONSTITUTIONAL_HASH,\n                },\n                exc_info=True,\n            )\n\n            self.cache_errors += 1\n            return False\n\n    async def delete(self, key: str) -> bool:\n        \"\"\"Delete value from cache.\n\n        Args:\n            key: Cache key to delete\n\n        Returns:\n            bool: True if successful\n        \"\"\"\n        if not self.is_connected:\n            try:\n                await self.connect()\n            except Exception as e:\n                logger.error(f\"Operation failed: {e}\")\n                raise\n\n        full_key = self._build_key(key)\n\n        try:\n            start_time = time.time()\n\n            # Delete from Redis\n            result = await self.redis_client.delete(full_key)\n\n            # Log cache delete\n            duration_ms = (time.time() - start_time) * 1000\n            performance_logger.log_cache_operation(\n                operation=\"delete\",\n                cache_hit=result > 0,\n                key=key,\n                duration_ms=duration_ms,\n            )\n\n            return result > 0\n\n        except Exception as e:\n            logger.error(\n                f\"Cache delete error: {e}\",\n                extra={\"key\": key, \"constitutional_hash\": CONSTITUTIONAL_HASH},\n                exc_info=True,\n            )\n\n            self.cache_errors += 1\n            return False\n\n    async def exists(self, key: str) -> bool:\n        \"\"\"Check if key exists in cache.\n\n        Args:\n            key: Cache key to check\n\n        Returns:\n            bool: True if key exists\n        \"\"\"\n        if not self.is_connected:\n            try:\n                await self.connect()\n            except Exception as e:\n                logger.error(f\"Operation failed: {e}\")\n                raise\n\n        full_key = self._build_key(key)\n\n        try:\n            result = await self.redis_client.exists(full_key)\n            return result > 0\n\n        except Exception as e:\n            logger.error(\n                f\"Cache exists error: {e}\",\n                extra={\"key\": key, \"constitutional_hash\": CONSTITUTIONAL_HASH},\n                exc_info=True,\n            )\n\n            self.cache_errors += 1\n            return False\n\n    async def clear_pattern(self, pattern: str) -> int:\n        \"\"\"Clear all keys matching pattern.\n\n        Args:\n            pattern: Key pattern to match\n\n        Returns:\n            int: Number of keys deleted\n        \"\"\"\n        if not self.is_connected:\n            try:\n                await self.connect()\n            except Exception as e:\n                logger.error(f\"Operation failed: {e}\")\n                raise\n\n        full_pattern = self._build_key(pattern)\n\n        try:\n            # Find matching keys\n            keys = await self.redis_client.keys(full_pattern)\n\n            if keys:\n                # Delete all matching keys\n                result = await self.redis_client.delete(*keys)\n\n                logger.info(\n                    f\"Cleared {result} cache keys matching pattern: {pattern}\",\n                    extra={\n                        \"pattern\": pattern,\n                        \"keys_deleted\": result,\n                        \"constitutional_hash\": CONSTITUTIONAL_HASH,\n                    },\n                )\n\n                return result\n            return 0\n\n        except Exception as e:\n            logger.error(\n                f\"Cache clear pattern error: {e}\",\n                extra={\"pattern\": pattern, \"constitutional_hash\": CONSTITUTIONAL_HASH},\n                exc_info=True,\n            )\n\n            self.cache_errors += 1\n            return 0\n\n    async def get_cache_info(self) -> dict[str, Any]:\n        \"\"\"Get cache information and statistics.\"\"\"\n        if not self.is_connected:\n            try:\n                await self.connect()\n            except Exception as e:\n                logger.error(f\"Operation failed: {e}\")\n                raise\n\n        try:\n            # Get Redis info\n            redis_info = await self.redis_client.info()\n\n            # Calculate hit rate\n            total_operations = self.cache_hits + self.cache_misses\n            hit_rate = (self.cache_hits / total_operations) if total_operations > 0 else 0.0\n\n            cache_info = {\n                \"is_connected\": self.is_connected,\n                \"redis_url\": self.redis_url,\n                \"key_prefix\": self.key_prefix,\n                \"default_ttl\": self.default_ttl,\n                \"statistics\": {\n                    \"cache_hits\": self.cache_hits,\n                    \"cache_misses\": self.cache_misses,\n                    \"cache_errors\": self.cache_errors,\n                    \"hit_rate\": round(hit_rate, 4),\n                    \"total_operations\": total_operations,\n                },\n                \"redis_info\": {\n                    \"used_memory\": redis_info.get(\"used_memory_human\"),\n                    \"connected_clients\": redis_info.get(\"connected_clients\"),\n                    \"total_commands_processed\": redis_info.get(\"total_commands_processed\"),\n                    \"keyspace_hits\": redis_info.get(\"keyspace_hits\"),\n                    \"keyspace_misses\": redis_info.get(\"keyspace_misses\"),\n                },\n            }\n\n            return ensure_constitutional_compliance(cache_info)\n\n        except Exception as e:\n            logger.error(\n                f\"Cache info error: {e}\",\n                extra={\"constitutional_hash\": CONSTITUTIONAL_HASH},\n                exc_info=True,\n            )\n\n            return ensure_constitutional_compliance(\n                {\n                    \"is_connected\": self.is_connected,\n                    \"error\": str(e),\n                    \"statistics\": {\n                        \"cache_hits\": self.cache_hits,\n                        \"cache_misses\": self.cache_misses,\n                        \"cache_errors\": self.cache_errors,\n                    },\n                }\n            )\n\n    def _build_key(self, key: str) -> str:\n        \"\"\"Build full cache key with prefix.\"\"\"\n        return f\"{self.key_prefix}, {key}\"\n\n    def _validate_cached_data(self, data: dict[str, Any]) -> bool:\n        \"\"\"Validate constitutional compliance of cached data.\"\"\"\n        # Check for constitutional hash\n        cached_hash = data.get(\"constitutional_hash\")\n        if not cached_hash or cached_hash != CONSTITUTIONAL_HASH:\n            return False\n\n        # Check for required fields\n        required_fields = [\"value\", \"cached_at\", \"service\"]\n        for field in required_fields:\n            if field not in data:\n                return False\n\n        # Check service name\n        return data.get(\"service\") == \"acgs-code-analysis-engine\"\n\n    def generate_cache_key(self, *components: str) -> str:\n        \"\"\"Generate cache key from components.\n\n        Args:\n            components: Key components\n\n        Returns:\n            str: Generated cache key\n        \"\"\"\n        # Create deterministic key from components\n        key_string = \":\".join(str(c) for c in components)\n\n        # Add constitutional hash for uniqueness\n        key_with_hash = f\"{key_string}:{CONSTITUTIONAL_HASH}\"\n\n        # Generate hash for long keys\n        if len(key_with_hash) > 200:\n            try:\n                key_hash = hashlib.sha256(key_with_hash.encode()).hexdigest()[:16]\n            except Exception as e:\n                logger.error(f\"Operation failed: {e}\")\n                raise\n            return f\"hash:{key_hash}\"\n\n        return key_string\n\n    async def __aenter__(self) -> Any:\n        \"\"\"Async context manager entry.\"\"\"\n        try:\n            await self.connect()\n        except Exception as e:\n            logger.error(f\"Operation failed: {e}\")\n            raise\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb) -> Any:\n        \"\"\"Async context manager exit.\"\"\"\n        await self.disconnect()\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), src/core/breakthrough (79 occurrences), and src/core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.259734",
  "last_updated": "2026-01-04T05:35:58.444631"
}