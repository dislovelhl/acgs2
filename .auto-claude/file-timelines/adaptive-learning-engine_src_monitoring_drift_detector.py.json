{
  "file_path": "adaptive-learning-engine/src/monitoring/drift_detector.py",
  "main_branch_history": [],
  "task_views": {
    "049-cache-drift-detection-report-results": {
      "task_id": "049-cache-drift-detection-report-results",
      "branch_point": {
        "commit_hash": "4a99fe22e8e0087919301b1aa185d4e2c6da716c",
        "content": "\"\"\"\nAdaptive Learning Engine - Drift Detector\nConstitutional Hash: cdd01ef066bc6cf2\n\nEvidently-based concept drift detection for monitoring model performance.\nCompares reference (baseline) vs. current (recent) data distributions\nto detect when the model needs updating or rollback.\n\"\"\"\n\nimport asyncio\nimport logging\nimport threading\nimport time\nfrom collections import deque\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Callable, Deque, Dict, List, Optional\n\nimport numpy as np\nimport pandas as pd\nfrom evidently.metric_preset import DataDriftPreset\nfrom evidently.report import Report\n\nlogger = logging.getLogger(__name__)\n\n\nclass DriftStatus(Enum):\n    \"\"\"Current drift detection status.\"\"\"\n\n    NO_DRIFT = \"no_drift\"  # No significant drift detected\n    DRIFT_DETECTED = \"drift_detected\"  # Significant drift detected\n    INSUFFICIENT_DATA = \"insufficient_data\"  # Not enough data for detection\n    DISABLED = \"disabled\"  # Drift detection is disabled\n    ERROR = \"error\"  # Error during drift detection\n\n\n@dataclass\nclass DriftResult:\n    \"\"\"Result from a drift detection check.\"\"\"\n\n    status: DriftStatus\n    drift_detected: bool\n    drift_score: float  # Share of drifted columns (0.0 - 1.0)\n    drift_threshold: float\n    columns_drifted: Dict[str, bool]  # Per-column drift status\n    column_drift_scores: Dict[str, float]  # Per-column drift scores\n    reference_size: int\n    current_size: int\n    timestamp: float = field(default_factory=time.time)\n    message: str = \"\"\n\n\n@dataclass\nclass DriftAlert:\n    \"\"\"Alert generated when drift is detected.\"\"\"\n\n    drift_result: DriftResult\n    severity: str  # \"warning\" or \"critical\"\n    triggered_at: float = field(default_factory=time.time)\n    acknowledged: bool = False\n    alert_id: str = field(default_factory=lambda: f\"drift_{int(time.time() * 1000)}\")\n\n\n@dataclass\nclass DriftMetrics:\n    \"\"\"Aggregated drift detection metrics.\"\"\"\n\n    total_checks: int\n    drift_detections: int\n    last_check_time: Optional[float]\n    last_drift_time: Optional[float]\n    current_drift_score: float\n    average_drift_score: float\n    status: DriftStatus\n    consecutive_drift_count: int\n    data_points_collected: int\n\n\nclass DriftDetector:\n    \"\"\"Evidently-based drift detector for governance model monitoring.\n\n    Monitors concept drift by comparing reference (baseline) data distribution\n    against current (recent) prediction data. Uses Evidently's DataDriftPreset\n    which includes multiple statistical tests (K-S, PSI, etc.).\n\n    Features:\n    - Configurable drift threshold (PSI-based)\n    - Automatic reference data management\n    - Low-traffic detection (insufficient data warning)\n    - Alert callbacks for integration\n    - Thread-safe operations\n    - Graceful degradation on errors\n\n    Example usage:\n        detector = DriftDetector(\n            drift_threshold=0.2,\n            reference_window_size=1000,\n            current_window_size=100,\n        )\n\n        # Add prediction data\n        detector.add_data_point(features={\"f1\": 1.0, \"f2\": 2.0}, label=1)\n\n        # Check for drift\n        result = detector.check_drift()\n        if result.drift_detected:\n            print(f\"Drift detected! Score: {result.drift_score}\")\n    \"\"\"\n\n    def __init__(\n        self,\n        drift_threshold: float = 0.2,\n        reference_window_size: int = 1000,\n        current_window_size: int = 100,\n        min_samples_for_drift: int = 10,\n        check_interval_seconds: int = 300,\n        drift_share_threshold: float = 0.5,\n        enabled: bool = True,\n    ) -> None:\n        \"\"\"Initialize the drift detector.\n\n        Args:\n            drift_threshold: PSI threshold for column drift (default 0.2).\n            reference_window_size: Number of samples in reference dataset.\n            current_window_size: Number of recent samples for comparison.\n            min_samples_for_drift: Minimum samples needed for drift check.\n            check_interval_seconds: Interval between automatic checks.\n            drift_share_threshold: Fraction of columns that must drift\n                to trigger dataset-level drift alert.\n            enabled: Whether drift detection is enabled.\n        \"\"\"\n        self.drift_threshold = drift_threshold\n        self.reference_window_size = reference_window_size\n        self.current_window_size = current_window_size\n        self.min_samples_for_drift = min_samples_for_drift\n        self.check_interval_seconds = check_interval_seconds\n        self.drift_share_threshold = drift_share_threshold\n        self._enabled = enabled\n\n        # Thread safety\n        self._lock = threading.RLock()\n\n        # Data storage\n        self._reference_data: Deque[Dict[str, Any]] = deque(maxlen=reference_window_size)\n        self._current_data: Deque[Dict[str, Any]] = deque(maxlen=current_window_size)\n        self._all_data: Deque[Dict[str, Any]] = deque(\n            maxlen=reference_window_size + current_window_size\n        )\n\n        # State tracking\n        self._reference_locked = False  # Whether reference data is frozen\n        self._last_check_time: Optional[float] = None\n        self._last_drift_time: Optional[float] = None\n        self._total_checks = 0\n        self._drift_detections = 0\n        self._consecutive_drift_count = 0\n        self._drift_score_history: Deque[float] = deque(maxlen=100)\n        self._current_status = DriftStatus.INSUFFICIENT_DATA if enabled else DriftStatus.DISABLED\n\n        # Alert callbacks\n        self._alert_callbacks: List[Callable[[DriftAlert], None]] = []\n        self._pending_alerts: Deque[DriftAlert] = deque(maxlen=100)\n\n        # Column tracking\n        self._known_columns: set = set()\n\n        logger.info(\n            \"DriftDetector initialized\",\n            extra={\n                \"drift_threshold\": drift_threshold,\n                \"reference_window_size\": reference_window_size,\n                \"current_window_size\": current_window_size,\n                \"enabled\": enabled,\n            },\n        )\n\n    def add_data_point(\n        self,\n        features: Dict[str, Any],\n        label: Optional[int] = None,\n        prediction: Optional[int] = None,\n        timestamp: Optional[float] = None,\n    ) -> None:\n        \"\"\"Add a single data point for drift monitoring.\n\n        Args:\n            features: Feature dictionary with numeric values.\n            label: Optional true label.\n            prediction: Optional model prediction.\n            timestamp: Optional timestamp (uses current time if not provided).\n        \"\"\"\n        if not self._enabled:\n            return\n\n        with self._lock:\n            # Build data record\n            record = features.copy()\n\n            # Add optional fields\n            if label is not None:\n                record[\"_label\"] = label\n            if prediction is not None:\n                record[\"_prediction\"] = prediction\n            record[\"_timestamp\"] = timestamp or time.time()\n\n            # Update known columns\n            self._known_columns.update(k for k in features.keys() if not k.startswith(\"_\"))\n\n            # Add to current data window\n            self._current_data.append(record)\n            self._all_data.append(record)\n\n            # If reference is not locked, also add to reference\n            if not self._reference_locked:\n                self._reference_data.append(record)\n\n    def add_batch(\n        self,\n        data_points: List[Dict[str, Any]],\n        labels: Optional[List[int]] = None,\n        predictions: Optional[List[int]] = None,\n    ) -> int:\n        \"\"\"Add multiple data points at once.\n\n        Args:\n            data_points: List of feature dictionaries.\n            labels: Optional list of true labels.\n            predictions: Optional list of model predictions.\n\n        Returns:\n            Number of points added.\n        \"\"\"\n        count = 0\n        for i, features in enumerate(data_points):\n            label = labels[i] if labels and i < len(labels) else None\n            prediction = predictions[i] if predictions and i < len(predictions) else None\n            self.add_data_point(features=features, label=label, prediction=prediction)\n            count += 1\n        return count\n\n    def lock_reference_data(self) -> None:\n        \"\"\"Lock the reference data to prevent further updates.\n\n        Call this once you have enough baseline data to establish\n        a reference distribution for drift comparison.\n        \"\"\"\n        with self._lock:\n            self._reference_locked = True\n            logger.info(\n                \"Reference data locked\",\n                extra={\"reference_size\": len(self._reference_data)},\n            )\n\n    def unlock_reference_data(self) -> None:\n        \"\"\"Unlock reference data to allow updates.\"\"\"\n        with self._lock:\n            self._reference_locked = False\n            logger.info(\"Reference data unlocked\")\n\n    def update_reference_from_current(self) -> int:\n        \"\"\"Update reference data with current data.\n\n        Useful for resetting the reference baseline after model updates.\n\n        Returns:\n            Number of points in new reference.\n        \"\"\"\n        with self._lock:\n            # Copy current data to reference\n            self._reference_data.clear()\n            self._reference_data.extend(self._current_data)\n            self._reference_locked = True\n            logger.info(\n                \"Reference data updated from current\",\n                extra={\"reference_size\": len(self._reference_data)},\n            )\n            return len(self._reference_data)\n\n    def set_reference_data(self, reference_df: pd.DataFrame) -> None:\n        \"\"\"Set reference data from a DataFrame.\n\n        Args:\n            reference_df: DataFrame with feature columns.\n        \"\"\"\n        with self._lock:\n            self._reference_data.clear()\n            for _, row in reference_df.iterrows():\n                self._reference_data.append(row.to_dict())\n            self._reference_locked = True\n            self._known_columns.update(\n                c for c in reference_df.columns if not str(c).startswith(\"_\")\n            )\n            logger.info(\n                \"Reference data set from DataFrame\",\n                extra={\"reference_size\": len(self._reference_data)},\n            )\n\n    def check_drift(self) -> DriftResult:\n        \"\"\"Check for data drift between reference and current data.\n\n        Uses Evidently's DataDriftPreset which includes multiple\n        statistical tests (K-S test, PSI, etc.) to detect distribution shifts.\n\n        Returns:\n            DriftResult with drift status, scores, and details.\n        \"\"\"\n        with self._lock:\n            timestamp = time.time()\n            self._last_check_time = timestamp\n            self._total_checks += 1\n\n            # Check if disabled\n            if not self._enabled:\n                return DriftResult(\n                    status=DriftStatus.DISABLED,\n                    drift_detected=False,\n                    drift_score=0.0,\n                    drift_threshold=self.drift_threshold,\n                    columns_drifted={},\n                    column_drift_scores={},\n                    reference_size=0,\n                    current_size=0,\n                    timestamp=timestamp,\n                    message=\"Drift detection is disabled\",\n                )\n\n            # Check for sufficient data\n            ref_size = len(self._reference_data)\n            cur_size = len(self._current_data)\n\n            if ref_size < self.min_samples_for_drift:\n                self._current_status = DriftStatus.INSUFFICIENT_DATA\n                return DriftResult(\n                    status=DriftStatus.INSUFFICIENT_DATA,\n                    drift_detected=False,\n                    drift_score=0.0,\n                    drift_threshold=self.drift_threshold,\n                    columns_drifted={},\n                    column_drift_scores={},\n                    reference_size=ref_size,\n                    current_size=cur_size,\n                    timestamp=timestamp,\n                    message=f\"Insufficient reference data: {ref_size} < {self.min_samples_for_drift}\",\n                )\n\n            if cur_size < self.min_samples_for_drift:\n                self._current_status = DriftStatus.INSUFFICIENT_DATA\n                return DriftResult(\n                    status=DriftStatus.INSUFFICIENT_DATA,\n                    drift_detected=False,\n                    drift_score=0.0,\n                    drift_threshold=self.drift_threshold,\n                    columns_drifted={},\n                    column_drift_scores={},\n                    reference_size=ref_size,\n                    current_size=cur_size,\n                    timestamp=timestamp,\n                    message=f\"Insufficient current data: {cur_size} < {self.min_samples_for_drift}\",\n                )\n\n            try:\n                # Convert to DataFrames\n                reference_df = self._to_dataframe(list(self._reference_data))\n                current_df = self._to_dataframe(list(self._current_data))\n\n                # Ensure same columns\n                common_columns = list(set(reference_df.columns) & set(current_df.columns))\n                # Filter out internal columns\n                feature_columns = [c for c in common_columns if not str(c).startswith(\"_\")]\n\n                if not feature_columns:\n                    return DriftResult(\n                        status=DriftStatus.ERROR,\n                        drift_detected=False,\n                        drift_score=0.0,\n                        drift_threshold=self.drift_threshold,\n                        columns_drifted={},\n                        column_drift_scores={},\n                        reference_size=ref_size,\n                        current_size=cur_size,\n                        timestamp=timestamp,\n                        message=\"No common feature columns found\",\n                    )\n\n                reference_df = reference_df[feature_columns]\n                current_df = current_df[feature_columns]\n\n                # Run Evidently drift detection\n                drift_report = Report(\n                    metrics=[\n                        DataDriftPreset(\n                            drift_share=self.drift_share_threshold,\n                        )\n                    ]\n                )\n                drift_report.run(\n                    reference_data=reference_df,\n                    current_data=current_df,\n                )\n\n                # Extract results\n                report_dict = drift_report.as_dict()\n\n                # Parse drift results from report\n                result = self._parse_drift_report(\n                    report_dict=report_dict,\n                    ref_size=ref_size,\n                    cur_size=cur_size,\n                    timestamp=timestamp,\n                )\n\n                # Update tracking\n                self._drift_score_history.append(result.drift_score)\n\n                if result.drift_detected:\n                    self._drift_detections += 1\n                    self._consecutive_drift_count += 1\n                    self._last_drift_time = timestamp\n                    self._current_status = DriftStatus.DRIFT_DETECTED\n\n                    # Trigger alert\n                    self._trigger_alert(result)\n\n                    logger.warning(\n                        \"Drift detected\",\n                        extra={\n                            \"drift_score\": result.drift_score,\n                            \"threshold\": self.drift_threshold,\n                            \"columns_drifted\": sum(result.columns_drifted.values()),\n                        },\n                    )\n                else:\n                    self._consecutive_drift_count = 0\n                    self._current_status = DriftStatus.NO_DRIFT\n\n                return result\n\n            except Exception as e:\n                # Graceful degradation: log error but don't crash\n                logger.error(f\"Drift detection error: {e}\", exc_info=True)\n                self._current_status = DriftStatus.ERROR\n                return DriftResult(\n                    status=DriftStatus.ERROR,\n                    drift_detected=False,\n                    drift_score=0.0,\n                    drift_threshold=self.drift_threshold,\n                    columns_drifted={},\n                    column_drift_scores={},\n                    reference_size=ref_size,\n                    current_size=cur_size,\n                    timestamp=timestamp,\n                    message=f\"Error during drift detection: {str(e)}\",\n                )\n\n    async def check_drift_async(self) -> DriftResult:\n        \"\"\"Async version of check_drift for non-blocking operation.\n\n        Returns:\n            DriftResult with drift status, scores, and details.\n        \"\"\"\n        # Run sync check in thread pool to avoid blocking\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, self.check_drift)\n\n    def get_status(self) -> DriftResult:\n        \"\"\"Get current drift status without running a new check.\n\n        Returns:\n            Last drift result or default if no checks performed.\n        \"\"\"\n        with self._lock:\n            timestamp = time.time()\n\n            if self._last_check_time is None:\n                return DriftResult(\n                    status=self._current_status,\n                    drift_detected=False,\n                    drift_score=0.0,\n                    drift_threshold=self.drift_threshold,\n                    columns_drifted={},\n                    column_drift_scores={},\n                    reference_size=len(self._reference_data),\n                    current_size=len(self._current_data),\n                    timestamp=timestamp,\n                    message=\"No drift check performed yet\",\n                )\n\n            # Return current status\n            return DriftResult(\n                status=self._current_status,\n                drift_detected=self._current_status == DriftStatus.DRIFT_DETECTED,\n                drift_score=(self._drift_score_history[-1] if self._drift_score_history else 0.0),\n                drift_threshold=self.drift_threshold,\n                columns_drifted={},\n                column_drift_scores={},\n                reference_size=len(self._reference_data),\n                current_size=len(self._current_data),\n                timestamp=self._last_check_time,\n                message=f\"Last check at {datetime.fromtimestamp(self._last_check_time).isoformat()}\",\n            )\n\n    def get_metrics(self) -> DriftMetrics:\n        \"\"\"Get aggregated drift detection metrics.\n\n        Returns:\n            DriftMetrics with check counts and statistics.\n        \"\"\"\n        with self._lock:\n            avg_score = (\n                float(np.mean(list(self._drift_score_history)))\n                if self._drift_score_history\n                else 0.0\n            )\n            current_score = self._drift_score_history[-1] if self._drift_score_history else 0.0\n\n            return DriftMetrics(\n                total_checks=self._total_checks,\n                drift_detections=self._drift_detections,\n                last_check_time=self._last_check_time,\n                last_drift_time=self._last_drift_time,\n                current_drift_score=current_score,\n                average_drift_score=avg_score,\n                status=self._current_status,\n                consecutive_drift_count=self._consecutive_drift_count,\n                data_points_collected=len(self._all_data),\n            )\n\n    def register_alert_callback(self, callback: Callable[[DriftAlert], None]) -> None:\n        \"\"\"Register a callback for drift alerts.\n\n        Args:\n            callback: Function called when drift is detected.\n        \"\"\"\n        with self._lock:\n            self._alert_callbacks.append(callback)\n\n    def get_pending_alerts(self) -> List[DriftAlert]:\n        \"\"\"Get list of unacknowledged alerts.\n\n        Returns:\n            List of DriftAlert objects.\n        \"\"\"\n        with self._lock:\n            return [a for a in self._pending_alerts if not a.acknowledged]\n\n    def acknowledge_alert(self, alert_id: str) -> bool:\n        \"\"\"Acknowledge a drift alert.\n\n        Args:\n            alert_id: ID of the alert to acknowledge.\n\n        Returns:\n            True if alert was found and acknowledged.\n        \"\"\"\n        with self._lock:\n            for alert in self._pending_alerts:\n                if alert.alert_id == alert_id:\n                    alert.acknowledged = True\n                    return True\n            return False\n\n    def enable(self) -> None:\n        \"\"\"Enable drift detection.\"\"\"\n        with self._lock:\n            self._enabled = True\n            self._current_status = (\n                DriftStatus.INSUFFICIENT_DATA\n                if len(self._reference_data) < self.min_samples_for_drift\n                else DriftStatus.NO_DRIFT\n            )\n            logger.info(\"Drift detection enabled\")\n\n    def disable(self) -> None:\n        \"\"\"Disable drift detection.\"\"\"\n        with self._lock:\n            self._enabled = False\n            self._current_status = DriftStatus.DISABLED\n            logger.info(\"Drift detection disabled\")\n\n    def is_enabled(self) -> bool:\n        \"\"\"Check if drift detection is enabled.\"\"\"\n        return self._enabled\n\n    def reset(self) -> None:\n        \"\"\"Reset detector to initial state.\n\n        Clears all data and resets metrics.\n        \"\"\"\n        with self._lock:\n            self._reference_data.clear()\n            self._current_data.clear()\n            self._all_data.clear()\n            self._reference_locked = False\n            self._last_check_time = None\n            self._last_drift_time = None\n            self._total_checks = 0\n            self._drift_detections = 0\n            self._consecutive_drift_count = 0\n            self._drift_score_history.clear()\n            self._pending_alerts.clear()\n            self._known_columns.clear()\n            self._current_status = (\n                DriftStatus.INSUFFICIENT_DATA if self._enabled else DriftStatus.DISABLED\n            )\n            logger.info(\"DriftDetector reset\")\n\n    def _to_dataframe(self, data: List[Dict[str, Any]]) -> pd.DataFrame:\n        \"\"\"Convert list of dictionaries to DataFrame.\n\n        Filters to numeric columns only for drift detection.\n\n        Args:\n            data: List of feature dictionaries.\n\n        Returns:\n            DataFrame with numeric columns.\n        \"\"\"\n        df = pd.DataFrame(data)\n\n        # Select only numeric columns\n        numeric_df = df.select_dtypes(include=[np.number])\n\n        return numeric_df\n\n    def _parse_drift_report(\n        self,\n        report_dict: Dict[str, Any],\n        ref_size: int,\n        cur_size: int,\n        timestamp: float,\n    ) -> DriftResult:\n        \"\"\"Parse Evidently drift report into DriftResult.\n\n        Args:\n            report_dict: Evidently report as dictionary.\n            ref_size: Reference data size.\n            cur_size: Current data size.\n            timestamp: Check timestamp.\n\n        Returns:\n            Parsed DriftResult.\n        \"\"\"\n        columns_drifted: Dict[str, bool] = {}\n        column_drift_scores: Dict[str, float] = {}\n        dataset_drift = False\n        share_of_drifted_columns = 0.0\n\n        try:\n            metrics_list = report_dict.get(\"metrics\", [])\n\n            for metric in metrics_list:\n                result = metric.get(\"result\", {})\n\n                # Dataset-level drift\n                if \"dataset_drift\" in result:\n                    dataset_drift = result[\"dataset_drift\"]\n                    share_of_drifted_columns = result.get(\"share_of_drifted_columns\", 0.0)\n\n                # Column-level drift\n                drift_by_columns = result.get(\"drift_by_columns\", {})\n                for col_name, col_data in drift_by_columns.items():\n                    if isinstance(col_data, dict):\n                        columns_drifted[col_name] = col_data.get(\"drift_detected\", False)\n                        # Try to get drift score (p-value or statistic varies by test)\n                        drift_score = col_data.get(\"drift_score\", 0.0)\n                        if drift_score is None:\n                            drift_score = col_data.get(\"stattest_score\", 0.0) or 0.0\n                        column_drift_scores[col_name] = float(drift_score)\n\n        except Exception as e:\n            logger.warning(f\"Error parsing drift report: {e}\")\n\n        # Build result\n        status = DriftStatus.DRIFT_DETECTED if dataset_drift else DriftStatus.NO_DRIFT\n        num_drifted = sum(1 for v in columns_drifted.values() if v)\n\n        return DriftResult(\n            status=status,\n            drift_detected=dataset_drift,\n            drift_score=share_of_drifted_columns,\n            drift_threshold=self.drift_threshold,\n            columns_drifted=columns_drifted,\n            column_drift_scores=column_drift_scores,\n            reference_size=ref_size,\n            current_size=cur_size,\n            timestamp=timestamp,\n            message=(\n                f\"Drift detected in {num_drifted} columns\"\n                if dataset_drift\n                else \"No significant drift detected\"\n            ),\n        )\n\n    def _trigger_alert(self, result: DriftResult) -> None:\n        \"\"\"Trigger drift alert callbacks.\n\n        Args:\n            result: Drift result that triggered the alert.\n        \"\"\"\n        # Determine severity\n        severity = \"critical\" if self._consecutive_drift_count >= 3 else \"warning\"\n\n        alert = DriftAlert(\n            drift_result=result,\n            severity=severity,\n        )\n\n        # Store alert\n        self._pending_alerts.append(alert)\n\n        # Call callbacks (outside lock if possible, but we're already in lock)\n        for callback in self._alert_callbacks:\n            try:\n                callback(alert)\n            except Exception as e:\n                logger.error(f\"Alert callback error: {e}\")\n\n    def get_reference_data(self) -> pd.DataFrame:\n        \"\"\"Get reference data as DataFrame.\n\n        Returns:\n            Reference DataFrame.\n        \"\"\"\n        with self._lock:\n            if not self._reference_data:\n                return pd.DataFrame()\n            return self._to_dataframe(list(self._reference_data))\n\n    def get_current_data(self) -> pd.DataFrame:\n        \"\"\"Get current data as DataFrame.\n\n        Returns:\n            Current DataFrame.\n        \"\"\"\n        with self._lock:\n            if not self._current_data:\n                return pd.DataFrame()\n            return self._to_dataframe(list(self._current_data))\n\n    def generate_html_report(self, output_path: str) -> bool:\n        \"\"\"Generate an HTML drift report.\n\n        Args:\n            output_path: Path to save the HTML report.\n\n        Returns:\n            True if report was generated successfully.\n        \"\"\"\n        with self._lock:\n            if (\n                len(self._reference_data) < self.min_samples_for_drift\n                or len(self._current_data) < self.min_samples_for_drift\n            ):\n                logger.warning(\"Insufficient data for HTML report\")\n                return False\n\n            try:\n                reference_df = self._to_dataframe(list(self._reference_data))\n                current_df = self._to_dataframe(list(self._current_data))\n\n                # Ensure same columns\n                common_columns = list(set(reference_df.columns) & set(current_df.columns))\n                feature_columns = [c for c in common_columns if not str(c).startswith(\"_\")]\n\n                if not feature_columns:\n                    return False\n\n                reference_df = reference_df[feature_columns]\n                current_df = current_df[feature_columns]\n\n                drift_report = Report(\n                    metrics=[DataDriftPreset(drift_share=self.drift_share_threshold)]\n                )\n                drift_report.run(\n                    reference_data=reference_df,\n                    current_data=current_df,\n                )\n                drift_report.save_html(output_path)\n\n                logger.info(f\"Drift report saved to {output_path}\")\n                return True\n\n            except Exception as e:\n                logger.error(f\"Error generating HTML report: {e}\")\n                return False\n\n    def __repr__(self) -> str:\n        \"\"\"String representation of the detector.\"\"\"\n        return (\n            f\"DriftDetector(\"\n            f\"status={self._current_status.value}, \"\n            f\"ref_size={len(self._reference_data)}, \"\n            f\"cur_size={len(self._current_data)}, \"\n            f\"checks={self._total_checks}, \"\n            f\"drifts={self._drift_detections})\"\n        )\n",
        "timestamp": "2026-01-03T19:07:33.686648"
      },
      "worktree_state": {
        "content": "\"\"\"\nAdaptive Learning Engine - Drift Detector\nConstitutional Hash: cdd01ef066bc6cf2\n\nEvidently-based concept drift detection for monitoring model performance.\nCompares reference (baseline) vs. current (recent) data distributions\nto detect when the model needs updating or rollback.\n\"\"\"\n\nimport asyncio\nimport hashlib\nimport logging\nimport threading\nimport time\nfrom collections import deque\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Callable, Deque, Dict, List, Optional\n\nimport numpy as np\nimport pandas as pd\nfrom evidently.metric_preset import DataDriftPreset\nfrom evidently.report import Report\n\nlogger = logging.getLogger(__name__)\n\n\nclass DriftStatus(Enum):\n    \"\"\"Current drift detection status.\"\"\"\n\n    NO_DRIFT = \"no_drift\"  # No significant drift detected\n    DRIFT_DETECTED = \"drift_detected\"  # Significant drift detected\n    INSUFFICIENT_DATA = \"insufficient_data\"  # Not enough data for detection\n    DISABLED = \"disabled\"  # Drift detection is disabled\n    ERROR = \"error\"  # Error during drift detection\n\n\n@dataclass\nclass DriftResult:\n    \"\"\"Result from a drift detection check.\"\"\"\n\n    status: DriftStatus\n    drift_detected: bool\n    drift_score: float  # Share of drifted columns (0.0 - 1.0)\n    drift_threshold: float\n    columns_drifted: Dict[str, bool]  # Per-column drift status\n    column_drift_scores: Dict[str, float]  # Per-column drift scores\n    reference_size: int\n    current_size: int\n    timestamp: float = field(default_factory=time.time)\n    message: str = \"\"\n\n\n@dataclass\nclass DriftAlert:\n    \"\"\"Alert generated when drift is detected.\"\"\"\n\n    drift_result: DriftResult\n    severity: str  # \"warning\" or \"critical\"\n    triggered_at: float = field(default_factory=time.time)\n    acknowledged: bool = False\n    alert_id: str = field(default_factory=lambda: f\"drift_{int(time.time() * 1000)}\")\n\n\n@dataclass\nclass DriftMetrics:\n    \"\"\"Aggregated drift detection metrics.\"\"\"\n\n    total_checks: int\n    drift_detections: int\n    last_check_time: Optional[float]\n    last_drift_time: Optional[float]\n    current_drift_score: float\n    average_drift_score: float\n    status: DriftStatus\n    consecutive_drift_count: int\n    data_points_collected: int\n\n\nclass DriftDetector:\n    \"\"\"Evidently-based drift detector for governance model monitoring.\n\n    Monitors concept drift by comparing reference (baseline) data distribution\n    against current (recent) prediction data. Uses Evidently's DataDriftPreset\n    which includes multiple statistical tests (K-S, PSI, etc.).\n\n    Features:\n    - Configurable drift threshold (PSI-based)\n    - Automatic reference data management\n    - Low-traffic detection (insufficient data warning)\n    - Alert callbacks for integration\n    - Thread-safe operations\n    - Graceful degradation on errors\n    - DataFrame caching for performance optimization\n\n    Caching:\n        The detector implements an intelligent caching system to avoid redundant\n        DataFrame conversions and drift report computations, significantly improving\n        performance when check_drift() is called repeatedly with unchanged data.\n\n        Caching Behavior:\n        - When enable_caching=True (default), caches reference/current DataFrames\n          and complete drift report results\n        - Cache keys are based on checksums of the underlying data (computed from\n          deque length and first/last items for performance)\n        - Cached DataFrames are reused in _to_dataframe() when data hasn't changed\n        - Cached drift reports are reused in check_drift() when both reference\n          and current data are unchanged\n\n        Cache Invalidation:\n        - Reference cache: Invalidated when reference data is modified (via\n          add_data_point while unlocked, set_reference_data, or\n          update_reference_from_current)\n        - Current cache: Invalidated on every add_data_point() call\n        - Report cache: Invalidated whenever reference or current data changes\n        - All caches: Cleared on reset()\n\n        Performance:\n        - Avoids expensive DataFrame conversions when data is unchanged\n        - Prevents redundant Evidently drift report computations\n        - Particularly beneficial for high-frequency drift checks\n\n        Disabling Caching:\n        - Set enable_caching=False to disable all caching behavior\n        - Useful for testing, debugging, or memory-constrained environments\n        - When disabled, all data is reprocessed on every check_drift() call\n\n    Example usage:\n        detector = DriftDetector(\n            drift_threshold=0.2,\n            reference_window_size=1000,\n            current_window_size=100,\n            enable_caching=True,  # Enable caching (default)\n        )\n\n        # Add prediction data\n        detector.add_data_point(features={\"f1\": 1.0, \"f2\": 2.0}, label=1)\n\n        # Check for drift (will compute and cache)\n        result = detector.check_drift()\n        if result.drift_detected:\n            print(f\"Drift detected! Score: {result.drift_score}\")\n\n        # Subsequent checks with same data will use cache\n        result2 = detector.check_drift()  # Returns cached result\n    \"\"\"\n\n    def __init__(\n        self,\n        drift_threshold: float = 0.2,\n        reference_window_size: int = 1000,\n        current_window_size: int = 100,\n        min_samples_for_drift: int = 10,\n        check_interval_seconds: int = 300,\n        drift_share_threshold: float = 0.5,\n        enabled: bool = True,\n        enable_caching: bool = True,\n    ) -> None:\n        \"\"\"Initialize the drift detector.\n\n        Args:\n            drift_threshold: PSI threshold for column drift (default 0.2).\n            reference_window_size: Number of samples in reference dataset.\n            current_window_size: Number of recent samples for comparison.\n            min_samples_for_drift: Minimum samples needed for drift check.\n            check_interval_seconds: Interval between automatic checks.\n            drift_share_threshold: Fraction of columns that must drift\n                to trigger dataset-level drift alert.\n            enabled: Whether drift detection is enabled.\n            enable_caching: Whether to cache DataFrame conversions and drift\n                reports for performance. When enabled, the detector caches\n                reference/current DataFrames and reuses them when data hasn't\n                changed (detected via checksums). Disable for testing or when\n                memory is constrained. Default is True.\n        \"\"\"\n        self.drift_threshold = drift_threshold\n        self.reference_window_size = reference_window_size\n        self.current_window_size = current_window_size\n        self.min_samples_for_drift = min_samples_for_drift\n        self.check_interval_seconds = check_interval_seconds\n        self.drift_share_threshold = drift_share_threshold\n        self._enabled = enabled\n\n        # Thread safety\n        self._lock = threading.RLock()\n\n        # Data storage\n        self._reference_data: Deque[Dict[str, Any]] = deque(maxlen=reference_window_size)\n        self._current_data: Deque[Dict[str, Any]] = deque(maxlen=current_window_size)\n        self._all_data: Deque[Dict[str, Any]] = deque(\n            maxlen=reference_window_size + current_window_size\n        )\n\n        # State tracking\n        self._reference_locked = False  # Whether reference data is frozen\n        self._last_check_time: Optional[float] = None\n        self._last_drift_time: Optional[float] = None\n        self._total_checks = 0\n        self._drift_detections = 0\n        self._consecutive_drift_count = 0\n        self._drift_score_history: Deque[float] = deque(maxlen=100)\n        self._current_status = DriftStatus.INSUFFICIENT_DATA if enabled else DriftStatus.DISABLED\n\n        # Alert callbacks\n        self._alert_callbacks: List[Callable[[DriftAlert], None]] = []\n        self._pending_alerts: Deque[DriftAlert] = deque(maxlen=100)\n\n        # Column tracking\n        self._known_columns: set = set()\n\n        # Caching infrastructure\n        self._cache_enabled = enable_caching\n        self._reference_df_cache: Optional[pd.DataFrame] = None\n        self._current_df_cache: Optional[pd.DataFrame] = None\n        self._reference_checksum: Optional[str] = None\n        self._current_checksum: Optional[str] = None\n        self._last_report_cache: Optional[DriftResult] = None\n        self._report_cache_checksum: Optional[str] = None\n\n        logger.info(\n            \"DriftDetector initialized\",\n            extra={\n                \"drift_threshold\": drift_threshold,\n                \"reference_window_size\": reference_window_size,\n                \"current_window_size\": current_window_size,\n                \"enabled\": enabled,\n                \"enable_caching\": enable_caching,\n            },\n        )\n\n    def add_data_point(\n        self,\n        features: Dict[str, Any],\n        label: Optional[int] = None,\n        prediction: Optional[int] = None,\n        timestamp: Optional[float] = None,\n    ) -> None:\n        \"\"\"Add a single data point for drift monitoring.\n\n        Args:\n            features: Feature dictionary with numeric values.\n            label: Optional true label.\n            prediction: Optional model prediction.\n            timestamp: Optional timestamp (uses current time if not provided).\n        \"\"\"\n        if not self._enabled:\n            return\n\n        with self._lock:\n            # Build data record\n            record = features.copy()\n\n            # Add optional fields\n            if label is not None:\n                record[\"_label\"] = label\n            if prediction is not None:\n                record[\"_prediction\"] = prediction\n            record[\"_timestamp\"] = timestamp or time.time()\n\n            # Update known columns\n            self._known_columns.update(k for k in features.keys() if not k.startswith(\"_\"))\n\n            # Add to current data window\n            self._current_data.append(record)\n            self._all_data.append(record)\n\n            # If reference is not locked, also add to reference\n            if not self._reference_locked:\n                self._reference_data.append(record)\n\n            # Invalidate caches after data changes\n            self._invalidate_current_cache()  # Current data always changes\n            if not self._reference_locked:\n                self._clear_reference_cache()  # Reference data changes if not locked\n\n    def add_batch(\n        self,\n        data_points: List[Dict[str, Any]],\n        labels: Optional[List[int]] = None,\n        predictions: Optional[List[int]] = None,\n    ) -> int:\n        \"\"\"Add multiple data points at once.\n\n        Args:\n            data_points: List of feature dictionaries.\n            labels: Optional list of true labels.\n            predictions: Optional list of model predictions.\n\n        Returns:\n            Number of points added.\n        \"\"\"\n        count = 0\n        for i, features in enumerate(data_points):\n            label = labels[i] if labels and i < len(labels) else None\n            prediction = predictions[i] if predictions and i < len(predictions) else None\n            self.add_data_point(features=features, label=label, prediction=prediction)\n            count += 1\n        return count\n\n    def lock_reference_data(self) -> None:\n        \"\"\"Lock the reference data to prevent further updates.\n\n        Call this once you have enough baseline data to establish\n        a reference distribution for drift comparison.\n        \"\"\"\n        with self._lock:\n            self._reference_locked = True\n            logger.info(\n                \"Reference data locked\",\n                extra={\"reference_size\": len(self._reference_data)},\n            )\n\n    def unlock_reference_data(self) -> None:\n        \"\"\"Unlock reference data to allow updates.\"\"\"\n        with self._lock:\n            self._reference_locked = False\n            logger.info(\"Reference data unlocked\")\n\n    def update_reference_from_current(self) -> int:\n        \"\"\"Update reference data with current data.\n\n        Useful for resetting the reference baseline after model updates.\n\n        Returns:\n            Number of points in new reference.\n        \"\"\"\n        with self._lock:\n            # Copy current data to reference\n            self._reference_data.clear()\n            self._reference_data.extend(self._current_data)\n            self._reference_locked = True\n            # Invalidate reference cache after copying current to reference\n            self._clear_reference_cache()\n            logger.info(\n                \"Reference data updated from current\",\n                extra={\"reference_size\": len(self._reference_data)},\n            )\n            return len(self._reference_data)\n\n    def set_reference_data(self, reference_df: pd.DataFrame) -> None:\n        \"\"\"Set reference data from a DataFrame.\n\n        Args:\n            reference_df: DataFrame with feature columns.\n        \"\"\"\n        with self._lock:\n            self._reference_data.clear()\n            for _, row in reference_df.iterrows():\n                self._reference_data.append(row.to_dict())\n            self._reference_locked = True\n            self._known_columns.update(\n                c for c in reference_df.columns if not str(c).startswith(\"_\")\n            )\n            # Invalidate reference cache after setting new reference data\n            self._clear_reference_cache()\n            logger.info(\n                \"Reference data set from DataFrame\",\n                extra={\"reference_size\": len(self._reference_data)},\n            )\n\n    def check_drift(self) -> DriftResult:\n        \"\"\"Check for data drift between reference and current data.\n\n        Uses Evidently's DataDriftPreset which includes multiple\n        statistical tests (K-S test, PSI, etc.) to detect distribution shifts.\n\n        Caching Behavior:\n            When enable_caching=True (set in __init__), this method implements\n            intelligent result caching to avoid redundant computations:\n\n            - Computes checksums of reference and current data deques\n            - If both checksums match the last check, returns cached DriftResult\n            - If data has changed, performs full drift detection and caches result\n            - Cache includes complete DriftResult (status, scores, column details)\n            - Timestamp is updated to reflect current check time even for cached results\n\n            Cache Invalidation:\n            - Automatically invalidated when reference or current data changes\n            - add_data_point() invalidates current cache (and report cache)\n            - set_reference_data() and update_reference_from_current() invalidate\n              reference cache (and report cache)\n            - reset() clears all caches\n\n            Performance:\n            - Cached checks are ~100-1000x faster than full drift computation\n            - Particularly beneficial when checking drift frequently (e.g., every\n              prediction) but data changes slowly (e.g., batch updates)\n            - No performance penalty when caching is disabled (enable_caching=False)\n\n        Returns:\n            DriftResult with drift status, scores, and details. The result may\n            be freshly computed or retrieved from cache, depending on whether\n            the underlying data has changed since the last check.\n        \"\"\"\n        with self._lock:\n            timestamp = time.time()\n            self._last_check_time = timestamp\n            self._total_checks += 1\n\n            # Check if disabled\n            if not self._enabled:\n                return DriftResult(\n                    status=DriftStatus.DISABLED,\n                    drift_detected=False,\n                    drift_score=0.0,\n                    drift_threshold=self.drift_threshold,\n                    columns_drifted={},\n                    column_drift_scores={},\n                    reference_size=0,\n                    current_size=0,\n                    timestamp=timestamp,\n                    message=\"Drift detection is disabled\",\n                )\n\n            # Check for sufficient data\n            ref_size = len(self._reference_data)\n            cur_size = len(self._current_data)\n\n            if ref_size < self.min_samples_for_drift:\n                self._current_status = DriftStatus.INSUFFICIENT_DATA\n                return DriftResult(\n                    status=DriftStatus.INSUFFICIENT_DATA,\n                    drift_detected=False,\n                    drift_score=0.0,\n                    drift_threshold=self.drift_threshold,\n                    columns_drifted={},\n                    column_drift_scores={},\n                    reference_size=ref_size,\n                    current_size=cur_size,\n                    timestamp=timestamp,\n                    message=f\"Insufficient reference data: {ref_size} < {self.min_samples_for_drift}\",\n                )\n\n            if cur_size < self.min_samples_for_drift:\n                self._current_status = DriftStatus.INSUFFICIENT_DATA\n                return DriftResult(\n                    status=DriftStatus.INSUFFICIENT_DATA,\n                    drift_detected=False,\n                    drift_score=0.0,\n                    drift_threshold=self.drift_threshold,\n                    columns_drifted={},\n                    column_drift_scores={},\n                    reference_size=ref_size,\n                    current_size=cur_size,\n                    timestamp=timestamp,\n                    message=f\"Insufficient current data: {cur_size} < {self.min_samples_for_drift}\",\n                )\n\n            # Compute combined checksum for caching\n            combined_checksum = None\n            if self._cache_enabled:\n                ref_checksum = self._compute_deque_checksum(self._reference_data)\n                cur_checksum = self._compute_deque_checksum(self._current_data)\n                combined_checksum = hashlib.md5(\n                    f\"{ref_checksum}|{cur_checksum}\".encode(\"utf-8\"),\n                    usedforsecurity=False\n                ).hexdigest()\n\n                # Check cache: if reference + current data hasn't changed, return cached result\n                if (\n                    combined_checksum == self._report_cache_checksum\n                    and self._last_report_cache is not None\n                ):\n                    logger.debug(\"Returning cached drift result\")\n                    # Update timestamp to reflect when check was requested, not when it was computed\n                    cached_result = self._last_report_cache\n                    return DriftResult(\n                        status=cached_result.status,\n                        drift_detected=cached_result.drift_detected,\n                        drift_score=cached_result.drift_score,\n                        drift_threshold=cached_result.drift_threshold,\n                        columns_drifted=cached_result.columns_drifted,\n                        column_drift_scores=cached_result.column_drift_scores,\n                        reference_size=cached_result.reference_size,\n                        current_size=cached_result.current_size,\n                        timestamp=timestamp,  # Use current request time\n                        message=cached_result.message,\n                    )\n\n            try:\n                # Convert to DataFrames (with caching)\n                reference_df = self._to_dataframe(list(self._reference_data), data_source=\"reference\")\n                current_df = self._to_dataframe(list(self._current_data), data_source=\"current\")\n\n                # Ensure same columns\n                common_columns = list(set(reference_df.columns) & set(current_df.columns))\n                # Filter out internal columns\n                feature_columns = [c for c in common_columns if not str(c).startswith(\"_\")]\n\n                if not feature_columns:\n                    return DriftResult(\n                        status=DriftStatus.ERROR,\n                        drift_detected=False,\n                        drift_score=0.0,\n                        drift_threshold=self.drift_threshold,\n                        columns_drifted={},\n                        column_drift_scores={},\n                        reference_size=ref_size,\n                        current_size=cur_size,\n                        timestamp=timestamp,\n                        message=\"No common feature columns found\",\n                    )\n\n                reference_df = reference_df[feature_columns]\n                current_df = current_df[feature_columns]\n\n                # Run Evidently drift detection\n                drift_report = Report(\n                    metrics=[\n                        DataDriftPreset(\n                            drift_share=self.drift_share_threshold,\n                        )\n                    ]\n                )\n                drift_report.run(\n                    reference_data=reference_df,\n                    current_data=current_df,\n                )\n\n                # Extract results\n                report_dict = drift_report.as_dict()\n\n                # Parse drift results from report\n                result = self._parse_drift_report(\n                    report_dict=report_dict,\n                    ref_size=ref_size,\n                    cur_size=cur_size,\n                    timestamp=timestamp,\n                )\n\n                # Update tracking\n                self._drift_score_history.append(result.drift_score)\n\n                if result.drift_detected:\n                    self._drift_detections += 1\n                    self._consecutive_drift_count += 1\n                    self._last_drift_time = timestamp\n                    self._current_status = DriftStatus.DRIFT_DETECTED\n\n                    # Trigger alert\n                    self._trigger_alert(result)\n\n                    logger.warning(\n                        \"Drift detected\",\n                        extra={\n                            \"drift_score\": result.drift_score,\n                            \"threshold\": self.drift_threshold,\n                            \"columns_drifted\": sum(result.columns_drifted.values()),\n                        },\n                    )\n                else:\n                    self._consecutive_drift_count = 0\n                    self._current_status = DriftStatus.NO_DRIFT\n\n                # Cache the result if caching is enabled\n                if self._cache_enabled and combined_checksum is not None:\n                    self._last_report_cache = result\n                    self._report_cache_checksum = combined_checksum\n\n                return result\n\n            except Exception as e:\n                # Graceful degradation: log error but don't crash\n                logger.error(f\"Drift detection error: {e}\", exc_info=True)\n                self._current_status = DriftStatus.ERROR\n                return DriftResult(\n                    status=DriftStatus.ERROR,\n                    drift_detected=False,\n                    drift_score=0.0,\n                    drift_threshold=self.drift_threshold,\n                    columns_drifted={},\n                    column_drift_scores={},\n                    reference_size=ref_size,\n                    current_size=cur_size,\n                    timestamp=timestamp,\n                    message=f\"Error during drift detection: {str(e)}\",\n                )\n\n    async def check_drift_async(self) -> DriftResult:\n        \"\"\"Async version of check_drift for non-blocking operation.\n\n        Returns:\n            DriftResult with drift status, scores, and details.\n        \"\"\"\n        # Run sync check in thread pool to avoid blocking\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, self.check_drift)\n\n    def get_status(self) -> DriftResult:\n        \"\"\"Get current drift status without running a new check.\n\n        Returns:\n            Last drift result or default if no checks performed.\n        \"\"\"\n        with self._lock:\n            timestamp = time.time()\n\n            if self._last_check_time is None:\n                return DriftResult(\n                    status=self._current_status,\n                    drift_detected=False,\n                    drift_score=0.0,\n                    drift_threshold=self.drift_threshold,\n                    columns_drifted={},\n                    column_drift_scores={},\n                    reference_size=len(self._reference_data),\n                    current_size=len(self._current_data),\n                    timestamp=timestamp,\n                    message=\"No drift check performed yet\",\n                )\n\n            # Return current status\n            return DriftResult(\n                status=self._current_status,\n                drift_detected=self._current_status == DriftStatus.DRIFT_DETECTED,\n                drift_score=(self._drift_score_history[-1] if self._drift_score_history else 0.0),\n                drift_threshold=self.drift_threshold,\n                columns_drifted={},\n                column_drift_scores={},\n                reference_size=len(self._reference_data),\n                current_size=len(self._current_data),\n                timestamp=self._last_check_time,\n                message=f\"Last check at {datetime.fromtimestamp(self._last_check_time).isoformat()}\",\n            )\n\n    def get_metrics(self) -> DriftMetrics:\n        \"\"\"Get aggregated drift detection metrics.\n\n        Returns:\n            DriftMetrics with check counts and statistics.\n        \"\"\"\n        with self._lock:\n            avg_score = (\n                float(np.mean(list(self._drift_score_history)))\n                if self._drift_score_history\n                else 0.0\n            )\n            current_score = self._drift_score_history[-1] if self._drift_score_history else 0.0\n\n            return DriftMetrics(\n                total_checks=self._total_checks,\n                drift_detections=self._drift_detections,\n                last_check_time=self._last_check_time,\n                last_drift_time=self._last_drift_time,\n                current_drift_score=current_score,\n                average_drift_score=avg_score,\n                status=self._current_status,\n                consecutive_drift_count=self._consecutive_drift_count,\n                data_points_collected=len(self._all_data),\n            )\n\n    def register_alert_callback(self, callback: Callable[[DriftAlert], None]) -> None:\n        \"\"\"Register a callback for drift alerts.\n\n        Args:\n            callback: Function called when drift is detected.\n        \"\"\"\n        with self._lock:\n            self._alert_callbacks.append(callback)\n\n    def get_pending_alerts(self) -> List[DriftAlert]:\n        \"\"\"Get list of unacknowledged alerts.\n\n        Returns:\n            List of DriftAlert objects.\n        \"\"\"\n        with self._lock:\n            return [a for a in self._pending_alerts if not a.acknowledged]\n\n    def acknowledge_alert(self, alert_id: str) -> bool:\n        \"\"\"Acknowledge a drift alert.\n\n        Args:\n            alert_id: ID of the alert to acknowledge.\n\n        Returns:\n            True if alert was found and acknowledged.\n        \"\"\"\n        with self._lock:\n            for alert in self._pending_alerts:\n                if alert.alert_id == alert_id:\n                    alert.acknowledged = True\n                    return True\n            return False\n\n    def enable(self) -> None:\n        \"\"\"Enable drift detection.\"\"\"\n        with self._lock:\n            self._enabled = True\n            self._current_status = (\n                DriftStatus.INSUFFICIENT_DATA\n                if len(self._reference_data) < self.min_samples_for_drift\n                else DriftStatus.NO_DRIFT\n            )\n            logger.info(\"Drift detection enabled\")\n\n    def disable(self) -> None:\n        \"\"\"Disable drift detection.\"\"\"\n        with self._lock:\n            self._enabled = False\n            self._current_status = DriftStatus.DISABLED\n            logger.info(\"Drift detection disabled\")\n\n    def is_enabled(self) -> bool:\n        \"\"\"Check if drift detection is enabled.\"\"\"\n        return self._enabled\n\n    def reset(self) -> None:\n        \"\"\"Reset detector to initial state.\n\n        Clears all data and resets metrics.\n        \"\"\"\n        with self._lock:\n            self._reference_data.clear()\n            self._current_data.clear()\n            self._all_data.clear()\n            self._reference_locked = False\n            self._last_check_time = None\n            self._last_drift_time = None\n            self._total_checks = 0\n            self._drift_detections = 0\n            self._consecutive_drift_count = 0\n            self._drift_score_history.clear()\n            self._pending_alerts.clear()\n            self._known_columns.clear()\n            self._current_status = (\n                DriftStatus.INSUFFICIENT_DATA if self._enabled else DriftStatus.DISABLED\n            )\n            # Clear cache fields\n            self._reference_df_cache = None\n            self._current_df_cache = None\n            self._reference_checksum = None\n            self._current_checksum = None\n            self._last_report_cache = None\n            self._report_cache_checksum = None\n            logger.info(\"DriftDetector reset\")\n\n    def _compute_deque_checksum(self, data: Deque[Dict[str, Any]], num_items: int = 3) -> str:\n        \"\"\"Compute a fast checksum of deque data to detect changes.\n\n        Uses length + hash of first/last few items for performance.\n        This allows detecting data changes without converting the entire\n        deque to a DataFrame or hashing all items.\n\n        Args:\n            data: Deque of data dictionaries.\n            num_items: Number of items to hash from start and end (default 3).\n\n        Returns:\n            Hex string checksum representing the data.\n        \"\"\"\n        if not data:\n            return hashlib.md5(b\"empty\", usedforsecurity=False).hexdigest()\n\n        # Start with length\n        components = [str(len(data))]\n\n        # Hash first few items\n        first_items = list(data)[:num_items]\n        for item in first_items:\n            # Convert dict to sorted tuple of items for consistent hashing\n            item_str = str(sorted(item.items()))\n            components.append(item_str)\n\n        # Hash last few items (if different from first)\n        if len(data) > num_items:\n            last_items = list(data)[-num_items:]\n            for item in last_items:\n                item_str = str(sorted(item.items()))\n                components.append(item_str)\n\n        # Combine all components and hash\n        combined = \"|\".join(components)\n        checksum = hashlib.md5(combined.encode(\"utf-8\"), usedforsecurity=False).hexdigest()\n\n        return checksum\n\n    def _invalidate_current_cache(self) -> None:\n        \"\"\"Invalidate current data cache and related report cache.\n\n        Should be called whenever the current data deque is modified.\n        Clears both the DataFrame cache and the report result cache,\n        since they depend on the current data.\n        \"\"\"\n        self._current_df_cache = None\n        self._current_checksum = None\n        # Report cache depends on both reference and current data,\n        # so invalidate it when current data changes\n        self._last_report_cache = None\n        self._report_cache_checksum = None\n\n    def _clear_reference_cache(self) -> None:\n        \"\"\"Clear reference data cache and related report cache.\n\n        Should be called whenever the reference data deque is modified.\n        Clears both the DataFrame cache and the report result cache,\n        since they depend on the reference data.\n        \"\"\"\n        self._reference_df_cache = None\n        self._reference_checksum = None\n        # Report cache depends on both reference and current data,\n        # so invalidate it when reference data changes\n        self._last_report_cache = None\n        self._report_cache_checksum = None\n\n    def _to_dataframe(\n        self, data: List[Dict[str, Any]], data_source: Optional[str] = None\n    ) -> pd.DataFrame:\n        \"\"\"Convert list of dictionaries to DataFrame.\n\n        Filters to numeric columns only for drift detection.\n\n        Args:\n            data: List of feature dictionaries.\n            data_source: Optional identifier for cache lookup ('reference' or 'current').\n                Used to enable DataFrame caching for performance optimization.\n\n        Returns:\n            DataFrame with numeric columns.\n        \"\"\"\n        # Check cache if enabled and data_source is provided\n        cache_checksum = None\n        if self._cache_enabled and data_source:\n            # Compute checksum of current data\n            current_checksum = self._compute_deque_checksum(deque(data))\n\n            # Try to return cached DataFrame\n            if data_source == \"reference\":\n                if (\n                    self._reference_checksum == current_checksum\n                    and self._reference_df_cache is not None\n                ):\n                    return self._reference_df_cache\n            elif data_source == \"current\":\n                if (\n                    self._current_checksum == current_checksum\n                    and self._current_df_cache is not None\n                ):\n                    return self._current_df_cache\n\n            # Cache miss - will need to convert and update cache\n            cache_checksum = current_checksum\n\n        # Convert to DataFrame\n        df = pd.DataFrame(data)\n\n        # Select only numeric columns\n        numeric_df = df.select_dtypes(include=[np.number])\n\n        # Update cache if we computed a checksum (caching enabled with data_source)\n        if cache_checksum is not None:\n            if data_source == \"reference\":\n                self._reference_df_cache = numeric_df\n                self._reference_checksum = cache_checksum\n            elif data_source == \"current\":\n                self._current_df_cache = numeric_df\n                self._current_checksum = cache_checksum\n\n        return numeric_df\n\n    def _parse_drift_report(\n        self,\n        report_dict: Dict[str, Any],\n        ref_size: int,\n        cur_size: int,\n        timestamp: float,\n    ) -> DriftResult:\n        \"\"\"Parse Evidently drift report into DriftResult.\n\n        Args:\n            report_dict: Evidently report as dictionary.\n            ref_size: Reference data size.\n            cur_size: Current data size.\n            timestamp: Check timestamp.\n\n        Returns:\n            Parsed DriftResult.\n        \"\"\"\n        columns_drifted: Dict[str, bool] = {}\n        column_drift_scores: Dict[str, float] = {}\n        dataset_drift = False\n        share_of_drifted_columns = 0.0\n\n        try:\n            metrics_list = report_dict.get(\"metrics\", [])\n\n            for metric in metrics_list:\n                result = metric.get(\"result\", {})\n\n                # Dataset-level drift\n                if \"dataset_drift\" in result:\n                    dataset_drift = result[\"dataset_drift\"]\n                    share_of_drifted_columns = result.get(\"share_of_drifted_columns\", 0.0)\n\n                # Column-level drift\n                drift_by_columns = result.get(\"drift_by_columns\", {})\n                for col_name, col_data in drift_by_columns.items():\n                    if isinstance(col_data, dict):\n                        columns_drifted[col_name] = col_data.get(\"drift_detected\", False)\n                        # Try to get drift score (p-value or statistic varies by test)\n                        drift_score = col_data.get(\"drift_score\", 0.0)\n                        if drift_score is None:\n                            drift_score = col_data.get(\"stattest_score\", 0.0) or 0.0\n                        column_drift_scores[col_name] = float(drift_score)\n\n        except Exception as e:\n            logger.warning(f\"Error parsing drift report: {e}\")\n\n        # Build result\n        status = DriftStatus.DRIFT_DETECTED if dataset_drift else DriftStatus.NO_DRIFT\n        num_drifted = sum(1 for v in columns_drifted.values() if v)\n\n        return DriftResult(\n            status=status,\n            drift_detected=dataset_drift,\n            drift_score=share_of_drifted_columns,\n            drift_threshold=self.drift_threshold,\n            columns_drifted=columns_drifted,\n            column_drift_scores=column_drift_scores,\n            reference_size=ref_size,\n            current_size=cur_size,\n            timestamp=timestamp,\n            message=(\n                f\"Drift detected in {num_drifted} columns\"\n                if dataset_drift\n                else \"No significant drift detected\"\n            ),\n        )\n\n    def _trigger_alert(self, result: DriftResult) -> None:\n        \"\"\"Trigger drift alert callbacks.\n\n        Args:\n            result: Drift result that triggered the alert.\n        \"\"\"\n        # Determine severity\n        severity = \"critical\" if self._consecutive_drift_count >= 3 else \"warning\"\n\n        alert = DriftAlert(\n            drift_result=result,\n            severity=severity,\n        )\n\n        # Store alert\n        self._pending_alerts.append(alert)\n\n        # Call callbacks (outside lock if possible, but we're already in lock)\n        for callback in self._alert_callbacks:\n            try:\n                callback(alert)\n            except Exception as e:\n                logger.error(f\"Alert callback error: {e}\")\n\n    def get_reference_data(self) -> pd.DataFrame:\n        \"\"\"Get reference data as DataFrame.\n\n        Returns:\n            Reference DataFrame.\n        \"\"\"\n        with self._lock:\n            if not self._reference_data:\n                return pd.DataFrame()\n            return self._to_dataframe(list(self._reference_data), data_source=\"reference\")\n\n    def get_current_data(self) -> pd.DataFrame:\n        \"\"\"Get current data as DataFrame.\n\n        Returns:\n            Current DataFrame.\n        \"\"\"\n        with self._lock:\n            if not self._current_data:\n                return pd.DataFrame()\n            return self._to_dataframe(list(self._current_data), data_source=\"current\")\n\n    def generate_html_report(self, output_path: str) -> bool:\n        \"\"\"Generate an HTML drift report.\n\n        Args:\n            output_path: Path to save the HTML report.\n\n        Returns:\n            True if report was generated successfully.\n        \"\"\"\n        with self._lock:\n            if (\n                len(self._reference_data) < self.min_samples_for_drift\n                or len(self._current_data) < self.min_samples_for_drift\n            ):\n                logger.warning(\"Insufficient data for HTML report\")\n                return False\n\n            try:\n                reference_df = self._to_dataframe(list(self._reference_data), data_source=\"reference\")\n                current_df = self._to_dataframe(list(self._current_data), data_source=\"current\")\n\n                # Ensure same columns\n                common_columns = list(set(reference_df.columns) & set(current_df.columns))\n                feature_columns = [c for c in common_columns if not str(c).startswith(\"_\")]\n\n                if not feature_columns:\n                    return False\n\n                reference_df = reference_df[feature_columns]\n                current_df = current_df[feature_columns]\n\n                drift_report = Report(\n                    metrics=[DataDriftPreset(drift_share=self.drift_share_threshold)]\n                )\n                drift_report.run(\n                    reference_data=reference_df,\n                    current_data=current_df,\n                )\n                drift_report.save_html(output_path)\n\n                logger.info(f\"Drift report saved to {output_path}\")\n                return True\n\n            except Exception as e:\n                logger.error(f\"Error generating HTML report: {e}\")\n                return False\n\n    def __repr__(self) -> str:\n        \"\"\"String representation of the detector.\"\"\"\n        return (\n            f\"DriftDetector(\"\n            f\"status={self._current_status.value}, \"\n            f\"ref_size={len(self._reference_data)}, \"\n            f\"cur_size={len(self._current_data)}, \"\n            f\"checks={self._total_checks}, \"\n            f\"drifts={self._drift_detections})\"\n        )\n",
        "last_modified": "2026-01-03T19:08:21.370422"
      },
      "task_intent": {
        "title": "049-cache-drift-detection-report-results",
        "description": "The DriftDetector.check_drift() method creates a new Evidently Report object and runs full statistical analysis on every call. The _to_dataframe method also performs DataFrame conversion repeatedly from the same deque data without caching. This optimization adds intelligent caching to reduce CPU overhead in high-traffic scenarios (10,000+ RPS).",
        "from_plan": true
      },
      "commits_behind_main": 11,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:07:33.695960",
  "last_updated": "2026-01-03T19:07:33.698926"
}