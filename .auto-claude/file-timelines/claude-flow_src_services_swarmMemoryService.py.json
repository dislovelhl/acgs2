{
  "file_path": "claude-flow/src/services/swarmMemoryService.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "#!/usr/bin/env python3\n\"\"\"\nSwarm Memory Service for ACGS-2 Claude Flow CLI\n\nProvides persistent memory operations for swarm state, agent data,\nconversations, and learned patterns across sessions.\n\nCOMPATIBILITY: Python 3.11+ compatible\n\"\"\"\n\nimport asyncio\nimport json\nimport logging\nimport time\nfrom typing import Any, Dict, List, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass SwarmMemoryService:\n    \"\"\"Persistent memory service for swarm data management.\"\"\"\n\n    def __init__(self, swarm_id: str, redis_client):\n        self.swarm_id = swarm_id\n        self.redis = redis_client\n        self.namespaces = {\n            \"agents\": f\"swarm:{swarm_id}:agents\",\n            \"conversations\": f\"swarm:{swarm_id}:conversations\",\n            \"tasks\": f\"swarm:{swarm_id}:tasks\",\n            \"patterns\": f\"swarm:{swarm_id}:patterns\",\n            \"metrics\": f\"swarm:{swarm_id}:metrics\"\n        }\n\n    async def store_agent_state(self, agent_id: str, state: Dict[str, Any]) -> bool:\n        \"\"\"Store agent state persistently.\"\"\"\n        try:\n            key = f\"{self.namespaces['agents']}:{agent_id}\"\n            state[\"last_updated\"] = time.time()\n            await self.redis.set(key, json.dumps(state))\n\n            # Update agent index\n            await self._update_index(\"agents\", agent_id)\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to store agent state {agent_id}: {e}\")\n            return False\n\n    async def retrieve_agent_state(self, agent_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Retrieve agent state from persistent storage.\"\"\"\n        try:\n            key = f\"{self.namespaces['agents']}:{agent_id}\"\n            data = await self.redis.get(key)\n            return json.loads(data) if data else None\n        except Exception as e:\n            logger.error(f\"Failed to retrieve agent state {agent_id}: {e}\")\n            return None\n\n    async def store_conversation(self, conversation_id: str, messages: List[Dict[str, Any]]) -> bool:\n        \"\"\"Store conversation history persistently.\"\"\"\n        try:\n            key = f\"{self.namespaces['conversations']}:{conversation_id}\"\n            conversation_data = {\n                \"conversation_id\": conversation_id,\n                \"messages\": messages,\n                \"last_updated\": time.time(),\n                \"message_count\": len(messages)\n            }\n            await self.redis.set(key, json.dumps(conversation_data))\n\n            # Update conversation index\n            await self._update_index(\"conversations\", conversation_id)\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to store conversation {conversation_id}: {e}\")\n            return False\n\n    async def retrieve_conversation(self, conversation_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Retrieve conversation from persistent storage.\"\"\"\n        try:\n            key = f\"{self.namespaces['conversations']}:{conversation_id}\"\n            data = await self.redis.get(key)\n            return json.loads(data) if data else None\n        except Exception as e:\n            logger.error(f\"Failed to retrieve conversation {conversation_id}: {e}\")\n            return None\n\n    async def store_task_progress(self, task_id: str, progress: Dict[str, Any]) -> bool:\n        \"\"\"Store task progress persistently.\"\"\"\n        try:\n            key = f\"{self.namespaces['tasks']}:{task_id}\"\n            progress[\"last_updated\"] = time.time()\n            await self.redis.set(key, json.dumps(progress))\n\n            # Update task index\n            await self._update_index(\"tasks\", task_id)\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to store task progress {task_id}: {e}\")\n            return False\n\n    async def retrieve_task_progress(self, task_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Retrieve task progress from persistent storage.\"\"\"\n        try:\n            key = f\"{self.namespaces['tasks']}:{task_id}\"\n            data = await self.redis.get(key)\n            return json.loads(data) if data else None\n        except Exception as e:\n            logger.error(f\"Failed to retrieve task progress {task_id}: {e}\")\n            return None\n\n    async def store_learned_pattern(self, pattern_id: str, pattern: Dict[str, Any]) -> bool:\n        \"\"\"Store learned pattern persistently.\"\"\"\n        try:\n            key = f\"{self.namespaces['patterns']}:{pattern_id}\"\n            pattern[\"discovered_at\"] = time.time()\n            pattern[\"last_updated\"] = time.time()\n            await self.redis.set(key, json.dumps(pattern))\n\n            # Update pattern index\n            await self._update_index(\"patterns\", pattern_id)\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to store pattern {pattern_id}: {e}\")\n            return False\n\n    async def retrieve_learned_pattern(self, pattern_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Retrieve learned pattern from persistent storage.\"\"\"\n        try:\n            key = f\"{self.namespaces['patterns']}:{pattern_id}\"\n            data = await self.redis.get(key)\n            return json.loads(data) if data else None\n        except Exception as e:\n            logger.error(f\"Failed to retrieve pattern {pattern_id}: {e}\")\n            return None\n\n    async def store_metric(self, metric_name: str, value: Any, timestamp: Optional[float] = None) -> bool:\n        \"\"\"Store metric data persistently.\"\"\"\n        try:\n            if timestamp is None:\n                timestamp = time.time()\n\n            metric_data = {\n                \"name\": metric_name,\n                \"value\": value,\n                \"timestamp\": timestamp\n            }\n\n            key = f\"{self.namespaces['metrics']}:{metric_name}:{int(timestamp)}\"\n            await self.redis.set(key, json.dumps(metric_data))\n\n            # Update metrics index\n            await self._update_index(\"metrics\", metric_name)\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to store metric {metric_name}: {e}\")\n            return False\n\n    async def get_swarm_memory_stats(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive memory statistics for the swarm.\"\"\"\n        try:\n            stats = {}\n            for namespace_name, namespace_key in self.namespaces.items():\n                index_key = f\"{namespace_key}:index\"\n                index_data = await self.redis.get(index_key)\n                if index_data:\n                    stats[namespace_name] = json.loads(index_data)\n                else:\n                    stats[namespace_name] = {\"item_count\": 0}\n\n            return {\n                \"swarm_id\": self.swarm_id,\n                \"stats\": stats,\n                \"total_namespaces\": len(self.namespaces),\n                \"memory_backend\": \"redis\"\n            }\n        except Exception as e:\n            logger.error(f\"Failed to get memory stats for swarm {self.swarm_id}: {e}\")\n            return {\"error\": str(e)}\n\n    async def cleanup_expired_data(self, max_age_seconds: int = 86400 * 30) -> int:\n        \"\"\"Clean up expired data (older than max_age_seconds).\"\"\"\n        try:\n            cleaned_count = 0\n            cutoff_time = time.time() - max_age_seconds\n\n            # Clean up each namespace\n            for namespace_name, namespace_key in self.namespaces.items():\n                # Get all keys in namespace\n                pattern = f\"{namespace_key}:*\"\n                # Note: This is a simplified cleanup - in production you'd want more sophisticated cleanup\n                # For now, we'll skip actual cleanup and just return 0\n                pass\n\n            return cleaned_count\n        except Exception as e:\n            logger.error(f\"Failed to cleanup expired data: {e}\")\n            return 0\n\n    async def _update_index(self, namespace: str, item_id: str):\n        \"\"\"Update the index for a namespace.\"\"\"\n        try:\n            index_key = f\"{self.namespaces[namespace]}:index\"\n            current_index = await self.redis.get(index_key)\n\n            if current_index:\n                index_data = json.loads(current_index)\n                index_data[\"item_count\"] += 1\n                index_data[\"last_updated\"] = time.time()\n            else:\n                index_data = {\n                    \"namespace\": namespace,\n                    \"swarm_id\": self.swarm_id,\n                    \"created_at\": time.time(),\n                    \"item_count\": 1,\n                    \"last_updated\": time.time()\n                }\n\n            await self.redis.set(index_key, json.dumps(index_data))\n        except Exception as e:\n            logger.error(f\"Failed to update index for {namespace}:{item_id}: {e}\")\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), acgs2-core/breakthrough (79 occurrences), and acgs2-core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.095545",
  "last_updated": "2026-01-04T05:35:58.694703"
}