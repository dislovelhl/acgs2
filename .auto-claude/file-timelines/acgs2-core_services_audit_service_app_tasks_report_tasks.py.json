{
  "file_path": "src/core/services/audit_service/app/tasks/report_tasks.py",
  "main_branch_history": [],
  "task_views": {
    "060-document-error-codes-and-troubleshooting-for-commo": {
      "task_id": "060-document-error-codes-and-troubleshooting-for-commo",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nReport Generation Celery Tasks for Audit Service\nConstitutional Hash: cdd01ef066bc6cf2\n\nProvides background task execution for:\n- Scheduled report generation (PDF/CSV)\n- Email delivery of generated reports\n- Retry logic with exponential backoff\n\"\"\"\n\nimport logging\nimport os\nfrom dataclasses import dataclass\nfrom datetime import datetime, timezone\nfrom typing import Any, Dict, List, Optional\n\nfrom celery import shared_task\nfrom celery.exceptions import MaxRetriesExceededError\n\nlogger = logging.getLogger(__name__)\n\n# Report storage path from environment\nREPORT_STORAGE_PATH = os.getenv(\"REPORT_STORAGE_PATH\", \"/tmp/reports\")\n\n\n@dataclass\nclass ReportGenerationResult:\n    \"\"\"Result object for report generation tasks.\"\"\"\n\n    success: bool\n    report_id: str\n    tenant_id: str\n    framework: str\n    format: str\n    file_path: Optional[str] = None\n    file_size_bytes: Optional[int] = None\n    generated_at: Optional[str] = None\n    error_message: Optional[str] = None\n    email_sent: bool = False\n    email_recipients: Optional[List[str]] = None\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert result to dictionary for Celery serialization.\"\"\"\n        return {\n            \"success\": self.success,\n            \"report_id\": self.report_id,\n            \"tenant_id\": self.tenant_id,\n            \"framework\": self.framework,\n            \"format\": self.format,\n            \"file_path\": self.file_path,\n            \"file_size_bytes\": self.file_size_bytes,\n            \"generated_at\": self.generated_at,\n            \"error_message\": self.error_message,\n            \"email_sent\": self.email_sent,\n            \"email_recipients\": self.email_recipients,\n        }\n\n\ndef _get_report_generator():\n    \"\"\"\n    Lazy import of ComplianceReportGenerator to avoid circular imports.\n\n    Returns:\n        ComplianceReportGenerator class\n    \"\"\"\n    try:\n        from app.services.report_generator import ComplianceReportGenerator\n\n        return ComplianceReportGenerator\n    except ImportError:\n        # Fallback for different module contexts\n        from ..services.report_generator import ComplianceReportGenerator\n\n        return ComplianceReportGenerator\n\n\ndef _get_email_service():\n    \"\"\"\n    Lazy import of EmailService (may not exist yet).\n\n    Returns:\n        EmailService class or None if not available\n    \"\"\"\n    try:\n        from app.services.email_service import EmailService\n\n        return EmailService\n    except ImportError:\n        try:\n            from ..services.email_service import EmailService\n\n            return EmailService\n        except ImportError:\n            logger.warning(\"EmailService not available - email delivery disabled\")\n            return None\n\n\ndef _ensure_storage_directory():\n    \"\"\"Ensure the report storage directory exists.\"\"\"\n    os.makedirs(REPORT_STORAGE_PATH, exist_ok=True)\n\n\ndef _generate_report_id(tenant_id: str, framework: str) -> str:\n    \"\"\"Generate a unique report ID.\"\"\"\n    timestamp = int(datetime.now(timezone.utc).timestamp())\n    return f\"RPT-{tenant_id[:8].upper()}-{framework.upper()}-{timestamp}\"\n\n\ndef _fetch_logs_for_tenant(\n    tenant_id: str,\n    start_date: Optional[datetime] = None,\n    end_date: Optional[datetime] = None,\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Fetch decision logs for a tenant.\n\n    In a real implementation, this would query the audit ledger database.\n    For now, returns an empty list that can be mocked in tests.\n\n    Args:\n        tenant_id: Target tenant identifier\n        start_date: Optional start date for log filtering\n        end_date: Optional end date for log filtering\n\n    Returns:\n        List of decision log dictionaries\n    \"\"\"\n    # TODO: Implement actual log fetching from audit ledger\n    # This should integrate with the audit_ledger database or service\n    logger.info(\n        \"Fetching logs for tenant=%s, start_date=%s, end_date=%s\",\n        tenant_id,\n        start_date,\n        end_date,\n    )\n    return []\n\n\ndef _save_report_to_storage(\n    report_bytes: bytes,\n    report_id: str,\n    format: str,\n) -> str:\n    \"\"\"\n    Save generated report to storage.\n\n    Args:\n        report_bytes: Report content as bytes\n        report_id: Unique report identifier\n        format: Report format (pdf/csv)\n\n    Returns:\n        Full path to saved file\n    \"\"\"\n    _ensure_storage_directory()\n\n    extension = format.lower()\n    filename = f\"{report_id}.{extension}\"\n    file_path = os.path.join(REPORT_STORAGE_PATH, filename)\n\n    with open(file_path, \"wb\") as f:\n        f.write(report_bytes)\n\n    logger.info(\"Report saved to %s (%d bytes)\", file_path, len(report_bytes))\n    return file_path\n\n\n@shared_task(\n    bind=True,\n    name=\"audit_service.generate_scheduled_report\",\n    max_retries=3,\n    default_retry_delay=60,\n    autoretry_for=(Exception,),\n    retry_backoff=True,\n    retry_backoff_max=600,\n    retry_jitter=True,\n    acks_late=True,\n    queue=\"reports\",\n)\ndef generate_scheduled_report(\n    self,\n    tenant_id: str,\n    framework: str,\n    format: str = \"pdf\",\n    recipient_emails: Optional[List[str]] = None,\n    company_name: Optional[str] = None,\n    logo_url: Optional[str] = None,\n    brand_color: Optional[str] = None,\n) -> Dict[str, Any]:\n    \"\"\"\n    Celery task for generating scheduled compliance reports.\n\n    This task:\n    1. Fetches decision logs for the tenant\n    2. Generates a report in the specified format (PDF/CSV)\n    3. Saves the report to storage\n    4. Optionally sends the report via email to specified recipients\n\n    Args:\n        tenant_id: Target tenant identifier\n        framework: Compliance framework (ISO42001, SOC2, ISO27001, GDPR)\n        format: Output format (pdf or csv)\n        recipient_emails: Optional list of email addresses for delivery\n        company_name: Optional company name for branding (PDF only)\n        logo_url: Optional URL/path to company logo (PDF only)\n        brand_color: Optional brand color hex code (PDF only)\n\n    Returns:\n        Dictionary containing report generation results\n\n    Raises:\n        MaxRetriesExceededError: If all retry attempts fail\n    \"\"\"\n    report_id = _generate_report_id(tenant_id, framework)\n    generated_at = datetime.now(timezone.utc).isoformat()\n\n    logger.info(\n        \"Starting scheduled report generation: report_id=%s, tenant=%s, \"\n        \"framework=%s, format=%s, task_id=%s\",\n        report_id,\n        tenant_id,\n        framework,\n        format,\n        self.request.id,\n    )\n\n    try:\n        # Get the report generator\n        ReportGenerator = _get_report_generator()\n\n        # Fetch logs for the tenant\n        logs = _fetch_logs_for_tenant(tenant_id)\n\n        # Generate the report based on format\n        format_lower = format.lower()\n        if format_lower == \"pdf\":\n            report_bytes = ReportGenerator.generate_pdf_report(\n                logs=logs,\n                tenant_id=tenant_id,\n                framework=framework,\n                company_name=company_name,\n                logo_url=logo_url,\n                brand_color=brand_color,\n            )\n        elif format_lower == \"csv\":\n            report_bytes = ReportGenerator.generate_csv_bytes(\n                logs=logs,\n                tenant_id=tenant_id,\n            )\n        else:\n            raise ValueError(f\"Unsupported format: {format}. Must be 'pdf' or 'csv'\")\n\n        # Save report to storage\n        file_path = _save_report_to_storage(report_bytes, report_id, format_lower)\n        file_size = len(report_bytes)\n\n        logger.info(\n            \"Report generated successfully: report_id=%s, file_path=%s, \" \"size=%d bytes\",\n            report_id,\n            file_path,\n            file_size,\n        )\n\n        # Send email if recipients specified\n        email_sent = False\n        if recipient_emails:\n            email_sent = _send_report_email(\n                report_bytes=report_bytes,\n                report_id=report_id,\n                format=format_lower,\n                framework=framework,\n                tenant_id=tenant_id,\n                recipient_emails=recipient_emails,\n            )\n\n        result = ReportGenerationResult(\n            success=True,\n            report_id=report_id,\n            tenant_id=tenant_id,\n            framework=framework,\n            format=format_lower,\n            file_path=file_path,\n            file_size_bytes=file_size,\n            generated_at=generated_at,\n            email_sent=email_sent,\n            email_recipients=recipient_emails if email_sent else None,\n        )\n\n        return result.to_dict()\n\n    except MaxRetriesExceededError:\n        logger.error(\n            \"Max retries exceeded for report generation: report_id=%s, \" \"tenant=%s, framework=%s\",\n            report_id,\n            tenant_id,\n            framework,\n        )\n        result = ReportGenerationResult(\n            success=False,\n            report_id=report_id,\n            tenant_id=tenant_id,\n            framework=framework,\n            format=format,\n            generated_at=generated_at,\n            error_message=\"Max retries exceeded\",\n        )\n        return result.to_dict()\n\n    except Exception as e:\n        logger.error(\n            \"Report generation failed: report_id=%s, tenant=%s, framework=%s, \"\n            \"error=%s, retry=%d/%d\",\n            report_id,\n            tenant_id,\n            framework,\n            str(e),\n            self.request.retries,\n            self.max_retries,\n        )\n\n        # Retry with exponential backoff\n        # The task decorator handles retries automatically with autoretry_for\n        raise\n\n\ndef _send_report_email(\n    report_bytes: bytes,\n    report_id: str,\n    format: str,\n    framework: str,\n    tenant_id: str,\n    recipient_emails: List[str],\n) -> bool:\n    \"\"\"\n    Send report via email to specified recipients.\n\n    Args:\n        report_bytes: Report content as bytes\n        report_id: Unique report identifier\n        format: Report format (pdf/csv)\n        framework: Compliance framework name\n        tenant_id: Tenant identifier\n        recipient_emails: List of recipient email addresses\n\n    Returns:\n        True if email was sent successfully, False otherwise\n    \"\"\"\n    EmailService = _get_email_service()\n    if EmailService is None:\n        logger.warning(\n            \"Email service not available, skipping email delivery for report_id=%s\",\n            report_id,\n        )\n        return False\n\n    try:\n        report_name = f\"{framework} Compliance Report\"\n\n        for recipient in recipient_emails:\n            logger.info(\n                \"Sending report email: report_id=%s, recipient=%s\",\n                report_id,\n                recipient,\n            )\n            EmailService.send_report_email(\n                recipient=recipient,\n                pdf_bytes=report_bytes,\n                report_name=report_name,\n                format=format,\n            )\n\n        logger.info(\n            \"Report emails sent successfully: report_id=%s, recipients=%s\",\n            report_id,\n            recipient_emails,\n        )\n        return True\n\n    except Exception as e:\n        logger.error(\n            \"Failed to send report email: report_id=%s, error=%s\",\n            report_id,\n            str(e),\n        )\n        # Don't fail the task if email fails - report was still generated\n        return False\n\n\n@shared_task(\n    bind=True,\n    name=\"audit_service.generate_report_async\",\n    max_retries=3,\n    default_retry_delay=30,\n    autoretry_for=(Exception,),\n    retry_backoff=True,\n    retry_backoff_max=300,\n    retry_jitter=True,\n    acks_late=True,\n    queue=\"reports\",\n)\ndef generate_report_async(\n    self,\n    tenant_id: str,\n    framework: str,\n    format: str = \"pdf\",\n    logs: Optional[List[Dict[str, Any]]] = None,\n    company_name: Optional[str] = None,\n    logo_url: Optional[str] = None,\n    brand_color: Optional[str] = None,\n) -> Dict[str, Any]:\n    \"\"\"\n    Celery task for on-demand async report generation.\n\n    Unlike generate_scheduled_report, this task:\n    - Accepts pre-fetched logs directly (useful for API-triggered generation)\n    - Does not send emails automatically\n    - Has shorter retry delays for faster feedback\n\n    Args:\n        tenant_id: Target tenant identifier\n        framework: Compliance framework (ISO42001, SOC2, ISO27001, GDPR)\n        format: Output format (pdf or csv)\n        logs: Optional pre-fetched decision logs\n        company_name: Optional company name for branding (PDF only)\n        logo_url: Optional URL/path to company logo (PDF only)\n        brand_color: Optional brand color hex code (PDF only)\n\n    Returns:\n        Dictionary containing report generation results\n    \"\"\"\n    report_id = _generate_report_id(tenant_id, framework)\n    generated_at = datetime.now(timezone.utc).isoformat()\n\n    logger.info(\n        \"Starting async report generation: report_id=%s, tenant=%s, \"\n        \"framework=%s, format=%s, task_id=%s\",\n        report_id,\n        tenant_id,\n        framework,\n        format,\n        self.request.id,\n    )\n\n    try:\n        # Get the report generator\n        ReportGenerator = _get_report_generator()\n\n        # Use provided logs or fetch from storage\n        if logs is None:\n            logs = _fetch_logs_for_tenant(tenant_id)\n\n        # Generate the report based on format\n        format_lower = format.lower()\n        if format_lower == \"pdf\":\n            report_bytes = ReportGenerator.generate_pdf_report(\n                logs=logs,\n                tenant_id=tenant_id,\n                framework=framework,\n                company_name=company_name,\n                logo_url=logo_url,\n                brand_color=brand_color,\n            )\n        elif format_lower == \"csv\":\n            report_bytes = ReportGenerator.generate_csv_bytes(\n                logs=logs,\n                tenant_id=tenant_id,\n            )\n        else:\n            raise ValueError(f\"Unsupported format: {format}. Must be 'pdf' or 'csv'\")\n\n        # Save report to storage\n        file_path = _save_report_to_storage(report_bytes, report_id, format_lower)\n        file_size = len(report_bytes)\n\n        logger.info(\n            \"Async report generated successfully: report_id=%s, file_path=%s, \" \"size=%d bytes\",\n            report_id,\n            file_path,\n            file_size,\n        )\n\n        result = ReportGenerationResult(\n            success=True,\n            report_id=report_id,\n            tenant_id=tenant_id,\n            framework=framework,\n            format=format_lower,\n            file_path=file_path,\n            file_size_bytes=file_size,\n            generated_at=generated_at,\n        )\n\n        return result.to_dict()\n\n    except Exception as e:\n        logger.error(\n            \"Async report generation failed: report_id=%s, tenant=%s, \"\n            \"framework=%s, error=%s, retry=%d/%d\",\n            report_id,\n            tenant_id,\n            framework,\n            str(e),\n            self.request.retries,\n            self.max_retries,\n        )\n        raise\n",
        "timestamp": "2026-01-04T05:35:51.134105"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "060-document-error-codes-and-troubleshooting-for-commo",
        "description": "The codebase has 13 TODO/FIXME comments across critical files including webhooks.py, approval_chain_engine.py, and config_validator.py. Additionally, there's no centralized documentation for error codes, failure modes, or troubleshooting guides. Users encountering errors have no reference for resolution.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:08.581092",
  "last_updated": "2026-01-04T05:35:51.256118"
}