{
  "file_path": "claude-flow/src/services/analysisService.ts",
  "main_branch_history": [],
  "task_views": {
    "059-add-jsdoc-coverage-for-claude-flow-typescript-serv": {
      "task_id": "059-add-jsdoc-coverage-for-claude-flow-typescript-serv",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "import * as fs from 'fs';\nimport * as path from 'path';\nimport { spawn } from 'child_process';\n\nexport interface AnalysisOptions {\n  target: string;\n  focus: 'quality' | 'security' | 'performance' | 'architecture';\n  depth: 'quick' | 'deep';\n  format: 'text' | 'json' | 'report';\n  includePatterns: string[];\n  excludePatterns: string[];\n}\n\nexport interface AnalysisResult {\n  target: string;\n  focus: string;\n  depth: string;\n  format: string;\n  summary: {\n    filesAnalyzed: number;\n    totalLines: number;\n    analysisTime: number;\n  };\n  findings: Finding[];\n  recommendations: Recommendation[];\n  metrics: Record<string, any>;\n}\n\nexport interface Finding {\n  severity: 'critical' | 'high' | 'medium' | 'low' | 'info';\n  category: string;\n  message: string;\n  file?: string;\n  line?: number;\n  code?: string;\n  recommendation?: string;\n}\n\nexport interface Recommendation {\n  description: string;\n  priority: 'high' | 'medium' | 'low';\n  estimatedEffort: string;\n  benefits?: string;\n  category: string;\n}\n\nexport async function performAnalysis(options: AnalysisOptions): Promise<AnalysisResult> {\n  const startTime = Date.now();\n\n  try {\n    // Discover files to analyze\n    const files = discoverFiles(options.target, options.includePatterns, options.excludePatterns);\n\n    // Perform analysis based on focus\n    let findings: Finding[] = [];\n    let recommendations: Recommendation[] = [];\n    let metrics: Record<string, any> = {};\n\n    switch (options.focus) {\n      case 'quality':\n        ({ findings, recommendations, metrics } = await analyzeQuality(files, options.depth));\n        break;\n      case 'security':\n        ({ findings, recommendations, metrics } = await analyzeSecurity(files, options.depth));\n        break;\n      case 'performance':\n        ({ findings, recommendations, metrics } = await analyzePerformance(files, options.depth));\n        break;\n      case 'architecture':\n        ({ findings, recommendations, metrics } = await analyzeArchitecture(files, options.depth));\n        break;\n    }\n\n    // Calculate summary\n    const totalLines = await countTotalLines(files);\n    const analysisTime = Date.now() - startTime;\n\n    return {\n      target: options.target,\n      focus: options.focus,\n      depth: options.depth,\n      format: options.format,\n      summary: {\n        filesAnalyzed: files.length,\n        totalLines,\n        analysisTime\n      },\n      findings,\n      recommendations,\n      metrics\n    };\n\n  } catch (error) {\n    throw new Error(`Analysis failed: ${error instanceof Error ? error.message : String(error)}`);\n  }\n}\n\nfunction discoverFiles(target: string, includePatterns: string[], excludePatterns: string[]): string[] {\n  const allFiles: string[] = [];\n\n  function walkDir(dir: string): void {\n    try {\n      const items = fs.readdirSync(dir);\n\n      for (const item of items) {\n        const fullPath = path.join(dir, item);\n        const stat = fs.statSync(fullPath);\n\n        if (stat.isDirectory()) {\n          // Check if directory should be excluded\n          const relativePath = path.relative(target, fullPath);\n          const shouldExclude = excludePatterns.some(pattern => {\n            if (pattern.includes('**')) {\n              // Simple globstar handling\n              return relativePath.startsWith(pattern.replace('/**', '').replace('\\\\**', ''));\n            }\n            return relativePath.includes(pattern.replace('/**', '').replace('\\\\**', ''));\n          });\n\n          if (!shouldExclude) {\n            walkDir(fullPath);\n          }\n        } else if (stat.isFile()) {\n          // Check if file matches include patterns\n          const fileName = path.basename(fullPath);\n          const shouldInclude = includePatterns.some(pattern => {\n            // Simple glob matching\n            if (pattern === '*.py' && fileName.endsWith('.py')) return true;\n            if (pattern === '*.js' && fileName.endsWith('.js')) return true;\n            if (pattern === '*.ts' && fileName.endsWith('.ts')) return true;\n            if (pattern === '*.java' && fileName.endsWith('.java')) return true;\n            if (pattern === '*.go' && fileName.endsWith('.go')) return true;\n            if (pattern === '*.rs' && fileName.endsWith('.rs')) return true;\n            return false;\n          });\n\n          if (shouldInclude) {\n            allFiles.push(fullPath);\n          }\n        }\n      }\n    } catch (error) {\n      // Skip directories that can't be read\n    }\n  }\n\n  walkDir(target);\n  return allFiles;\n}\n\nasync function countTotalLines(files: string[]): Promise<number> {\n  let totalLines = 0;\n\n  for (const file of files) {\n    try {\n      const content = fs.readFileSync(file, 'utf-8');\n      totalLines += content.split('\\n').length;\n    } catch {\n      // Skip files that can't be read\n    }\n  }\n\n  return totalLines;\n}\n\nasync function analyzeQuality(files: string[], depth: string): Promise<{\n  findings: Finding[];\n  recommendations: Recommendation[];\n  metrics: Record<string, any>;\n}> {\n  const findings: Finding[] = [];\n  const metrics: Record<string, any> = {\n    totalFiles: files.length,\n    averageComplexity: 0,\n    codeSmells: 0,\n    maintainabilityIndex: 85\n  };\n\n  for (const file of files) {\n    try {\n      const content = fs.readFileSync(file, 'utf-8');\n      const lines = content.split('\\n');\n\n      // Quick analysis for code quality issues\n      const fileFindings = analyzeFileQuality(file, content, lines, depth);\n      findings.push(...fileFindings);\n\n      // Update metrics\n      metrics.codeSmells += fileFindings.length;\n\n    } catch (error) {\n      findings.push({\n        severity: 'low',\n        category: 'quality',\n        message: `Could not analyze file: ${path.basename(file)}`,\n        file: path.relative(process.cwd(), file),\n        recommendation: 'Ensure file is readable and properly encoded'\n      });\n    }\n  }\n\n  // Calculate average complexity (simplified)\n  metrics.averageComplexity = metrics.codeSmells / Math.max(files.length, 1);\n\n  const recommendations: Recommendation[] = [\n    {\n      description: 'Implement consistent code formatting and linting rules',\n      priority: 'high',\n      estimatedEffort: '2-4 hours',\n      benefits: 'Improved code readability and reduced review time',\n      category: 'quality'\n    },\n    {\n      description: 'Add comprehensive unit test coverage (>80%)',\n      priority: 'high',\n      estimatedEffort: '1-2 weeks',\n      benefits: 'Increased code reliability and reduced regression bugs',\n      category: 'quality'\n    },\n    {\n      description: 'Refactor functions with high cyclomatic complexity',\n      priority: 'medium',\n      estimatedEffort: '3-5 days',\n      benefits: 'Improved maintainability and reduced bug likelihood',\n      category: 'quality'\n    }\n  ];\n\n  return { findings, recommendations, metrics };\n}\n\nfunction analyzeFileQuality(file: string, content: string, lines: string[], depth: string): Finding[] {\n  const findings: Finding[] = [];\n  const filePath = path.relative(process.cwd(), file);\n  const ext = path.extname(file).toLowerCase();\n\n  // Check for long functions (basic complexity check)\n  let currentFunctionLines = 0;\n  let inFunction = false;\n  let functionStart = 0;\n\n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i].trim();\n\n    // Language-specific function detection\n    if (ext === '.py' && (line.startsWith('def ') || line.startsWith('async def '))) {\n      if (inFunction && currentFunctionLines > 50) {\n        findings.push({\n          severity: 'medium',\n          category: 'quality',\n          message: 'Function exceeds 50 lines - consider refactoring',\n          file: filePath,\n          line: functionStart + 1,\n          recommendation: 'Break down into smaller, focused functions'\n        });\n      }\n      inFunction = true;\n      currentFunctionLines = 0;\n      functionStart = i;\n    } else if (ext === '.js' || ext === '.ts') {\n      if (line.includes('function ') || line.includes('=>') || line.match(/\\bconst\\s+\\w+\\s*=/)) {\n        if (inFunction && currentFunctionLines > 30) {\n          findings.push({\n            severity: 'medium',\n            category: 'quality',\n            message: 'Function exceeds 30 lines - consider refactoring',\n            file: filePath,\n            line: functionStart + 1,\n            recommendation: 'Break down into smaller, focused functions'\n          });\n        }\n        inFunction = true;\n        currentFunctionLines = 0;\n        functionStart = i;\n      }\n    }\n\n    if (inFunction) {\n      currentFunctionLines++;\n\n      // Check for nested complexity\n      if (depth === 'deep') {\n        const indentLevel = line.length - line.trimStart().length;\n        if (indentLevel > 12) { // Roughly 3 levels of nesting\n          findings.push({\n            severity: 'low',\n            category: 'quality',\n            message: 'Deep nesting detected - consider simplifying logic',\n            file: filePath,\n            line: i + 1,\n            recommendation: 'Extract nested logic into separate functions'\n          });\n        }\n      }\n    }\n\n    // Check for TODO comments\n    if (line.toLowerCase().includes('todo') || line.toLowerCase().includes('fixme')) {\n      findings.push({\n        severity: 'info',\n        category: 'quality',\n        message: 'TODO/FIXME comment found',\n        file: filePath,\n        line: i + 1,\n        recommendation: 'Address the TODO item or create a proper issue'\n      });\n    }\n\n    // Check for console.log statements in production code\n    if (depth === 'deep' && (line.includes('console.log') || line.includes('print('))) {\n      findings.push({\n        severity: 'low',\n        category: 'quality',\n        message: 'Debug logging statement found in code',\n        file: filePath,\n        line: i + 1,\n        recommendation: 'Remove debug statements or use proper logging'\n      });\n    }\n  }\n\n  return findings;\n}\n\nasync function analyzeSecurity(files: string[], depth: string): Promise<{\n  findings: Finding[];\n  recommendations: Recommendation[];\n  metrics: Record<string, any>;\n}> {\n  const findings: Finding[] = [];\n  const metrics: Record<string, any> = {\n    totalFiles: files.length,\n    vulnerabilitiesFound: 0,\n    securityScore: 85,\n    riskLevel: 'low'\n  };\n\n  for (const file of files) {\n    try {\n      const content = fs.readFileSync(file, 'utf-8');\n      const fileFindings = analyzeFileSecurity(file, content, depth);\n      findings.push(...fileFindings);\n      metrics.vulnerabilitiesFound += fileFindings.length;\n    } catch (error) {\n      // Skip files that can't be read\n    }\n  }\n\n  // Adjust security score based on findings\n  const highSeverityCount = findings.filter(f => f.severity === 'high' || f.severity === 'critical').length;\n  if (highSeverityCount > 0) {\n    metrics.securityScore -= highSeverityCount * 10;\n    metrics.riskLevel = highSeverityCount > 5 ? 'high' : 'medium';\n  }\n\n  const recommendations: Recommendation[] = [\n    {\n      description: 'Implement input validation and sanitization for all user inputs',\n      priority: 'high',\n      estimatedEffort: '1-2 days',\n      benefits: 'Protection against injection attacks and malformed data',\n      category: 'security'\n    },\n    {\n      description: 'Add authentication and authorization checks',\n      priority: 'high',\n      estimatedEffort: '3-5 days',\n      benefits: 'Prevents unauthorized access to sensitive operations',\n      category: 'security'\n    },\n    {\n      description: 'Implement proper error handling without information leakage',\n      priority: 'medium',\n      estimatedEffort: '1-2 days',\n      benefits: 'Prevents information disclosure to attackers',\n      category: 'security'\n    },\n    {\n      description: 'Regular security dependency updates and vulnerability scanning',\n      priority: 'medium',\n      estimatedEffort: 'Ongoing',\n      benefits: 'Protection against known vulnerabilities in dependencies',\n      category: 'security'\n    }\n  ];\n\n  return { findings, recommendations, metrics };\n}\n\nfunction analyzeFileSecurity(file: string, content: string, depth: string): Finding[] {\n  const findings: Finding[] = [];\n  const filePath = path.relative(process.cwd(), file);\n  const lines = content.split('\\n');\n\n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i];\n\n    // Check for common security issues\n    if (depth === 'deep') {\n      // SQL injection patterns\n      if (line.includes('SELECT') || line.includes('INSERT') || line.includes('UPDATE')) {\n        if (line.includes('+') || line.includes('format(') || line.includes('f\"')) {\n          findings.push({\n            severity: 'high',\n            category: 'security',\n            message: 'Potential SQL injection vulnerability',\n            file: filePath,\n            line: i + 1,\n            code: line.trim(),\n            recommendation: 'Use parameterized queries or prepared statements'\n          });\n        }\n      }\n\n      // Hardcoded secrets\n      if (line.match(/password|secret|key|token/i) &&\n          (line.includes('\"') || line.includes(\"'\")) &&\n          !line.includes('process.env') && !line.includes('os.getenv')) {\n        findings.push({\n          severity: 'high',\n          category: 'security',\n          message: 'Potential hardcoded secret detected',\n          file: filePath,\n          line: i + 1,\n          recommendation: 'Use environment variables or secure credential storage'\n        });\n      }\n\n      // XSS vulnerabilities in web code\n      if ((file.endsWith('.js') || file.endsWith('.ts') || file.endsWith('.jsx') || file.endsWith('.tsx')) &&\n          line.includes('innerHTML') || line.includes('outerHTML')) {\n        findings.push({\n          severity: 'medium',\n          category: 'security',\n          message: 'Potential XSS vulnerability with direct HTML injection',\n          file: filePath,\n          line: i + 1,\n          code: line.trim(),\n          recommendation: 'Use textContent or sanitize HTML input'\n        });\n      }\n\n      // Path traversal\n      if (line.includes('../') || line.includes('..\\\\')) {\n        findings.push({\n          severity: 'medium',\n          category: 'security',\n          message: 'Potential path traversal vulnerability',\n          file: filePath,\n          line: i + 1,\n          code: line.trim(),\n          recommendation: 'Validate and sanitize file paths'\n        });\n      }\n    }\n\n    // Check for eval usage\n    if (line.includes('eval(')) {\n      findings.push({\n        severity: 'high',\n        category: 'security',\n        message: 'Use of eval() function detected',\n        file: filePath,\n        line: i + 1,\n        code: line.trim(),\n        recommendation: 'Avoid eval() - use safer alternatives'\n      });\n    }\n  }\n\n  return findings;\n}\n\nasync function analyzePerformance(files: string[], depth: string): Promise<{\n  findings: Finding[];\n  recommendations: Recommendation[];\n  metrics: Record<string, any>;\n}> {\n  const findings: Finding[] = [];\n  const metrics: Record<string, any> = {\n    totalFiles: files.length,\n    performanceIssues: 0,\n    estimatedOptimizationPotential: 0\n  };\n\n  for (const file of files) {\n    try {\n      const content = fs.readFileSync(file, 'utf-8');\n      const fileFindings = analyzeFilePerformance(file, content, depth);\n      findings.push(...fileFindings);\n      metrics.performanceIssues += fileFindings.length;\n    } catch (error) {\n      // Skip files that can't be read\n    }\n  }\n\n  const recommendations: Recommendation[] = [\n    {\n      description: 'Implement caching for frequently accessed data',\n      priority: 'high',\n      estimatedEffort: '2-3 days',\n      benefits: 'Significant performance improvement for repeated operations',\n      category: 'performance'\n    },\n    {\n      description: 'Optimize database queries and add proper indexing',\n      priority: 'high',\n      estimatedEffort: '3-5 days',\n      benefits: 'Faster data retrieval and reduced database load',\n      category: 'performance'\n    },\n    {\n      description: 'Implement lazy loading for large datasets',\n      priority: 'medium',\n      estimatedEffort: '1-2 days',\n      benefits: 'Reduced memory usage and faster initial load times',\n      category: 'performance'\n    },\n    {\n      description: 'Add performance monitoring and profiling',\n      priority: 'medium',\n      estimatedEffort: '1-2 days',\n      benefits: 'Ability to identify and resolve performance bottlenecks',\n      category: 'performance'\n    }\n  ];\n\n  return { findings, recommendations, metrics };\n}\n\nfunction analyzeFilePerformance(file: string, content: string, depth: string): Finding[] {\n  const findings: Finding[] = [];\n  const filePath = path.relative(process.cwd(), file);\n  const lines = content.split('\\n');\n\n  for (let i = 0; i < lines.length; i++) {\n    const line = lines[i];\n\n    if (depth === 'deep') {\n      // Check for inefficient loops\n      if (line.includes('for') && line.includes('length') && line.includes('.length')) {\n        if (lines[i + 1] && lines[i + 1].includes('.length')) {\n          findings.push({\n            severity: 'medium',\n            category: 'performance',\n            message: 'Potential inefficient loop - accessing length property repeatedly',\n            file: filePath,\n            line: i + 1,\n            code: line.trim(),\n            recommendation: 'Cache array length outside the loop'\n          });\n        }\n      }\n\n      // Check for synchronous file operations\n      if (line.includes('readFileSync') || line.includes('writeFileSync')) {\n        findings.push({\n          severity: 'medium',\n          category: 'performance',\n          message: 'Synchronous file operation detected',\n          file: filePath,\n          line: i + 1,\n          code: line.trim(),\n          recommendation: 'Use asynchronous file operations to avoid blocking'\n        });\n      }\n\n      // Check for large object creation in loops\n      if (line.includes('new ') && lines[i - 1] && lines[i - 1].includes('for ')) {\n        findings.push({\n          severity: 'low',\n          category: 'performance',\n          message: 'Object creation inside loop detected',\n          file: filePath,\n          line: i + 1,\n          code: line.trim(),\n          recommendation: 'Consider moving object creation outside the loop'\n        });\n      }\n    }\n\n    // Check for nested loops (basic detection)\n    if (line.includes('for ') && lines[i + 1] && lines[i + 1].includes('for ')) {\n      findings.push({\n        severity: 'low',\n        category: 'performance',\n        message: 'Nested loops detected - potential O(n\u00b2) complexity',\n        file: filePath,\n        line: i + 1,\n        recommendation: 'Review algorithm complexity and consider optimization'\n      });\n    }\n  }\n\n  return findings;\n}\n\nasync function analyzeArchitecture(files: string[], depth: string): Promise<{\n  findings: Finding[];\n  recommendations: Recommendation[];\n  metrics: Record<string, any>;\n}> {\n  const findings: Finding[] = [];\n  const metrics: Record<string, any> = {\n    totalFiles: files.length,\n    circularDependencies: 0,\n    tightCoupling: 0,\n    architectureScore: 80\n  };\n\n  // Analyze file structure and imports\n  const fileMap = new Map<string, string[]>();\n  const importMap = new Map<string, string[]>();\n\n  for (const file of files) {\n    try {\n      const content = fs.readFileSync(file, 'utf-8');\n      const imports = extractImports(file, content);\n      importMap.set(file, imports);\n\n      // Build reverse map for dependency analysis\n      for (const imp of imports) {\n        if (!fileMap.has(imp)) {\n          fileMap.set(imp, []);\n        }\n        fileMap.get(imp)!.push(file);\n      }\n    } catch (error) {\n      // Skip files that can't be read\n    }\n  }\n\n  // Check for architectural issues\n  for (const [file, imports] of importMap.entries()) {\n    const filePath = path.relative(process.cwd(), file);\n\n    // Check for circular dependencies (simplified)\n    for (const imp of imports) {\n      const importedBy = fileMap.get(imp) || [];\n      if (importedBy.some(f => {\n        const fImports = importMap.get(f) || [];\n        return fImports.includes(file);\n      })) {\n        findings.push({\n          severity: 'medium',\n          category: 'architecture',\n          message: 'Potential circular dependency detected',\n          file: filePath,\n          recommendation: 'Refactor to break circular dependencies using dependency injection'\n        });\n        metrics.circularDependencies++;\n      }\n    }\n\n    // Check for tight coupling (too many imports)\n    if (depth === 'deep' && imports.length > 20) {\n      findings.push({\n        severity: 'low',\n        category: 'architecture',\n        message: 'High number of imports - potential tight coupling',\n        file: filePath,\n        recommendation: 'Consider breaking down into smaller, focused modules'\n      });\n      metrics.tightCoupling++;\n    }\n  }\n\n  const recommendations: Recommendation[] = [\n    {\n      description: 'Implement clean architecture with clear separation of concerns',\n      priority: 'high',\n      estimatedEffort: '1-2 weeks',\n      benefits: 'Improved maintainability and testability',\n      category: 'architecture'\n    },\n    {\n      description: 'Define clear module boundaries and interfaces',\n      priority: 'high',\n      estimatedEffort: '3-5 days',\n      benefits: 'Reduced coupling and improved modularity',\n      category: 'architecture'\n    },\n    {\n      description: 'Implement dependency injection pattern',\n      priority: 'medium',\n      estimatedEffort: '1 week',\n      benefits: 'Better testability and flexibility',\n      category: 'architecture'\n    },\n    {\n      description: 'Add comprehensive API documentation and contracts',\n      priority: 'medium',\n      estimatedEffort: '3-5 days',\n      benefits: 'Improved developer experience and API stability',\n      category: 'architecture'\n    }\n  ];\n\n  return { findings, recommendations, metrics };\n}\n\nfunction extractImports(file: string, content: string): string[] {\n  const imports: string[] = [];\n  const lines = content.split('\\n');\n  const ext = path.extname(file).toLowerCase();\n\n  for (const line of lines) {\n    const trimmed = line.trim();\n\n    if (ext === '.py') {\n      // Python imports\n      if (trimmed.startsWith('import ') || trimmed.startsWith('from ')) {\n        // Extract module names (simplified)\n        const parts = trimmed.split(' ');\n        if (parts.length >= 2) {\n          imports.push(parts[1].split('.')[0]);\n        }\n      }\n    } else if (ext === '.js' || ext === '.ts') {\n      // JavaScript/TypeScript imports\n      if (trimmed.startsWith('import ') || trimmed.startsWith('require(')) {\n        // Extract module names (simplified)\n        if (trimmed.includes('from ')) {\n          const fromMatch = trimmed.match(/from ['\"]([^'\"]+)['\"]/);\n          if (fromMatch) {\n            imports.push(fromMatch[1]);\n          }\n        } else if (trimmed.includes('require(')) {\n          const requireMatch = trimmed.match(/require\\(['\"]([^'\"]+)['\"]\\)/);\n          if (requireMatch) {\n            imports.push(requireMatch[1]);\n          }\n        }\n      }\n    }\n  }\n\n  return [...new Set(imports)]; // Remove duplicates\n}\n",
        "timestamp": "2026-01-04T05:35:52.969195"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "Add JSDoc coverage for claude-flow TypeScript service public exports",
        "description": "Add comprehensive JSDoc documentation to the 45 exported functions/classes across 17 TypeScript files in the claude-flow CLI tool to improve API documentation for enterprise users",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-04T05:35:52.973425",
  "last_updated": "2026-01-04T05:35:52.976262"
}