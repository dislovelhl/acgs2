{
  "file_path": "integration-service/src/integrations/base.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nBase Integration Adapter Class\n\nProvides the abstract base class for all third-party integrations with\nauthenticate/validate/send_event methods and common functionality.\n\"\"\"\n\nimport abc\nimport logging\nfrom datetime import datetime, timezone\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, TypeVar\nfrom uuid import uuid4\n\nimport httpx\nfrom pydantic import BaseModel, Field, SecretStr\nfrom tenacity import (\n    RetryError,\n    before_sleep_log,\n    retry,\n    retry_if_exception_type,\n    stop_after_attempt,\n    wait_exponential,\n)\n\n# Import exceptions from centralized exceptions module\nfrom exceptions.auth import AuthenticationError\nfrom exceptions.delivery import DeliveryError\nfrom exceptions.integration import (\n    IntegrationConnectionError,\n    IntegrationError,\n    RateLimitError,\n)\nfrom exceptions.validation import ValidationError\n\nlogger = logging.getLogger(__name__)\n\n\n# Public API exports - make exceptions and classes available for import from this module\n__all__ = [\n    # Exceptions - imported from centralized exceptions module\n    \"IntegrationError\",\n    \"AuthenticationError\",\n    \"ValidationError\",\n    \"DeliveryError\",\n    \"RateLimitError\",\n    \"IntegrationConnectionError\",\n    # Enums\n    \"IntegrationType\",\n    \"IntegrationStatus\",\n    \"EventSeverity\",\n    # Models\n    \"IntegrationCredentials\",\n    \"IntegrationEvent\",\n    \"IntegrationResult\",\n    # Base class\n    \"BaseIntegration\",\n]\n\n\n# Enums\nclass IntegrationType(str, Enum):\n    \"\"\"Types of integrations supported\"\"\"\n\n    SIEM = \"siem\"\n    TICKETING = \"ticketing\"\n    CICD = \"cicd\"\n    WEBHOOK = \"webhook\"\n\n\nclass IntegrationStatus(str, Enum):\n    \"\"\"Status of an integration\"\"\"\n\n    ACTIVE = \"active\"\n    INACTIVE = \"inactive\"\n    ERROR = \"error\"\n    AUTHENTICATING = \"authenticating\"\n    RATE_LIMITED = \"rate_limited\"\n\n\nclass EventSeverity(str, Enum):\n    \"\"\"Severity levels for governance events\"\"\"\n\n    CRITICAL = \"critical\"\n    HIGH = \"high\"\n    MEDIUM = \"medium\"\n    LOW = \"low\"\n    INFO = \"info\"\n\n\n# Pydantic Models\nclass IntegrationCredentials(BaseModel):\n    \"\"\"Base model for integration credentials\"\"\"\n\n    integration_id: str = Field(default_factory=lambda: str(uuid4()))\n    integration_name: str = Field(..., description=\"Name of the integration\")\n    integration_type: IntegrationType = Field(..., description=\"Type of integration\")\n\n    # Common credential fields - subclasses override with specific fields\n    api_key: Optional[SecretStr] = Field(None, description=\"API key if applicable\")\n    api_token: Optional[SecretStr] = Field(None, description=\"API token if applicable\")\n    username: Optional[str] = Field(None, description=\"Username if applicable\")\n    password: Optional[SecretStr] = Field(None, description=\"Password if applicable\")\n    base_url: Optional[str] = Field(None, description=\"Base URL for the integration\")\n\n    # OAuth fields\n    client_id: Optional[str] = Field(None, description=\"OAuth client ID\")\n    client_secret: Optional[SecretStr] = Field(None, description=\"OAuth client secret\")\n    tenant_id: Optional[str] = Field(None, description=\"Tenant ID for multi-tenant services\")\n    access_token: Optional[SecretStr] = Field(None, description=\"OAuth access token\")\n    refresh_token: Optional[SecretStr] = Field(None, description=\"OAuth refresh token\")\n    token_expires_at: Optional[datetime] = Field(None, description=\"Token expiration time\")\n\n    class Config:\n        \"\"\"Pydantic config\"\"\"\n\n        json_encoders = {\n            SecretStr: lambda v: \"***REDACTED***\" if v else None,\n        }\n\n\nclass IntegrationEvent(BaseModel):\n    \"\"\"Model for governance events to be sent to integrations\"\"\"\n\n    event_id: str = Field(default_factory=lambda: str(uuid4()))\n    event_type: str = Field(..., description=\"Type of governance event\")\n    timestamp: datetime = Field(\n        default_factory=lambda: datetime.now(timezone.utc),\n        description=\"Event timestamp in UTC\",\n    )\n    severity: EventSeverity = Field(EventSeverity.INFO, description=\"Event severity level\")\n    source: str = Field(\"acgs2\", description=\"Source system\")\n\n    # Event content\n    policy_id: Optional[str] = Field(None, description=\"Related policy ID\")\n    resource_id: Optional[str] = Field(None, description=\"Affected resource ID\")\n    resource_type: Optional[str] = Field(None, description=\"Type of affected resource\")\n    action: Optional[str] = Field(None, description=\"Action that triggered the event\")\n    outcome: Optional[str] = Field(None, description=\"Outcome of the action\")\n\n    # Details\n    title: str = Field(..., description=\"Event title/summary\")\n    description: Optional[str] = Field(None, description=\"Detailed description\")\n    details: Dict[str, Any] = Field(default_factory=dict, description=\"Additional event details\")\n\n    # Metadata\n    user_id: Optional[str] = Field(None, description=\"User who triggered the event\")\n    tenant_id: Optional[str] = Field(None, description=\"Tenant ID for multi-tenant deployments\")\n    correlation_id: Optional[str] = Field(None, description=\"Correlation ID for tracing\")\n    tags: List[str] = Field(default_factory=list, description=\"Event tags\")\n\n\nclass IntegrationResult(BaseModel):\n    \"\"\"Result of an integration operation\"\"\"\n\n    success: bool = Field(..., description=\"Whether the operation succeeded\")\n    integration_name: str = Field(..., description=\"Name of the integration\")\n    operation: str = Field(..., description=\"Operation performed\")\n    timestamp: datetime = Field(\n        default_factory=lambda: datetime.now(timezone.utc),\n        description=\"Operation timestamp\",\n    )\n\n    # Success details\n    external_id: Optional[str] = Field(\n        None, description=\"External system ID (e.g., ticket ID, event ID)\"\n    )\n    external_url: Optional[str] = Field(None, description=\"URL to the external resource\")\n\n    # Error details\n    error_code: Optional[str] = Field(None, description=\"Error code if failed\")\n    error_message: Optional[str] = Field(None, description=\"Error message if failed\")\n    error_details: Dict[str, Any] = Field(\n        default_factory=dict, description=\"Additional error details\"\n    )\n\n    # Retry info\n    retry_count: int = Field(0, description=\"Number of retry attempts\")\n    should_retry: bool = Field(False, description=\"Whether operation should be retried\")\n    retry_after: Optional[int] = Field(None, description=\"Seconds to wait before retry\")\n\n\nclass BatchIntegrationResult(BaseModel):\n    \"\"\"\n    Result of a batch integration operation.\n\n    Provides batch-level success/failure tracking with per-event results,\n    enabling efficient monitoring and debugging of batch event processing.\n\n    The batch is considered successful if all events succeeded, partially successful\n    if some events succeeded, or failed if all events failed.\n\n    Example:\n        ```python\n        # Send batch of events\n        results = await adapter.send_events_batch(events)\n\n        # Wrap in BatchIntegrationResult for summary\n        batch_result = BatchIntegrationResult.from_results(\n            integration_name=adapter.name,\n            operation=\"send_events_batch\",\n            results=results\n        )\n\n        # Check overall batch status\n        if batch_result.all_succeeded:\n            logger.info(\n                f\"Batch completed: \"\n                f\"{batch_result.successful_count}/{batch_result.total_count}\"\n            )\n        elif batch_result.partial_success:\n            logger.warning(\n                f\"Partial success: \"\n                f\"{batch_result.successful_count}/{batch_result.total_count}\"\n            )\n        else:\n            logger.error(f\"Batch failed: {batch_result.error_message}\")\n\n        # Access individual event results\n        for i, result in enumerate(batch_result.event_results):\n            if not result.success:\n                logger.error(f\"Event {i} failed: {result.error_message}\")\n        ```\n    \"\"\"\n\n    integration_name: str = Field(..., description=\"Name of the integration\")\n    operation: str = Field(\n        default=\"send_events_batch\", description=\"Batch operation performed\"\n    )\n    timestamp: datetime = Field(\n        default_factory=lambda: datetime.now(timezone.utc),\n        description=\"Batch operation timestamp\",\n    )\n\n    # Per-event results\n    event_results: List[IntegrationResult] = Field(\n        ..., description=\"Individual result for each event in the batch\"\n    )\n\n    # Batch-level summary statistics\n    total_count: int = Field(..., description=\"Total number of events in the batch\")\n    successful_count: int = Field(..., description=\"Number of events that succeeded\")\n    failed_count: int = Field(..., description=\"Number of events that failed\")\n\n    # Batch-level status\n    all_succeeded: bool = Field(..., description=\"True if all events succeeded\")\n    all_failed: bool = Field(..., description=\"True if all events failed\")\n    partial_success: bool = Field(\n        ..., description=\"True if some (but not all) events succeeded\"\n    )\n\n    # Error details (for complete failures)\n    error_code: Optional[str] = Field(None, description=\"Error code if batch completely failed\")\n    error_message: Optional[str] = Field(\n        None, description=\"Error message if batch completely failed\"\n    )\n    error_details: Dict[str, Any] = Field(\n        default_factory=dict, description=\"Additional error details\"\n    )\n\n    # Retry info\n    retry_count: int = Field(0, description=\"Number of retry attempts for the batch\")\n    should_retry: bool = Field(\n        False, description=\"Whether the batch operation should be retried\"\n    )\n\n    @classmethod\n    def from_results(\n        cls,\n        integration_name: str,\n        operation: str,\n        results: List[IntegrationResult],\n        retry_count: int = 0,\n    ) -> \"BatchIntegrationResult\":\n        \"\"\"\n        Create a BatchIntegrationResult from a list of IntegrationResults.\n\n        Automatically computes summary statistics and determines batch-level status.\n\n        Args:\n            integration_name: Name of the integration\n            operation: Operation performed (e.g., \"send_events_batch\")\n            results: List of individual event results\n            retry_count: Number of retry attempts for this batch\n\n        Returns:\n            BatchIntegrationResult with computed statistics\n        \"\"\"\n        total = len(results)\n        successful = sum(1 for r in results if r.success)\n        failed = total - successful\n\n        all_succeeded = failed == 0 and total > 0\n        all_failed = successful == 0 and total > 0\n        partial_success = successful > 0 and failed > 0\n\n        # Extract error details from first failure if all failed\n        error_code = None\n        error_message = None\n        error_details = {}\n        if all_failed and results:\n            first_failure = results[0]\n            error_code = first_failure.error_code\n            error_message = first_failure.error_message\n            error_details = first_failure.error_details\n\n        return cls(\n            integration_name=integration_name,\n            operation=operation,\n            event_results=results,\n            total_count=total,\n            successful_count=successful,\n            failed_count=failed,\n            all_succeeded=all_succeeded,\n            all_failed=all_failed,\n            partial_success=partial_success,\n            error_code=error_code,\n            error_message=error_message,\n            error_details=error_details,\n            retry_count=retry_count,\n            should_retry=all_failed and any(r.should_retry for r in results),\n        )\n\n    @property\n    def success_rate(self) -> float:\n        \"\"\"\n        Calculate the success rate as a percentage.\n\n        Returns:\n            Success rate from 0.0 to 100.0, or 0.0 if no events\n        \"\"\"\n        if self.total_count == 0:\n            return 0.0\n        return (self.successful_count / self.total_count) * 100.0\n\n\n# Type variable for generic integration config\nConfigT = TypeVar(\"ConfigT\", bound=IntegrationCredentials)\n\n\nclass BaseIntegration(abc.ABC):\n    \"\"\"\n    Abstract base class for all third-party integrations.\n\n    Provides common functionality for authentication, validation, and event delivery\n    with built-in retry logic, circuit breaker support, and comprehensive error handling.\n\n    Subclasses must implement:\n    - _do_authenticate(): Perform actual authentication\n    - _do_validate(): Perform actual validation\n    - _do_send_event(): Perform actual event delivery\n    \"\"\"\n\n    # Default retry configuration\n    DEFAULT_MAX_RETRIES = 3\n    DEFAULT_RETRY_MIN_WAIT = 1  # seconds\n    DEFAULT_RETRY_MAX_WAIT = 16  # seconds\n    DEFAULT_TIMEOUT = 30.0  # seconds\n\n    def __init__(\n        self,\n        credentials: IntegrationCredentials,\n        max_retries: int = DEFAULT_MAX_RETRIES,\n        timeout: float = DEFAULT_TIMEOUT,\n    ):\n        \"\"\"\n        Initialize the integration adapter.\n\n        Args:\n            credentials: Integration credentials and configuration\n            max_retries: Maximum number of retry attempts for operations\n            timeout: HTTP request timeout in seconds\n        \"\"\"\n        self.credentials = credentials\n        self.max_retries = max_retries\n        self.timeout = timeout\n\n        # State\n        self._status = IntegrationStatus.INACTIVE\n        self._authenticated = False\n        self._last_error: Optional[str] = None\n        self._http_client: Optional[httpx.AsyncClient] = None\n\n        # Metrics\n        self._events_sent = 0\n        self._events_failed = 0\n        self._last_success: Optional[datetime] = None\n        self._last_failure: Optional[datetime] = None\n\n        # Batch metrics\n        self._batches_sent = 0\n        self._batches_failed = 0\n        self._batch_events_total = 0\n\n    @property\n    def name(self) -> str:\n        \"\"\"Get integration name\"\"\"\n        return self.credentials.integration_name\n\n    @property\n    def integration_type(self) -> IntegrationType:\n        \"\"\"Get integration type\"\"\"\n        return self.credentials.integration_type\n\n    @property\n    def status(self) -> IntegrationStatus:\n        \"\"\"Get current integration status\"\"\"\n        return self._status\n\n    @property\n    def is_authenticated(self) -> bool:\n        \"\"\"Check if integration is authenticated\"\"\"\n        return self._authenticated\n\n    @property\n    def metrics(self) -> Dict[str, Any]:\n        \"\"\"Get integration metrics\"\"\"\n        return {\n            \"events_sent\": self._events_sent,\n            \"events_failed\": self._events_failed,\n            \"last_success\": self._last_success.isoformat() if self._last_success else None,\n            \"last_failure\": self._last_failure.isoformat() if self._last_failure else None,\n            \"status\": self._status.value,\n            \"authenticated\": self._authenticated,\n            \"batches_sent\": self._batches_sent,\n            \"batches_failed\": self._batches_failed,\n            \"batch_events_total\": self._batch_events_total,\n        }\n\n    async def get_http_client(self) -> httpx.AsyncClient:\n        \"\"\"Get or create HTTP client with proper configuration\"\"\"\n        if self._http_client is None or self._http_client.is_closed:\n            self._http_client = httpx.AsyncClient(\n                timeout=self.timeout,\n                follow_redirects=True,\n            )\n        return self._http_client\n\n    async def close(self) -> None:\n        \"\"\"Close the integration and cleanup resources\"\"\"\n        if self._http_client is not None and not self._http_client.is_closed:\n            await self._http_client.aclose()\n            self._http_client = None\n        self._authenticated = False\n        self._status = IntegrationStatus.INACTIVE\n        logger.info(f\"Integration '{self.name}' closed\")\n\n    async def authenticate(self) -> IntegrationResult:\n        \"\"\"\n        Authenticate with the external service.\n\n        Returns:\n            IntegrationResult with success status and any error details\n\n        Raises:\n            AuthenticationError: If authentication fails after retries\n        \"\"\"\n        logger.info(f\"Authenticating integration '{self.name}'\")\n        self._status = IntegrationStatus.AUTHENTICATING\n\n        try:\n            result = await self._authenticate_with_retry()\n\n            if result.success:\n                self._authenticated = True\n                self._status = IntegrationStatus.ACTIVE\n                self._last_success = datetime.now(timezone.utc)\n                logger.info(f\"Integration '{self.name}' authenticated successfully\")\n            else:\n                self._authenticated = False\n                self._status = IntegrationStatus.ERROR\n                self._last_error = result.error_message\n                self._last_failure = datetime.now(timezone.utc)\n                logger.error(\n                    f\"Integration '{self.name}' authentication failed: {result.error_message}\"\n                )\n\n            return result\n\n        except RetryError as e:\n            self._authenticated = False\n            self._status = IntegrationStatus.ERROR\n            self._last_failure = datetime.now(timezone.utc)\n            error_msg = f\"Authentication failed after {self.max_retries} retries: {str(e)}\"\n            self._last_error = error_msg\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise AuthenticationError(error_msg, self.name) from e\n\n    @retry(\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=1, min=1, max=16),\n        retry=retry_if_exception_type((httpx.TimeoutException, httpx.NetworkError)),\n        before_sleep=before_sleep_log(logger, logging.WARNING),\n        reraise=True,\n    )\n    async def _authenticate_with_retry(self) -> IntegrationResult:\n        \"\"\"Authenticate with retry logic\"\"\"\n        return await self._do_authenticate()\n\n    @abc.abstractmethod\n    async def _do_authenticate(self) -> IntegrationResult:\n        \"\"\"\n        Perform the actual authentication.\n\n        Subclasses must implement this method with their specific authentication logic.\n\n        Returns:\n            IntegrationResult with success status\n        \"\"\"\n        pass\n\n    async def validate(self) -> IntegrationResult:\n        \"\"\"\n        Validate the integration configuration and connectivity.\n\n        Returns:\n            IntegrationResult with validation status\n\n        Raises:\n            ValidationError: If validation fails\n        \"\"\"\n        logger.info(f\"Validating integration '{self.name}'\")\n\n        try:\n            result = await self._validate_with_retry()\n\n            if result.success:\n                logger.info(f\"Integration '{self.name}' validation successful\")\n            else:\n                self._last_error = result.error_message\n                logger.warning(\n                    f\"Integration '{self.name}' validation failed: {result.error_message}\"\n                )\n\n            return result\n\n        except RetryError as e:\n            error_msg = f\"Validation failed after {self.max_retries} retries: {str(e)}\"\n            self._last_error = error_msg\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise ValidationError(error_msg, self.name) from e\n\n    @retry(\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=1, min=1, max=16),\n        retry=retry_if_exception_type((httpx.TimeoutException, httpx.NetworkError)),\n        before_sleep=before_sleep_log(logger, logging.WARNING),\n        reraise=True,\n    )\n    async def _validate_with_retry(self) -> IntegrationResult:\n        \"\"\"Validate with retry logic\"\"\"\n        return await self._do_validate()\n\n    @abc.abstractmethod\n    async def _do_validate(self) -> IntegrationResult:\n        \"\"\"\n        Perform the actual validation.\n\n        Subclasses must implement this method to validate:\n        - Credentials are properly configured\n        - External service is reachable\n        - Required permissions are granted\n        - Infrastructure prerequisites exist (e.g., Splunk index, Sentinel DCR)\n\n        Returns:\n            IntegrationResult with validation status\n        \"\"\"\n        pass\n\n    async def send_event(self, event: IntegrationEvent) -> IntegrationResult:\n        \"\"\"\n        Send a governance event to the external service.\n\n        Args:\n            event: The governance event to send\n\n        Returns:\n            IntegrationResult with delivery status\n\n        Raises:\n            DeliveryError: If delivery fails after retries\n            AuthenticationError: If not authenticated\n            RateLimitError: If rate limited by the external service\n        \"\"\"\n        if not self._authenticated:\n            error_msg = \"Integration is not authenticated\"\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise AuthenticationError(error_msg, self.name)\n\n        logger.debug(f\"Sending event {event.event_id} to integration '{self.name}'\")\n\n        try:\n            result = await self._send_event_with_retry(event)\n\n            if result.success:\n                self._events_sent += 1\n                self._last_success = datetime.now(timezone.utc)\n                logger.info(\n                    f\"Event {event.event_id} sent successfully to '{self.name}'. \"\n                    f\"External ID: {result.external_id}\"\n                )\n            else:\n                self._events_failed += 1\n                self._last_failure = datetime.now(timezone.utc)\n                self._last_error = result.error_message\n                logger.warning(\n                    f\"Event {event.event_id} delivery to '{self.name}' failed: \"\n                    f\"{result.error_message}\"\n                )\n\n            return result\n\n        except RetryError as e:\n            self._events_failed += 1\n            self._last_failure = datetime.now(timezone.utc)\n            error_msg = f\"Event delivery failed after {self.max_retries} retries: {str(e)}\"\n            self._last_error = error_msg\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise DeliveryError(error_msg, self.name) from e\n\n    @retry(\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=1, min=1, max=16),\n        retry=retry_if_exception_type((httpx.TimeoutException, httpx.NetworkError, DeliveryError)),\n        before_sleep=before_sleep_log(logger, logging.WARNING),\n        reraise=True,\n    )\n    async def _send_event_with_retry(self, event: IntegrationEvent) -> IntegrationResult:\n        \"\"\"Send event with retry logic\"\"\"\n        return await self._do_send_event(event)\n\n    @abc.abstractmethod\n    async def _do_send_event(self, event: IntegrationEvent) -> IntegrationResult:\n        \"\"\"\n        Perform the actual event delivery.\n\n        Subclasses must implement this method with their specific delivery logic.\n        Should handle rate limiting by raising RateLimitError with retry_after.\n\n        Args:\n            event: The governance event to send\n\n        Returns:\n            IntegrationResult with delivery status\n        \"\"\"\n        pass\n\n    async def send_events_batch(\n        self,\n        events: List[IntegrationEvent],\n    ) -> List[IntegrationResult]:\n        \"\"\"\n        Send multiple governance events to the external service in a batch.\n\n        Optimizes delivery by sending multiple events in a single API call where\n        supported, reducing network overhead and improving throughput for high-volume\n        governance event scenarios. This method provides automatic retry logic,\n        comprehensive metrics tracking, and fallback support for adapters without\n        native batch capabilities.\n\n        For adapters that don't support native batch operations, this method will\n        automatically fall back to sending events one-by-one using _do_send_event(),\n        providing transparent batch API support across all integrations.\n\n        Performance Characteristics:\n            - Batch operations reduce API calls from N to 1 for batch-capable adapters\n            - Network latency reduced from N*RTT to 1*RTT for batch operations\n            - Recommended for sending 10+ events when the adapter supports batching\n            - Empty list returns immediately with no side effects\n\n        Retry Behavior:\n            - Automatically retries batch operations up to 3 times (configurable)\n            - Uses exponential backoff: 1s, 2s, 4s, up to 16s between retries\n            - Retries on: TimeoutException, NetworkError, DeliveryError\n            - Does NOT retry on: AuthenticationError, ValidationError\n            - RateLimitError includes retry_after hint from service\n\n        Metrics Tracking:\n            - _batches_sent: Incremented for successful batches (all or partial success)\n            - _batches_failed: Incremented when all events in batch fail\n            - _batch_events_total: Total count of events successfully sent via batches\n            - _events_sent: Per-event success count (same as send_event)\n            - _events_failed: Per-event failure count (same as send_event)\n            - Metrics accessible via integration.metrics property\n\n        Args:\n            events: List of governance events to send. Can be empty (returns empty list).\n                   Events are processed in the order provided, and results maintain\n                   the same ordering for correlation.\n\n        Returns:\n            List of IntegrationResults, one for each input event. Results are returned\n            in the same order as the input events, allowing direct correlation via\n            zip(events, results). Empty list returns empty results.\n\n        Raises:\n            AuthenticationError: If the integration is not authenticated. Call\n                               authenticate() before sending events.\n            DeliveryError: If batch delivery fails after all retry attempts. Contains\n                          details about the final failure reason.\n            RateLimitError: If rate limited by the external service. The retry_after\n                           attribute indicates when to retry (seconds).\n\n        Example:\n            Basic batch sending:\n            ```python\n            # Send a batch of events\n            events = [event1, event2, event3]\n            results = await adapter.send_events_batch(events)\n\n            # Check results for each event\n            for event, result in zip(events, results):\n                if result.success:\n                    logger.info(f\"Event {event.event_id} sent successfully\")\n                else:\n                    logger.error(f\"Event {event.event_id} failed: {result.error_message}\")\n            ```\n\n            Checking batch metrics:\n            ```python\n            # Send multiple batches\n            await adapter.send_events_batch(batch1)\n            await adapter.send_events_batch(batch2)\n\n            # Check batch statistics\n            metrics = adapter.metrics\n            logger.info(f\"Batches sent: {metrics['batches_sent']}\")\n            logger.info(f\"Total events via batch: {metrics['batch_events_total']}\")\n            logger.info(f\"Batch success rate: {metrics['batches_sent']/(metrics['batches_sent']+metrics['batches_failed']):.1%}\")\n            ```\n\n            Handling partial success:\n            ```python\n            results = await adapter.send_events_batch(events)\n            successful = [r for r in results if r.success]\n            failed = [r for r in results if not r.success]\n\n            if failed:\n                logger.warning(f\"Partial batch failure: {len(failed)}/{len(events)} failed\")\n                # Retry failed events individually if needed\n                for idx, result in enumerate(results):\n                    if not result.success:\n                        await adapter.send_event(events[idx])\n            ```\n\n        Note:\n            Batch semantics depend on the adapter implementation:\n            - Splunk HEC: All-or-nothing semantics (all succeed or all fail)\n            - Sentinel DCR: All-or-nothing semantics (all succeed or all fail)\n            - Jira/ServiceNow: Default one-by-one fallback allows partial success\n            - Custom adapters: Can implement either semantic by overriding\n              _do_send_events_batch()\n\n            Thread Safety:\n            - This method is async-safe but not thread-safe\n            - Metrics updates are not atomic across threads\n            - Use separate adapter instances for concurrent threads\n\n            Authentication:\n            - Must call authenticate() before using this method\n            - Authentication state checked before each batch\n            - Raises AuthenticationError immediately if not authenticated\n        \"\"\"\n        if not self._authenticated:\n            error_msg = \"Integration is not authenticated\"\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise AuthenticationError(error_msg, self.name)\n\n        if not events:\n            return []\n\n        logger.debug(f\"Sending batch of {len(events)} events to integration '{self.name}'\")\n\n        try:\n            results = await self._send_events_batch_with_retry(events)\n\n            # Count successful and failed events\n            successful_count = sum(1 for r in results if r.success)\n            failed_count = len(results) - successful_count\n\n            # Track metrics\n            if failed_count == 0:\n                # All events succeeded\n                self._batches_sent += 1\n                self._events_sent += successful_count\n                self._batch_events_total += successful_count\n                self._last_success = datetime.now(timezone.utc)\n                logger.info(\n                    f\"Batch of {len(events)} events sent successfully to '{self.name}'\"\n                )\n            elif successful_count == 0:\n                # All events failed\n                self._batches_failed += 1\n                self._events_failed += failed_count\n                self._last_failure = datetime.now(timezone.utc)\n                self._last_error = results[0].error_message if results else \"Batch delivery failed\"\n                logger.warning(\n                    f\"Batch of {len(events)} events failed to send to '{self.name}': \"\n                    f\"{self._last_error}\"\n                )\n            else:\n                # Partial success\n                self._batches_sent += 1\n                self._events_sent += successful_count\n                self._events_failed += failed_count\n                self._batch_events_total += successful_count\n                self._last_success = datetime.now(timezone.utc)\n                logger.warning(\n                    f\"Batch of {len(events)} events partially succeeded for '{self.name}': \"\n                    f\"{successful_count} succeeded, {failed_count} failed\"\n                )\n\n            return results\n\n        except RetryError as e:\n            self._batches_failed += 1\n            self._events_failed += len(events)\n            self._last_failure = datetime.now(timezone.utc)\n            error_msg = f\"Batch delivery failed after {self.max_retries} retries: {str(e)}\"\n            self._last_error = error_msg\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise DeliveryError(error_msg, self.name) from e\n\n    @retry(\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=1, min=1, max=16),\n        retry=retry_if_exception_type((httpx.TimeoutException, httpx.NetworkError, DeliveryError)),\n        before_sleep=before_sleep_log(logger, logging.WARNING),\n        reraise=True,\n    )\n    async def _send_events_batch_with_retry(\n        self, events: List[IntegrationEvent]\n    ) -> List[IntegrationResult]:\n        \"\"\"Send events batch with retry logic\"\"\"\n        return await self._do_send_events_batch(events)\n\n    async def _do_send_events_batch(\n        self,\n        events: List[IntegrationEvent],\n    ) -> List[IntegrationResult]:\n        \"\"\"\n        Perform the actual batch event delivery.\n\n        This is the core method that subclasses override to implement adapter-specific\n        batch delivery logic when the external service supports batch operations.\n        This method is called by send_events_batch() after authentication checks and\n        is wrapped with automatic retry logic.\n\n        If not overridden, the base implementation will automatically fall back to\n        sending events one-by-one using _do_send_event(), allowing all adapters to\n        support batch operations transparently without additional implementation.\n\n        Implementation Contract:\n            - Called ONLY by send_events_batch() after authentication is verified\n            - Wrapped with automatic retry logic (3 attempts, exponential backoff)\n            - Should NOT handle authentication (handled by send_events_batch)\n            - Should NOT track metrics (handled by send_events_batch)\n            - MUST return one IntegrationResult per input event in same order\n            - MUST preserve event ordering in results for correlation\n\n        When to Override:\n            Override this method if:\n            - The external service has a dedicated batch API endpoint\n            - Batch operations are significantly more efficient than individual calls\n            - The service supports sending multiple events in a single HTTP request\n            - You want to implement custom batch size limits or chunking\n\n            Do NOT override if:\n            - The service only supports individual event submission\n            - The default one-by-one fallback is acceptable for your use case\n            - Examples: Jira, ServiceNow (no native batch APIs)\n\n        Error Handling:\n            Subclass implementations should raise:\n            - RateLimitError: When rate limited (include retry_after if available)\n            - DeliveryError: For general delivery failures (will trigger retry)\n            - AuthenticationError: If token/credentials become invalid mid-request\n            - IntegrationConnectionError: For network/connectivity issues\n\n            Do NOT catch and suppress exceptions - let them propagate for retry logic.\n            The send_events_batch() method handles retry orchestration and metrics.\n\n        Batch Size Considerations:\n            - Respect service-specific limits (e.g., Splunk HEC, Sentinel 1MB/500 records)\n            - Consider implementing chunking for large batches\n            - Document recommended batch sizes in adapter-specific docstrings\n            - Return appropriate errors if batch size exceeds service limits\n\n        Args:\n            events: List of governance events to send. Guaranteed to be non-empty\n                   (empty lists handled by send_events_batch). Events must be\n                   processed in the order provided.\n\n        Returns:\n            List of IntegrationResults for each event, in the same order as input.\n            Each result indicates success or failure for the corresponding event.\n            - For all-or-nothing semantics: All results have same success status\n            - For partial success: Mixed success/failure results allowed\n            - Empty input returns empty list (but should not occur in practice)\n\n        Raises:\n            RateLimitError: Service rate limit exceeded. Set retry_after attribute\n                          to indicate when to retry (seconds from now).\n            DeliveryError: Batch delivery failed. Will trigger retry logic.\n            AuthenticationError: Authentication token expired or invalid.\n            IntegrationConnectionError: Network or connectivity issues.\n\n        Implementation Examples:\n\n            All-or-nothing batch (Splunk/Sentinel pattern):\n            ```python\n            async def _do_send_events_batch(\n                self,\n                events: List[IntegrationEvent]\n            ) -> List[IntegrationResult]:\n                '''Send events using service's batch API (all-or-nothing).'''\n                if not events:\n                    return []\n\n                # Format events for service's batch API\n                batch_payload = self._format_batch_payload(events)\n\n                # Send batch request\n                client = await self.get_http_client()\n                response = await client.post(\n                    \"/api/batch\",\n                    json=batch_payload,\n                    headers={\"Authorization\": f\"Bearer {self.token}\"}\n                )\n\n                # Handle rate limiting\n                if response.status_code == 429:\n                    retry_after = int(response.headers.get(\"Retry-After\", 60))\n                    raise RateLimitError(\n                        \"Batch rate limited\",\n                        self.name,\n                        retry_after=retry_after\n                    )\n\n                # All-or-nothing semantics\n                if response.status_code == 200:\n                    # All events succeeded\n                    return [\n                        IntegrationResult(\n                            success=True,\n                            integration_name=self.name,\n                            operation=\"send_event\",\n                            external_id=event.event_id,\n                        )\n                        for event in events\n                    ]\n                else:\n                    # All events failed\n                    error_msg = response.text or f\"HTTP {response.status_code}\"\n                    return [\n                        IntegrationResult(\n                            success=False,\n                            integration_name=self.name,\n                            operation=\"send_event\",\n                            error_code=\"BATCH_FAILED\",\n                            error_message=error_msg,\n                        )\n                        for _ in events\n                    ]\n            ```\n\n            Partial success batch (custom pattern):\n            ```python\n            async def _do_send_events_batch(\n                self,\n                events: List[IntegrationEvent]\n            ) -> List[IntegrationResult]:\n                '''Send events with per-event success/failure tracking.'''\n                if not events:\n                    return []\n\n                # Format events for service's batch API\n                batch_payload = [self._format_event(e) for e in events]\n\n                # Send batch request\n                client = await self.get_http_client()\n                response = await client.post(\"/api/batch\", json=batch_payload)\n\n                if response.status_code != 200:\n                    # Entire batch failed\n                    raise DeliveryError(\n                        f\"Batch request failed: {response.text}\",\n                        self.name\n                    )\n\n                # Parse per-event results from response\n                results = []\n                response_data = response.json()\n                for idx, event in enumerate(events):\n                    event_result = response_data[\"results\"][idx]\n                    if event_result[\"status\"] == \"success\":\n                        results.append(IntegrationResult(\n                            success=True,\n                            integration_name=self.name,\n                            operation=\"send_event\",\n                            external_id=event_result[\"id\"],\n                        ))\n                    else:\n                        results.append(IntegrationResult(\n                            success=False,\n                            integration_name=self.name,\n                            operation=\"send_event\",\n                            error_code=event_result[\"error_code\"],\n                            error_message=event_result[\"error_message\"],\n                        ))\n\n                return results\n            ```\n\n            Chunking large batches:\n            ```python\n            async def _do_send_events_batch(\n                self,\n                events: List[IntegrationEvent]\n            ) -> List[IntegrationResult]:\n                '''Send events in chunks to respect service limits.'''\n                MAX_BATCH_SIZE = 100  # Service limit\n\n                if len(events) <= MAX_BATCH_SIZE:\n                    # Single batch\n                    return await self._send_single_batch(events)\n\n                # Chunk and send multiple batches\n                results = []\n                for i in range(0, len(events), MAX_BATCH_SIZE):\n                    chunk = events[i:i + MAX_BATCH_SIZE]\n                    chunk_results = await self._send_single_batch(chunk)\n                    results.extend(chunk_results)\n\n                return results\n            ```\n\n        Default Fallback Implementation:\n            If not overridden, sends events one-by-one using _do_send_event():\n            - Processes events sequentially in order\n            - Each event gets individual IntegrationResult\n            - Exceptions caught and converted to failure results\n            - Allows partial success (some events succeed, others fail)\n            - Suitable for adapters without batch APIs (Jira, ServiceNow)\n\n        See Also:\n            - send_events_batch(): Public API with auth checks and metrics\n            - _send_events_batch_with_retry(): Retry wrapper for this method\n            - Splunk adapter: Reference implementation with all-or-nothing semantics\n            - Sentinel adapter: Reference implementation with Azure DCR API\n        \"\"\"\n        # Default implementation: send events one-by-one\n        # Subclasses can override this for more efficient batch operations\n        logger.debug(\n            f\"Using default batch implementation for '{self.name}' - sending events one-by-one\"\n        )\n\n        results = []\n        for event in events:\n            try:\n                result = await self._do_send_event(event)\n                results.append(result)\n            except Exception as e:\n                # Create a failure result for this event\n                results.append(\n                    IntegrationResult(\n                        success=False,\n                        integration_name=self.name,\n                        operation=\"send_event\",\n                        error_code=\"SEND_FAILED\",\n                        error_message=str(e),\n                    )\n                )\n\n        return results\n\n    async def test_connection(self) -> IntegrationResult:\n        \"\"\"\n        Test the connection to the external service without fully authenticating.\n\n        Returns:\n            IntegrationResult indicating if the service is reachable\n        \"\"\"\n        logger.info(f\"Testing connection for integration '{self.name}'\")\n\n        try:\n            result = await self._do_test_connection()\n            return result\n        except Exception as e:\n            logger.error(f\"Connection test failed for '{self.name}': {str(e)}\")\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=\"CONNECTION_ERROR\",\n                error_message=str(e),\n            )\n\n    async def _do_test_connection(self) -> IntegrationResult:\n        \"\"\"\n        Test connection implementation.\n\n        Default implementation uses the base_url from credentials.\n        Subclasses can override for custom connection testing.\n        \"\"\"\n        if not self.credentials.base_url:\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=\"NO_BASE_URL\",\n                error_message=\"No base URL configured\",\n            )\n\n        try:\n            client = await self.get_http_client()\n            response = await client.head(self.credentials.base_url)\n\n            return IntegrationResult(\n                success=response.status_code < 500,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=None if response.status_code < 500 else f\"HTTP_{response.status_code}\",\n                error_message=(\n                    None\n                    if response.status_code < 500\n                    else f\"Server returned status {response.status_code}\"\n                ),\n            )\n        except httpx.TimeoutException:\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=\"TIMEOUT\",\n                error_message=f\"Connection timed out after {self.timeout}s\",\n            )\n        except httpx.NetworkError as e:\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=\"NETWORK_ERROR\",\n                error_message=str(e),\n            )\n\n    def _redact_sensitive_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Redact sensitive data from a dictionary for logging.\n\n        Args:\n            data: Dictionary that may contain sensitive values\n\n        Returns:\n            Copy of the dictionary with sensitive values redacted\n        \"\"\"\n        sensitive_keys = {\n            \"password\",\n            \"token\",\n            \"secret\",\n            \"api_key\",\n            \"api_token\",\n            \"access_token\",\n            \"refresh_token\",\n            \"client_secret\",\n            \"hec_token\",\n            \"bearer\",\n            \"authorization\",\n        }\n\n        def redact_value(key: str, value: Any) -> Any:\n            if isinstance(value, dict):\n                return {k: redact_value(k, v) for k, v in value.items()}\n            elif isinstance(value, list):\n                return [redact_value(key, item) for item in value]\n            elif any(sensitive in key.lower() for sensitive in sensitive_keys):\n                return \"***REDACTED***\"\n            return value\n\n        return {k: redact_value(k, v) for k, v in data.items()}\n\n    def __repr__(self) -> str:\n        return (\n            f\"<{self.__class__.__name__}(name={self.name}, \"\n            f\"type={self.integration_type.value}, status={self.status.value})>\"\n        )\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), acgs2-core/breakthrough (79 occurrences), and acgs2-core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    },
    "037-add-batch-event-processing-to-baseintegration": {
      "task_id": "037-add-batch-event-processing-to-baseintegration",
      "branch_point": {
        "commit_hash": "2fb699cec90aaf3419af3108057ed29ae4213e1b",
        "content": "\"\"\"\nBase Integration Adapter Class\n\nProvides the abstract base class for all third-party integrations with\nauthenticate/validate/send_event methods and common functionality.\n\"\"\"\n\nimport abc\nimport logging\nfrom datetime import datetime, timezone\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, TypeVar\nfrom uuid import uuid4\n\nimport httpx\nfrom pydantic import BaseModel, Field, SecretStr\nfrom tenacity import (\n    RetryError,\n    before_sleep_log,\n    retry,\n    retry_if_exception_type,\n    stop_after_attempt,\n    wait_exponential,\n)\n\n# Import exceptions from centralized exceptions module\nfrom exceptions.auth import AuthenticationError\nfrom exceptions.delivery import DeliveryError\nfrom exceptions.integration import (\n    IntegrationConnectionError,\n    IntegrationError,\n    RateLimitError,\n)\nfrom exceptions.validation import ValidationError\n\nlogger = logging.getLogger(__name__)\n\n\n# Public API exports - make exceptions and classes available for import from this module\n__all__ = [\n    # Exceptions - imported from centralized exceptions module\n    \"IntegrationError\",\n    \"AuthenticationError\",\n    \"ValidationError\",\n    \"DeliveryError\",\n    \"RateLimitError\",\n    \"IntegrationConnectionError\",\n    # Enums\n    \"IntegrationType\",\n    \"IntegrationStatus\",\n    \"EventSeverity\",\n    # Models\n    \"IntegrationCredentials\",\n    \"IntegrationEvent\",\n    \"IntegrationResult\",\n    # Base class\n    \"BaseIntegration\",\n]\n\n\n# Enums\nclass IntegrationType(str, Enum):\n    \"\"\"Types of integrations supported\"\"\"\n\n    SIEM = \"siem\"\n    TICKETING = \"ticketing\"\n    CICD = \"cicd\"\n    WEBHOOK = \"webhook\"\n\n\nclass IntegrationStatus(str, Enum):\n    \"\"\"Status of an integration\"\"\"\n\n    ACTIVE = \"active\"\n    INACTIVE = \"inactive\"\n    ERROR = \"error\"\n    AUTHENTICATING = \"authenticating\"\n    RATE_LIMITED = \"rate_limited\"\n\n\nclass EventSeverity(str, Enum):\n    \"\"\"Severity levels for governance events\"\"\"\n\n    CRITICAL = \"critical\"\n    HIGH = \"high\"\n    MEDIUM = \"medium\"\n    LOW = \"low\"\n    INFO = \"info\"\n\n\n# Pydantic Models\nclass IntegrationCredentials(BaseModel):\n    \"\"\"Base model for integration credentials\"\"\"\n\n    integration_id: str = Field(default_factory=lambda: str(uuid4()))\n    integration_name: str = Field(..., description=\"Name of the integration\")\n    integration_type: IntegrationType = Field(..., description=\"Type of integration\")\n\n    # Common credential fields - subclasses override with specific fields\n    api_key: Optional[SecretStr] = Field(None, description=\"API key if applicable\")\n    api_token: Optional[SecretStr] = Field(None, description=\"API token if applicable\")\n    username: Optional[str] = Field(None, description=\"Username if applicable\")\n    password: Optional[SecretStr] = Field(None, description=\"Password if applicable\")\n    base_url: Optional[str] = Field(None, description=\"Base URL for the integration\")\n\n    # OAuth fields\n    client_id: Optional[str] = Field(None, description=\"OAuth client ID\")\n    client_secret: Optional[SecretStr] = Field(None, description=\"OAuth client secret\")\n    tenant_id: Optional[str] = Field(None, description=\"Tenant ID for multi-tenant services\")\n    access_token: Optional[SecretStr] = Field(None, description=\"OAuth access token\")\n    refresh_token: Optional[SecretStr] = Field(None, description=\"OAuth refresh token\")\n    token_expires_at: Optional[datetime] = Field(None, description=\"Token expiration time\")\n\n    class Config:\n        \"\"\"Pydantic config\"\"\"\n\n        json_encoders = {\n            SecretStr: lambda v: \"***REDACTED***\" if v else None,\n        }\n\n\nclass IntegrationEvent(BaseModel):\n    \"\"\"Model for governance events to be sent to integrations\"\"\"\n\n    event_id: str = Field(default_factory=lambda: str(uuid4()))\n    event_type: str = Field(..., description=\"Type of governance event\")\n    timestamp: datetime = Field(\n        default_factory=lambda: datetime.now(timezone.utc),\n        description=\"Event timestamp in UTC\",\n    )\n    severity: EventSeverity = Field(EventSeverity.INFO, description=\"Event severity level\")\n    source: str = Field(\"acgs2\", description=\"Source system\")\n\n    # Event content\n    policy_id: Optional[str] = Field(None, description=\"Related policy ID\")\n    resource_id: Optional[str] = Field(None, description=\"Affected resource ID\")\n    resource_type: Optional[str] = Field(None, description=\"Type of affected resource\")\n    action: Optional[str] = Field(None, description=\"Action that triggered the event\")\n    outcome: Optional[str] = Field(None, description=\"Outcome of the action\")\n\n    # Details\n    title: str = Field(..., description=\"Event title/summary\")\n    description: Optional[str] = Field(None, description=\"Detailed description\")\n    details: Dict[str, Any] = Field(default_factory=dict, description=\"Additional event details\")\n\n    # Metadata\n    user_id: Optional[str] = Field(None, description=\"User who triggered the event\")\n    tenant_id: Optional[str] = Field(None, description=\"Tenant ID for multi-tenant deployments\")\n    correlation_id: Optional[str] = Field(None, description=\"Correlation ID for tracing\")\n    tags: List[str] = Field(default_factory=list, description=\"Event tags\")\n\n\nclass IntegrationResult(BaseModel):\n    \"\"\"Result of an integration operation\"\"\"\n\n    success: bool = Field(..., description=\"Whether the operation succeeded\")\n    integration_name: str = Field(..., description=\"Name of the integration\")\n    operation: str = Field(..., description=\"Operation performed\")\n    timestamp: datetime = Field(\n        default_factory=lambda: datetime.now(timezone.utc),\n        description=\"Operation timestamp\",\n    )\n\n    # Success details\n    external_id: Optional[str] = Field(\n        None, description=\"External system ID (e.g., ticket ID, event ID)\"\n    )\n    external_url: Optional[str] = Field(None, description=\"URL to the external resource\")\n\n    # Error details\n    error_code: Optional[str] = Field(None, description=\"Error code if failed\")\n    error_message: Optional[str] = Field(None, description=\"Error message if failed\")\n    error_details: Dict[str, Any] = Field(\n        default_factory=dict, description=\"Additional error details\"\n    )\n\n    # Retry info\n    retry_count: int = Field(0, description=\"Number of retry attempts\")\n    should_retry: bool = Field(False, description=\"Whether operation should be retried\")\n    retry_after: Optional[int] = Field(None, description=\"Seconds to wait before retry\")\n\n\nclass BatchIntegrationResult(BaseModel):\n    \"\"\"\n    Result of a batch integration operation.\n\n    Provides batch-level success/failure tracking with per-event results,\n    enabling efficient monitoring and debugging of batch event processing.\n\n    The batch is considered successful if all events succeeded, partially successful\n    if some events succeeded, or failed if all events failed.\n\n    Example:\n        ```python\n        # Send batch of events\n        results = await adapter.send_events_batch(events)\n\n        # Wrap in BatchIntegrationResult for summary\n        batch_result = BatchIntegrationResult.from_results(\n            integration_name=adapter.name,\n            operation=\"send_events_batch\",\n            results=results\n        )\n\n        # Check overall batch status\n        if batch_result.all_succeeded:\n            logger.info(\n                f\"Batch completed: \"\n                f\"{batch_result.successful_count}/{batch_result.total_count}\"\n            )\n        elif batch_result.partial_success:\n            logger.warning(\n                f\"Partial success: \"\n                f\"{batch_result.successful_count}/{batch_result.total_count}\"\n            )\n        else:\n            logger.error(f\"Batch failed: {batch_result.error_message}\")\n\n        # Access individual event results\n        for i, result in enumerate(batch_result.event_results):\n            if not result.success:\n                logger.error(f\"Event {i} failed: {result.error_message}\")\n        ```\n    \"\"\"\n\n    integration_name: str = Field(..., description=\"Name of the integration\")\n    operation: str = Field(\n        default=\"send_events_batch\", description=\"Batch operation performed\"\n    )\n    timestamp: datetime = Field(\n        default_factory=lambda: datetime.now(timezone.utc),\n        description=\"Batch operation timestamp\",\n    )\n\n    # Per-event results\n    event_results: List[IntegrationResult] = Field(\n        ..., description=\"Individual result for each event in the batch\"\n    )\n\n    # Batch-level summary statistics\n    total_count: int = Field(..., description=\"Total number of events in the batch\")\n    successful_count: int = Field(..., description=\"Number of events that succeeded\")\n    failed_count: int = Field(..., description=\"Number of events that failed\")\n\n    # Batch-level status\n    all_succeeded: bool = Field(..., description=\"True if all events succeeded\")\n    all_failed: bool = Field(..., description=\"True if all events failed\")\n    partial_success: bool = Field(\n        ..., description=\"True if some (but not all) events succeeded\"\n    )\n\n    # Error details (for complete failures)\n    error_code: Optional[str] = Field(None, description=\"Error code if batch completely failed\")\n    error_message: Optional[str] = Field(\n        None, description=\"Error message if batch completely failed\"\n    )\n    error_details: Dict[str, Any] = Field(\n        default_factory=dict, description=\"Additional error details\"\n    )\n\n    # Retry info\n    retry_count: int = Field(0, description=\"Number of retry attempts for the batch\")\n    should_retry: bool = Field(\n        False, description=\"Whether the batch operation should be retried\"\n    )\n\n    @classmethod\n    def from_results(\n        cls,\n        integration_name: str,\n        operation: str,\n        results: List[IntegrationResult],\n        retry_count: int = 0,\n    ) -> \"BatchIntegrationResult\":\n        \"\"\"\n        Create a BatchIntegrationResult from a list of IntegrationResults.\n\n        Automatically computes summary statistics and determines batch-level status.\n\n        Args:\n            integration_name: Name of the integration\n            operation: Operation performed (e.g., \"send_events_batch\")\n            results: List of individual event results\n            retry_count: Number of retry attempts for this batch\n\n        Returns:\n            BatchIntegrationResult with computed statistics\n        \"\"\"\n        total = len(results)\n        successful = sum(1 for r in results if r.success)\n        failed = total - successful\n\n        all_succeeded = failed == 0 and total > 0\n        all_failed = successful == 0 and total > 0\n        partial_success = successful > 0 and failed > 0\n\n        # Extract error details from first failure if all failed\n        error_code = None\n        error_message = None\n        error_details = {}\n        if all_failed and results:\n            first_failure = results[0]\n            error_code = first_failure.error_code\n            error_message = first_failure.error_message\n            error_details = first_failure.error_details\n\n        return cls(\n            integration_name=integration_name,\n            operation=operation,\n            event_results=results,\n            total_count=total,\n            successful_count=successful,\n            failed_count=failed,\n            all_succeeded=all_succeeded,\n            all_failed=all_failed,\n            partial_success=partial_success,\n            error_code=error_code,\n            error_message=error_message,\n            error_details=error_details,\n            retry_count=retry_count,\n            should_retry=all_failed and any(r.should_retry for r in results),\n        )\n\n    @property\n    def success_rate(self) -> float:\n        \"\"\"\n        Calculate the success rate as a percentage.\n\n        Returns:\n            Success rate from 0.0 to 100.0, or 0.0 if no events\n        \"\"\"\n        if self.total_count == 0:\n            return 0.0\n        return (self.successful_count / self.total_count) * 100.0\n\n\n# Type variable for generic integration config\nConfigT = TypeVar(\"ConfigT\", bound=IntegrationCredentials)\n\n\nclass BaseIntegration(abc.ABC):\n    \"\"\"\n    Abstract base class for all third-party integrations.\n\n    Provides common functionality for authentication, validation, and event delivery\n    with built-in retry logic, circuit breaker support, and comprehensive error handling.\n\n    Subclasses must implement:\n    - _do_authenticate(): Perform actual authentication\n    - _do_validate(): Perform actual validation\n    - _do_send_event(): Perform actual event delivery\n    \"\"\"\n\n    # Default retry configuration\n    DEFAULT_MAX_RETRIES = 3\n    DEFAULT_RETRY_MIN_WAIT = 1  # seconds\n    DEFAULT_RETRY_MAX_WAIT = 16  # seconds\n    DEFAULT_TIMEOUT = 30.0  # seconds\n\n    def __init__(\n        self,\n        credentials: IntegrationCredentials,\n        max_retries: int = DEFAULT_MAX_RETRIES,\n        timeout: float = DEFAULT_TIMEOUT,\n    ):\n        \"\"\"\n        Initialize the integration adapter.\n\n        Args:\n            credentials: Integration credentials and configuration\n            max_retries: Maximum number of retry attempts for operations\n            timeout: HTTP request timeout in seconds\n        \"\"\"\n        self.credentials = credentials\n        self.max_retries = max_retries\n        self.timeout = timeout\n\n        # State\n        self._status = IntegrationStatus.INACTIVE\n        self._authenticated = False\n        self._last_error: Optional[str] = None\n        self._http_client: Optional[httpx.AsyncClient] = None\n\n        # Metrics\n        self._events_sent = 0\n        self._events_failed = 0\n        self._last_success: Optional[datetime] = None\n        self._last_failure: Optional[datetime] = None\n\n        # Batch metrics\n        self._batches_sent = 0\n        self._batches_failed = 0\n        self._batch_events_total = 0\n\n    @property\n    def name(self) -> str:\n        \"\"\"Get integration name\"\"\"\n        return self.credentials.integration_name\n\n    @property\n    def integration_type(self) -> IntegrationType:\n        \"\"\"Get integration type\"\"\"\n        return self.credentials.integration_type\n\n    @property\n    def status(self) -> IntegrationStatus:\n        \"\"\"Get current integration status\"\"\"\n        return self._status\n\n    @property\n    def is_authenticated(self) -> bool:\n        \"\"\"Check if integration is authenticated\"\"\"\n        return self._authenticated\n\n    @property\n    def metrics(self) -> Dict[str, Any]:\n        \"\"\"Get integration metrics\"\"\"\n        return {\n            \"events_sent\": self._events_sent,\n            \"events_failed\": self._events_failed,\n            \"last_success\": self._last_success.isoformat() if self._last_success else None,\n            \"last_failure\": self._last_failure.isoformat() if self._last_failure else None,\n            \"status\": self._status.value,\n            \"authenticated\": self._authenticated,\n            \"batches_sent\": self._batches_sent,\n            \"batches_failed\": self._batches_failed,\n            \"batch_events_total\": self._batch_events_total,\n        }\n\n    async def get_http_client(self) -> httpx.AsyncClient:\n        \"\"\"Get or create HTTP client with proper configuration\"\"\"\n        if self._http_client is None or self._http_client.is_closed:\n            self._http_client = httpx.AsyncClient(\n                timeout=self.timeout,\n                follow_redirects=True,\n            )\n        return self._http_client\n\n    async def close(self) -> None:\n        \"\"\"Close the integration and cleanup resources\"\"\"\n        if self._http_client is not None and not self._http_client.is_closed:\n            await self._http_client.aclose()\n            self._http_client = None\n        self._authenticated = False\n        self._status = IntegrationStatus.INACTIVE\n        logger.info(f\"Integration '{self.name}' closed\")\n\n    async def authenticate(self) -> IntegrationResult:\n        \"\"\"\n        Authenticate with the external service.\n\n        Returns:\n            IntegrationResult with success status and any error details\n\n        Raises:\n            AuthenticationError: If authentication fails after retries\n        \"\"\"\n        logger.info(f\"Authenticating integration '{self.name}'\")\n        self._status = IntegrationStatus.AUTHENTICATING\n\n        try:\n            result = await self._authenticate_with_retry()\n\n            if result.success:\n                self._authenticated = True\n                self._status = IntegrationStatus.ACTIVE\n                self._last_success = datetime.now(timezone.utc)\n                logger.info(f\"Integration '{self.name}' authenticated successfully\")\n            else:\n                self._authenticated = False\n                self._status = IntegrationStatus.ERROR\n                self._last_error = result.error_message\n                self._last_failure = datetime.now(timezone.utc)\n                logger.error(\n                    f\"Integration '{self.name}' authentication failed: {result.error_message}\"\n                )\n\n            return result\n\n        except RetryError as e:\n            self._authenticated = False\n            self._status = IntegrationStatus.ERROR\n            self._last_failure = datetime.now(timezone.utc)\n            error_msg = f\"Authentication failed after {self.max_retries} retries: {str(e)}\"\n            self._last_error = error_msg\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise AuthenticationError(error_msg, self.name) from e\n\n    @retry(\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=1, min=1, max=16),\n        retry=retry_if_exception_type((httpx.TimeoutException, httpx.NetworkError)),\n        before_sleep=before_sleep_log(logger, logging.WARNING),\n        reraise=True,\n    )\n    async def _authenticate_with_retry(self) -> IntegrationResult:\n        \"\"\"Authenticate with retry logic\"\"\"\n        return await self._do_authenticate()\n\n    @abc.abstractmethod\n    async def _do_authenticate(self) -> IntegrationResult:\n        \"\"\"\n        Perform the actual authentication.\n\n        Subclasses must implement this method with their specific authentication logic.\n\n        Returns:\n            IntegrationResult with success status\n        \"\"\"\n        pass\n\n    async def validate(self) -> IntegrationResult:\n        \"\"\"\n        Validate the integration configuration and connectivity.\n\n        Returns:\n            IntegrationResult with validation status\n\n        Raises:\n            ValidationError: If validation fails\n        \"\"\"\n        logger.info(f\"Validating integration '{self.name}'\")\n\n        try:\n            result = await self._validate_with_retry()\n\n            if result.success:\n                logger.info(f\"Integration '{self.name}' validation successful\")\n            else:\n                self._last_error = result.error_message\n                logger.warning(\n                    f\"Integration '{self.name}' validation failed: {result.error_message}\"\n                )\n\n            return result\n\n        except RetryError as e:\n            error_msg = f\"Validation failed after {self.max_retries} retries: {str(e)}\"\n            self._last_error = error_msg\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise ValidationError(error_msg, self.name) from e\n\n    @retry(\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=1, min=1, max=16),\n        retry=retry_if_exception_type((httpx.TimeoutException, httpx.NetworkError)),\n        before_sleep=before_sleep_log(logger, logging.WARNING),\n        reraise=True,\n    )\n    async def _validate_with_retry(self) -> IntegrationResult:\n        \"\"\"Validate with retry logic\"\"\"\n        return await self._do_validate()\n\n    @abc.abstractmethod\n    async def _do_validate(self) -> IntegrationResult:\n        \"\"\"\n        Perform the actual validation.\n\n        Subclasses must implement this method to validate:\n        - Credentials are properly configured\n        - External service is reachable\n        - Required permissions are granted\n        - Infrastructure prerequisites exist (e.g., Splunk index, Sentinel DCR)\n\n        Returns:\n            IntegrationResult with validation status\n        \"\"\"\n        pass\n\n    async def send_event(self, event: IntegrationEvent) -> IntegrationResult:\n        \"\"\"\n        Send a governance event to the external service.\n\n        Args:\n            event: The governance event to send\n\n        Returns:\n            IntegrationResult with delivery status\n\n        Raises:\n            DeliveryError: If delivery fails after retries\n            AuthenticationError: If not authenticated\n            RateLimitError: If rate limited by the external service\n        \"\"\"\n        if not self._authenticated:\n            error_msg = \"Integration is not authenticated\"\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise AuthenticationError(error_msg, self.name)\n\n        logger.debug(f\"Sending event {event.event_id} to integration '{self.name}'\")\n\n        try:\n            result = await self._send_event_with_retry(event)\n\n            if result.success:\n                self._events_sent += 1\n                self._last_success = datetime.now(timezone.utc)\n                logger.info(\n                    f\"Event {event.event_id} sent successfully to '{self.name}'. \"\n                    f\"External ID: {result.external_id}\"\n                )\n            else:\n                self._events_failed += 1\n                self._last_failure = datetime.now(timezone.utc)\n                self._last_error = result.error_message\n                logger.warning(\n                    f\"Event {event.event_id} delivery to '{self.name}' failed: \"\n                    f\"{result.error_message}\"\n                )\n\n            return result\n\n        except RetryError as e:\n            self._events_failed += 1\n            self._last_failure = datetime.now(timezone.utc)\n            error_msg = f\"Event delivery failed after {self.max_retries} retries: {str(e)}\"\n            self._last_error = error_msg\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise DeliveryError(error_msg, self.name) from e\n\n    @retry(\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=1, min=1, max=16),\n        retry=retry_if_exception_type((httpx.TimeoutException, httpx.NetworkError, DeliveryError)),\n        before_sleep=before_sleep_log(logger, logging.WARNING),\n        reraise=True,\n    )\n    async def _send_event_with_retry(self, event: IntegrationEvent) -> IntegrationResult:\n        \"\"\"Send event with retry logic\"\"\"\n        return await self._do_send_event(event)\n\n    @abc.abstractmethod\n    async def _do_send_event(self, event: IntegrationEvent) -> IntegrationResult:\n        \"\"\"\n        Perform the actual event delivery.\n\n        Subclasses must implement this method with their specific delivery logic.\n        Should handle rate limiting by raising RateLimitError with retry_after.\n\n        Args:\n            event: The governance event to send\n\n        Returns:\n            IntegrationResult with delivery status\n        \"\"\"\n        pass\n\n    async def send_events_batch(\n        self,\n        events: List[IntegrationEvent],\n    ) -> List[IntegrationResult]:\n        \"\"\"\n        Send multiple governance events to the external service in a batch.\n\n        Optimizes delivery by sending multiple events in a single API call where\n        supported, reducing network overhead and improving throughput for high-volume\n        governance event scenarios. This method provides automatic retry logic,\n        comprehensive metrics tracking, and fallback support for adapters without\n        native batch capabilities.\n\n        For adapters that don't support native batch operations, this method will\n        automatically fall back to sending events one-by-one using _do_send_event(),\n        providing transparent batch API support across all integrations.\n\n        Performance Characteristics:\n            - Batch operations reduce API calls from N to 1 for batch-capable adapters\n            - Network latency reduced from N*RTT to 1*RTT for batch operations\n            - Recommended for sending 10+ events when the adapter supports batching\n            - Empty list returns immediately with no side effects\n\n        Retry Behavior:\n            - Automatically retries batch operations up to 3 times (configurable)\n            - Uses exponential backoff: 1s, 2s, 4s, up to 16s between retries\n            - Retries on: TimeoutException, NetworkError, DeliveryError\n            - Does NOT retry on: AuthenticationError, ValidationError\n            - RateLimitError includes retry_after hint from service\n\n        Metrics Tracking:\n            - _batches_sent: Incremented for successful batches (all or partial success)\n            - _batches_failed: Incremented when all events in batch fail\n            - _batch_events_total: Total count of events successfully sent via batches\n            - _events_sent: Per-event success count (same as send_event)\n            - _events_failed: Per-event failure count (same as send_event)\n            - Metrics accessible via integration.metrics property\n\n        Args:\n            events: List of governance events to send. Can be empty (returns empty list).\n                   Events are processed in the order provided, and results maintain\n                   the same ordering for correlation.\n\n        Returns:\n            List of IntegrationResults, one for each input event. Results are returned\n            in the same order as the input events, allowing direct correlation via\n            zip(events, results). Empty list returns empty results.\n\n        Raises:\n            AuthenticationError: If the integration is not authenticated. Call\n                               authenticate() before sending events.\n            DeliveryError: If batch delivery fails after all retry attempts. Contains\n                          details about the final failure reason.\n            RateLimitError: If rate limited by the external service. The retry_after\n                           attribute indicates when to retry (seconds).\n\n        Example:\n            Basic batch sending:\n            ```python\n            # Send a batch of events\n            events = [event1, event2, event3]\n            results = await adapter.send_events_batch(events)\n\n            # Check results for each event\n            for event, result in zip(events, results):\n                if result.success:\n                    logger.info(f\"Event {event.event_id} sent successfully\")\n                else:\n                    logger.error(f\"Event {event.event_id} failed: {result.error_message}\")\n            ```\n\n            Checking batch metrics:\n            ```python\n            # Send multiple batches\n            await adapter.send_events_batch(batch1)\n            await adapter.send_events_batch(batch2)\n\n            # Check batch statistics\n            metrics = adapter.metrics\n            logger.info(f\"Batches sent: {metrics['batches_sent']}\")\n            logger.info(f\"Total events via batch: {metrics['batch_events_total']}\")\n            logger.info(f\"Batch success rate: {metrics['batches_sent']/(metrics['batches_sent']+metrics['batches_failed']):.1%}\")\n            ```\n\n            Handling partial success:\n            ```python\n            results = await adapter.send_events_batch(events)\n            successful = [r for r in results if r.success]\n            failed = [r for r in results if not r.success]\n\n            if failed:\n                logger.warning(f\"Partial batch failure: {len(failed)}/{len(events)} failed\")\n                # Retry failed events individually if needed\n                for idx, result in enumerate(results):\n                    if not result.success:\n                        await adapter.send_event(events[idx])\n            ```\n\n        Note:\n            Batch semantics depend on the adapter implementation:\n            - Splunk HEC: All-or-nothing semantics (all succeed or all fail)\n            - Sentinel DCR: All-or-nothing semantics (all succeed or all fail)\n            - Jira/ServiceNow: Default one-by-one fallback allows partial success\n            - Custom adapters: Can implement either semantic by overriding\n              _do_send_events_batch()\n\n            Thread Safety:\n            - This method is async-safe but not thread-safe\n            - Metrics updates are not atomic across threads\n            - Use separate adapter instances for concurrent threads\n\n            Authentication:\n            - Must call authenticate() before using this method\n            - Authentication state checked before each batch\n            - Raises AuthenticationError immediately if not authenticated\n        \"\"\"\n        if not self._authenticated:\n            error_msg = \"Integration is not authenticated\"\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise AuthenticationError(error_msg, self.name)\n\n        if not events:\n            return []\n\n        logger.debug(f\"Sending batch of {len(events)} events to integration '{self.name}'\")\n\n        try:\n            results = await self._send_events_batch_with_retry(events)\n\n            # Count successful and failed events\n            successful_count = sum(1 for r in results if r.success)\n            failed_count = len(results) - successful_count\n\n            # Track metrics\n            if failed_count == 0:\n                # All events succeeded\n                self._batches_sent += 1\n                self._events_sent += successful_count\n                self._batch_events_total += successful_count\n                self._last_success = datetime.now(timezone.utc)\n                logger.info(\n                    f\"Batch of {len(events)} events sent successfully to '{self.name}'\"\n                )\n            elif successful_count == 0:\n                # All events failed\n                self._batches_failed += 1\n                self._events_failed += failed_count\n                self._last_failure = datetime.now(timezone.utc)\n                self._last_error = results[0].error_message if results else \"Batch delivery failed\"\n                logger.warning(\n                    f\"Batch of {len(events)} events failed to send to '{self.name}': \"\n                    f\"{self._last_error}\"\n                )\n            else:\n                # Partial success\n                self._batches_sent += 1\n                self._events_sent += successful_count\n                self._events_failed += failed_count\n                self._batch_events_total += successful_count\n                self._last_success = datetime.now(timezone.utc)\n                logger.warning(\n                    f\"Batch of {len(events)} events partially succeeded for '{self.name}': \"\n                    f\"{successful_count} succeeded, {failed_count} failed\"\n                )\n\n            return results\n\n        except RetryError as e:\n            self._batches_failed += 1\n            self._events_failed += len(events)\n            self._last_failure = datetime.now(timezone.utc)\n            error_msg = f\"Batch delivery failed after {self.max_retries} retries: {str(e)}\"\n            self._last_error = error_msg\n            logger.error(f\"Integration '{self.name}': {error_msg}\")\n            raise DeliveryError(error_msg, self.name) from e\n\n    @retry(\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=1, min=1, max=16),\n        retry=retry_if_exception_type((httpx.TimeoutException, httpx.NetworkError, DeliveryError)),\n        before_sleep=before_sleep_log(logger, logging.WARNING),\n        reraise=True,\n    )\n    async def _send_events_batch_with_retry(\n        self, events: List[IntegrationEvent]\n    ) -> List[IntegrationResult]:\n        \"\"\"Send events batch with retry logic\"\"\"\n        return await self._do_send_events_batch(events)\n\n    async def _do_send_events_batch(\n        self,\n        events: List[IntegrationEvent],\n    ) -> List[IntegrationResult]:\n        \"\"\"\n        Perform the actual batch event delivery.\n\n        This is the core method that subclasses override to implement adapter-specific\n        batch delivery logic when the external service supports batch operations.\n        This method is called by send_events_batch() after authentication checks and\n        is wrapped with automatic retry logic.\n\n        If not overridden, the base implementation will automatically fall back to\n        sending events one-by-one using _do_send_event(), allowing all adapters to\n        support batch operations transparently without additional implementation.\n\n        Implementation Contract:\n            - Called ONLY by send_events_batch() after authentication is verified\n            - Wrapped with automatic retry logic (3 attempts, exponential backoff)\n            - Should NOT handle authentication (handled by send_events_batch)\n            - Should NOT track metrics (handled by send_events_batch)\n            - MUST return one IntegrationResult per input event in same order\n            - MUST preserve event ordering in results for correlation\n\n        When to Override:\n            Override this method if:\n            - The external service has a dedicated batch API endpoint\n            - Batch operations are significantly more efficient than individual calls\n            - The service supports sending multiple events in a single HTTP request\n            - You want to implement custom batch size limits or chunking\n\n            Do NOT override if:\n            - The service only supports individual event submission\n            - The default one-by-one fallback is acceptable for your use case\n            - Examples: Jira, ServiceNow (no native batch APIs)\n\n        Error Handling:\n            Subclass implementations should raise:\n            - RateLimitError: When rate limited (include retry_after if available)\n            - DeliveryError: For general delivery failures (will trigger retry)\n            - AuthenticationError: If token/credentials become invalid mid-request\n            - IntegrationConnectionError: For network/connectivity issues\n\n            Do NOT catch and suppress exceptions - let them propagate for retry logic.\n            The send_events_batch() method handles retry orchestration and metrics.\n\n        Batch Size Considerations:\n            - Respect service-specific limits (e.g., Splunk HEC, Sentinel 1MB/500 records)\n            - Consider implementing chunking for large batches\n            - Document recommended batch sizes in adapter-specific docstrings\n            - Return appropriate errors if batch size exceeds service limits\n\n        Args:\n            events: List of governance events to send. Guaranteed to be non-empty\n                   (empty lists handled by send_events_batch). Events must be\n                   processed in the order provided.\n\n        Returns:\n            List of IntegrationResults for each event, in the same order as input.\n            Each result indicates success or failure for the corresponding event.\n            - For all-or-nothing semantics: All results have same success status\n            - For partial success: Mixed success/failure results allowed\n            - Empty input returns empty list (but should not occur in practice)\n\n        Raises:\n            RateLimitError: Service rate limit exceeded. Set retry_after attribute\n                          to indicate when to retry (seconds from now).\n            DeliveryError: Batch delivery failed. Will trigger retry logic.\n            AuthenticationError: Authentication token expired or invalid.\n            IntegrationConnectionError: Network or connectivity issues.\n\n        Implementation Examples:\n\n            All-or-nothing batch (Splunk/Sentinel pattern):\n            ```python\n            async def _do_send_events_batch(\n                self,\n                events: List[IntegrationEvent]\n            ) -> List[IntegrationResult]:\n                '''Send events using service's batch API (all-or-nothing).'''\n                if not events:\n                    return []\n\n                # Format events for service's batch API\n                batch_payload = self._format_batch_payload(events)\n\n                # Send batch request\n                client = await self.get_http_client()\n                response = await client.post(\n                    \"/api/batch\",\n                    json=batch_payload,\n                    headers={\"Authorization\": f\"Bearer {self.token}\"}\n                )\n\n                # Handle rate limiting\n                if response.status_code == 429:\n                    retry_after = int(response.headers.get(\"Retry-After\", 60))\n                    raise RateLimitError(\n                        \"Batch rate limited\",\n                        self.name,\n                        retry_after=retry_after\n                    )\n\n                # All-or-nothing semantics\n                if response.status_code == 200:\n                    # All events succeeded\n                    return [\n                        IntegrationResult(\n                            success=True,\n                            integration_name=self.name,\n                            operation=\"send_event\",\n                            external_id=event.event_id,\n                        )\n                        for event in events\n                    ]\n                else:\n                    # All events failed\n                    error_msg = response.text or f\"HTTP {response.status_code}\"\n                    return [\n                        IntegrationResult(\n                            success=False,\n                            integration_name=self.name,\n                            operation=\"send_event\",\n                            error_code=\"BATCH_FAILED\",\n                            error_message=error_msg,\n                        )\n                        for _ in events\n                    ]\n            ```\n\n            Partial success batch (custom pattern):\n            ```python\n            async def _do_send_events_batch(\n                self,\n                events: List[IntegrationEvent]\n            ) -> List[IntegrationResult]:\n                '''Send events with per-event success/failure tracking.'''\n                if not events:\n                    return []\n\n                # Format events for service's batch API\n                batch_payload = [self._format_event(e) for e in events]\n\n                # Send batch request\n                client = await self.get_http_client()\n                response = await client.post(\"/api/batch\", json=batch_payload)\n\n                if response.status_code != 200:\n                    # Entire batch failed\n                    raise DeliveryError(\n                        f\"Batch request failed: {response.text}\",\n                        self.name\n                    )\n\n                # Parse per-event results from response\n                results = []\n                response_data = response.json()\n                for idx, event in enumerate(events):\n                    event_result = response_data[\"results\"][idx]\n                    if event_result[\"status\"] == \"success\":\n                        results.append(IntegrationResult(\n                            success=True,\n                            integration_name=self.name,\n                            operation=\"send_event\",\n                            external_id=event_result[\"id\"],\n                        ))\n                    else:\n                        results.append(IntegrationResult(\n                            success=False,\n                            integration_name=self.name,\n                            operation=\"send_event\",\n                            error_code=event_result[\"error_code\"],\n                            error_message=event_result[\"error_message\"],\n                        ))\n\n                return results\n            ```\n\n            Chunking large batches:\n            ```python\n            async def _do_send_events_batch(\n                self,\n                events: List[IntegrationEvent]\n            ) -> List[IntegrationResult]:\n                '''Send events in chunks to respect service limits.'''\n                MAX_BATCH_SIZE = 100  # Service limit\n\n                if len(events) <= MAX_BATCH_SIZE:\n                    # Single batch\n                    return await self._send_single_batch(events)\n\n                # Chunk and send multiple batches\n                results = []\n                for i in range(0, len(events), MAX_BATCH_SIZE):\n                    chunk = events[i:i + MAX_BATCH_SIZE]\n                    chunk_results = await self._send_single_batch(chunk)\n                    results.extend(chunk_results)\n\n                return results\n            ```\n\n        Default Fallback Implementation:\n            If not overridden, sends events one-by-one using _do_send_event():\n            - Processes events sequentially in order\n            - Each event gets individual IntegrationResult\n            - Exceptions caught and converted to failure results\n            - Allows partial success (some events succeed, others fail)\n            - Suitable for adapters without batch APIs (Jira, ServiceNow)\n\n        See Also:\n            - send_events_batch(): Public API with auth checks and metrics\n            - _send_events_batch_with_retry(): Retry wrapper for this method\n            - Splunk adapter: Reference implementation with all-or-nothing semantics\n            - Sentinel adapter: Reference implementation with Azure DCR API\n        \"\"\"\n        # Default implementation: send events one-by-one\n        # Subclasses can override this for more efficient batch operations\n        logger.debug(\n            f\"Using default batch implementation for '{self.name}' - sending events one-by-one\"\n        )\n\n        results = []\n        for event in events:\n            try:\n                result = await self._do_send_event(event)\n                results.append(result)\n            except Exception as e:\n                # Create a failure result for this event\n                results.append(\n                    IntegrationResult(\n                        success=False,\n                        integration_name=self.name,\n                        operation=\"send_event\",\n                        error_code=\"SEND_FAILED\",\n                        error_message=str(e),\n                    )\n                )\n\n        return results\n\n    async def test_connection(self) -> IntegrationResult:\n        \"\"\"\n        Test the connection to the external service without fully authenticating.\n\n        Returns:\n            IntegrationResult indicating if the service is reachable\n        \"\"\"\n        logger.info(f\"Testing connection for integration '{self.name}'\")\n\n        try:\n            result = await self._do_test_connection()\n            return result\n        except Exception as e:\n            logger.error(f\"Connection test failed for '{self.name}': {str(e)}\")\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=\"CONNECTION_ERROR\",\n                error_message=str(e),\n            )\n\n    async def _do_test_connection(self) -> IntegrationResult:\n        \"\"\"\n        Test connection implementation.\n\n        Default implementation uses the base_url from credentials.\n        Subclasses can override for custom connection testing.\n        \"\"\"\n        if not self.credentials.base_url:\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=\"NO_BASE_URL\",\n                error_message=\"No base URL configured\",\n            )\n\n        try:\n            client = await self.get_http_client()\n            response = await client.head(self.credentials.base_url)\n\n            return IntegrationResult(\n                success=response.status_code < 500,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=None if response.status_code < 500 else f\"HTTP_{response.status_code}\",\n                error_message=(\n                    None\n                    if response.status_code < 500\n                    else f\"Server returned status {response.status_code}\"\n                ),\n            )\n        except httpx.TimeoutException:\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=\"TIMEOUT\",\n                error_message=f\"Connection timed out after {self.timeout}s\",\n            )\n        except httpx.NetworkError as e:\n            return IntegrationResult(\n                success=False,\n                integration_name=self.name,\n                operation=\"test_connection\",\n                error_code=\"NETWORK_ERROR\",\n                error_message=str(e),\n            )\n\n    def _redact_sensitive_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Redact sensitive data from a dictionary for logging.\n\n        Args:\n            data: Dictionary that may contain sensitive values\n\n        Returns:\n            Copy of the dictionary with sensitive values redacted\n        \"\"\"\n        sensitive_keys = {\n            \"password\",\n            \"token\",\n            \"secret\",\n            \"api_key\",\n            \"api_token\",\n            \"access_token\",\n            \"refresh_token\",\n            \"client_secret\",\n            \"hec_token\",\n            \"bearer\",\n            \"authorization\",\n        }\n\n        def redact_value(key: str, value: Any) -> Any:\n            if isinstance(value, dict):\n                return {k: redact_value(k, v) for k, v in value.items()}\n            elif isinstance(value, list):\n                return [redact_value(key, item) for item in value]\n            elif any(sensitive in key.lower() for sensitive in sensitive_keys):\n                return \"***REDACTED***\"\n            return value\n\n        return {k: redact_value(k, v) for k, v in data.items()}\n\n    def __repr__(self) -> str:\n        return (\n            f\"<{self.__class__.__name__}(name={self.name}, \"\n            f\"type={self.integration_type.value}, status={self.status.value})>\"\n        )\n",
        "timestamp": "2026-01-04T00:39:57.715547"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "037-add-batch-event-processing-to-baseintegration",
        "description": "Extend BaseIntegration with send_events_batch() method to efficiently send multiple events in a single API call where supported. Reduces API calls and improves throughput for high-volume governance event scenarios.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.225588",
  "last_updated": "2026-01-04T05:35:58.730435"
}