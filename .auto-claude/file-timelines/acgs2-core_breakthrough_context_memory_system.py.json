{
  "file_path": "src/core/breakthrough/context/memory_system.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nConstitutional Memory System\n============================\n\nConstitutional Hash: cdd01ef066bc6cf2\n\nImplements persistent memory for governance decisions enabling\nmulti-day autonomous agent sessions with:\n- Episodic memory (past decisions as precedents)\n- Semantic memory (constitutional principles)\n- Working memory (current context)\n\nReferences:\n- Memory in the Age of AI Agents (arXiv:2512.13564)\n- MongoDB LangGraph Store patterns\n\"\"\"\n\nimport hashlib\nimport json\nimport logging\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom enum import Enum\nfrom typing import Dict, List, Optional, Tuple\n\nfrom ...shared.types import (\n    AuditTrail,\n    ContextData,\n    JSONDict,\n    JSONValue,\n    MetadataDict,\n)\nfrom .. import CONSTITUTIONAL_HASH\n\nlogger = logging.getLogger(__name__)\n\n\nclass MemoryType(Enum):\n    \"\"\"Types of memory in the system.\"\"\"\n    EPISODIC = \"episodic\"  # Past decisions/events\n    SEMANTIC = \"semantic\"  # Principles/knowledge\n    WORKING = \"working\"    # Current context\n\n\n@dataclass\nclass MemoryEntry:\n    \"\"\"A single memory entry.\"\"\"\n    id: str\n    content: JSONValue\n    memory_type: MemoryType\n    timestamp: datetime\n    importance: float\n    embedding: Optional[List[float]] = None\n    metadata: MetadataDict = field(default_factory=dict)\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n\n    def to_dict(self) -> JSONDict:\n        return {\n            \"id\": self.id,\n            \"content\": self.content,\n            \"memory_type\": self.memory_type.value,\n            \"timestamp\": self.timestamp.isoformat(),\n            \"importance\": self.importance,\n            \"metadata\": self.metadata,\n            \"constitutional_hash\": self.constitutional_hash,\n        }\n\n\n@dataclass\nclass Precedent:\n    \"\"\"A governance precedent from episodic memory.\"\"\"\n    case_id: str\n    description: str\n    decision: str\n    outcome: str\n    timestamp: datetime\n    relevance_score: float\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n\n    def to_dict(self) -> JSONDict:\n        return {\n            \"case_id\": self.case_id,\n            \"description\": self.description,\n            \"decision\": self.decision,\n            \"outcome\": self.outcome,\n            \"timestamp\": self.timestamp.isoformat(),\n            \"relevance_score\": self.relevance_score,\n            \"constitutional_hash\": self.constitutional_hash,\n        }\n\n\n@dataclass\nclass GovernanceCase:\n    \"\"\"A current governance case to evaluate.\"\"\"\n    case_id: str\n    description: str\n    context: ContextData\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    embedding: Optional[List[float]] = None\n\n    def to_dict(self) -> JSONDict:\n        return {\n            \"case_id\": self.case_id,\n            \"description\": self.description,\n            \"context\": self.context,\n            \"timestamp\": self.timestamp.isoformat(),\n        }\n\n\n@dataclass\nclass GovernanceDecision:\n    \"\"\"A governance decision to be stored.\"\"\"\n    decision_id: str\n    case: GovernanceCase\n    decision: str\n    rationale: str\n    confidence: float\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    precedents_used: List[str] = field(default_factory=list)\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n\n    def to_dict(self) -> JSONDict:\n        return {\n            \"decision_id\": self.decision_id,\n            \"case\": self.case.to_dict(),\n            \"decision\": self.decision,\n            \"rationale\": self.rationale,\n            \"confidence\": self.confidence,\n            \"timestamp\": self.timestamp.isoformat(),\n            \"precedents_used\": self.precedents_used,\n            \"constitutional_hash\": self.constitutional_hash,\n        }\n\n\nclass EpisodicMemory:\n    \"\"\"\n    Episodic Memory for past governance decisions.\n\n    Stores decisions as precedents that can be retrieved\n    for similar future cases using semantic search.\n    \"\"\"\n\n    def __init__(self, max_entries: int = 10000):\n        self.max_entries = max_entries\n        self._entries: Dict[str, MemoryEntry] = {}\n        self._embeddings_index: Dict[str, List[float]] = {}\n\n        logger.info(f\"Initialized EpisodicMemory with max_entries={max_entries}\")\n\n    async def store(self, decision: GovernanceDecision) -> str:\n        \"\"\"Store a governance decision as episodic memory.\"\"\"\n        entry_id = decision.decision_id\n\n        # Create embedding from decision content\n        embedding = await self._create_embedding(decision)\n\n        entry = MemoryEntry(\n            id=entry_id,\n            content=decision.to_dict(),\n            memory_type=MemoryType.EPISODIC,\n            timestamp=decision.timestamp,\n            importance=decision.confidence,\n            embedding=embedding,\n            metadata={\n                \"case_id\": decision.case.case_id,\n                \"decision_type\": \"governance\",\n            }\n        )\n\n        # Evict if at capacity\n        if len(self._entries) >= self.max_entries:\n            await self._evict_least_important()\n\n        self._entries[entry_id] = entry\n        if embedding:\n            self._embeddings_index[entry_id] = embedding\n\n        logger.debug(f\"Stored episodic memory: {entry_id}\")\n        return entry_id\n\n    async def search(\n        self,\n        query_embedding: List[float],\n        top_k: int = 10,\n        filter_criteria: Optional[MetadataDict] = None\n    ) -> List[MemoryEntry]:\n        \"\"\"\n        Search episodic memory by similarity.\n\n        Args:\n            query_embedding: Query vector\n            top_k: Number of results to return\n            filter_criteria: Optional filters (e.g., constitutional_hash)\n\n        Returns:\n            List of matching memory entries\n        \"\"\"\n        if not self._embeddings_index:\n            return []\n\n        # Compute similarities\n        similarities = []\n        for entry_id, embedding in self._embeddings_index.items():\n            sim = self._cosine_similarity(query_embedding, embedding)\n            entry = self._entries[entry_id]\n\n            # Apply filters\n            if filter_criteria:\n                if not self._matches_filter(entry, filter_criteria):\n                    continue\n\n            similarities.append((entry_id, sim))\n\n        # Sort by similarity\n        similarities.sort(key=lambda x: x[1], reverse=True)\n\n        # Return top-k entries\n        results = []\n        for entry_id, sim in similarities[:top_k]:\n            entry = self._entries[entry_id]\n            entry.metadata[\"similarity_score\"] = sim\n            results.append(entry)\n\n        return results\n\n    async def _create_embedding(self, decision: GovernanceDecision) -> List[float]:\n        \"\"\"Create embedding from decision content.\"\"\"\n        # In production, this would use a proper embedding model\n        # For now, create a simple hash-based pseudo-embedding\n        content = json.dumps(decision.to_dict(), sort_keys=True)\n        hash_bytes = hashlib.sha256(content.encode()).digest()\n        # Convert to float vector\n        return [b / 255.0 for b in hash_bytes[:128]]\n\n    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:\n        \"\"\"Compute cosine similarity between two vectors.\"\"\"\n        if len(a) != len(b):\n            return 0.0\n        dot_product = sum(x * y for x, y in zip(a, b, strict=True))\n        norm_a = sum(x * x for x in a) ** 0.5\n        norm_b = sum(x * x for x in b) ** 0.5\n        if norm_a == 0 or norm_b == 0:\n            return 0.0\n        return dot_product / (norm_a * norm_b)\n\n    def _matches_filter(\n        self,\n        entry: MemoryEntry,\n        filter_criteria: MetadataDict\n    ) -> bool:\n        \"\"\"Check if entry matches filter criteria.\"\"\"\n        for key, value in filter_criteria.items():\n            if key == \"constitutional_hash\":\n                if entry.constitutional_hash != value:\n                    return False\n            elif key in entry.metadata:\n                if entry.metadata[key] != value:\n                    return False\n        return True\n\n    async def _evict_least_important(self) -> None:\n        \"\"\"Evict least important entry to make room.\"\"\"\n        if not self._entries:\n            return\n\n        # Find entry with lowest importance\n        min_entry_id = min(\n            self._entries.keys(),\n            key=lambda k: self._entries[k].importance\n        )\n\n        del self._entries[min_entry_id]\n        if min_entry_id in self._embeddings_index:\n            del self._embeddings_index[min_entry_id]\n\n        logger.debug(f\"Evicted episodic memory: {min_entry_id}\")\n\n\nclass SemanticMemory:\n    \"\"\"\n    Semantic Memory for constitutional principles and knowledge.\n\n    Stores long-term factual knowledge that doesn't change\n    with individual decisions.\n    \"\"\"\n\n    def __init__(self):\n        self._principles: Dict[str, MemoryEntry] = {}\n        self._knowledge: Dict[str, MemoryEntry] = {}\n\n        logger.info(\"Initialized SemanticMemory\")\n\n    async def store_principle(\n        self,\n        principle_id: str,\n        content: str,\n        importance: float = 1.0,\n        metadata: Optional[MetadataDict] = None\n    ) -> str:\n        \"\"\"Store a constitutional principle.\"\"\"\n        entry = MemoryEntry(\n            id=principle_id,\n            content=content,\n            memory_type=MemoryType.SEMANTIC,\n            timestamp=datetime.utcnow(),\n            importance=importance,\n            metadata=metadata or {}\n        )\n\n        self._principles[principle_id] = entry\n        logger.debug(f\"Stored principle: {principle_id}\")\n        return principle_id\n\n    async def get_principle(self, principle_id: str) -> Optional[MemoryEntry]:\n        \"\"\"Retrieve a constitutional principle.\"\"\"\n        return self._principles.get(principle_id)\n\n    async def get_all_principles(self) -> List[MemoryEntry]:\n        \"\"\"Get all constitutional principles.\"\"\"\n        return list(self._principles.values())\n\n    async def store_knowledge(\n        self,\n        knowledge_id: str,\n        content: JSONValue,\n        category: str,\n        importance: float = 0.5\n    ) -> str:\n        \"\"\"Store general knowledge.\"\"\"\n        entry = MemoryEntry(\n            id=knowledge_id,\n            content=content,\n            memory_type=MemoryType.SEMANTIC,\n            timestamp=datetime.utcnow(),\n            importance=importance,\n            metadata={\"category\": category}\n        )\n\n        self._knowledge[knowledge_id] = entry\n        return knowledge_id\n\n    async def search_knowledge(\n        self,\n        query: str,\n        category: Optional[str] = None\n    ) -> List[MemoryEntry]:\n        \"\"\"Search knowledge base.\"\"\"\n        results = []\n        for entry in self._knowledge.values():\n            if category and entry.metadata.get(\"category\") != category:\n                continue\n            # Simple text matching (would use semantic search in production)\n            if query.lower() in str(entry.content).lower():\n                results.append(entry)\n        return results\n\n\nclass WorkingMemory:\n    \"\"\"\n    Working Memory for current context.\n\n    Short-term memory that holds active context during\n    governance processing. Uses TTL for automatic cleanup.\n    \"\"\"\n\n    def __init__(self, default_ttl_seconds: int = 3600):\n        self.default_ttl = timedelta(seconds=default_ttl_seconds)\n        self._entries: Dict[str, Tuple[MemoryEntry, datetime]] = {}  # entry, expiry\n\n        logger.info(f\"Initialized WorkingMemory with TTL={default_ttl_seconds}s\")\n\n    async def store(\n        self,\n        key: str,\n        content: JSONValue,\n        ttl_seconds: Optional[int] = None\n    ) -> str:\n        \"\"\"Store content in working memory with TTL.\"\"\"\n        ttl = timedelta(seconds=ttl_seconds) if ttl_seconds else self.default_ttl\n        expiry = datetime.utcnow() + ttl\n\n        entry = MemoryEntry(\n            id=key,\n            content=content,\n            memory_type=MemoryType.WORKING,\n            timestamp=datetime.utcnow(),\n            importance=0.5,\n        )\n\n        self._entries[key] = (entry, expiry)\n        return key\n\n    async def get(self, key: str) -> Optional[JSONValue]:\n        \"\"\"Get content from working memory.\"\"\"\n        await self._cleanup_expired()\n\n        if key not in self._entries:\n            return None\n\n        entry, expiry = self._entries[key]\n        if datetime.utcnow() > expiry:\n            del self._entries[key]\n            return None\n\n        return entry.content\n\n    async def delete(self, key: str) -> bool:\n        \"\"\"Delete entry from working memory.\"\"\"\n        if key in self._entries:\n            del self._entries[key]\n            return True\n        return False\n\n    async def clear(self) -> None:\n        \"\"\"Clear all working memory.\"\"\"\n        self._entries.clear()\n\n    async def _cleanup_expired(self) -> None:\n        \"\"\"Remove expired entries.\"\"\"\n        now = datetime.utcnow()\n        expired = [\n            key for key, (_, expiry) in self._entries.items()\n            if now > expiry\n        ]\n        for key in expired:\n            del self._entries[key]\n\n\nclass ConstitutionalMemorySystem:\n    \"\"\"\n    Unified Constitutional Memory System.\n\n    Integrates episodic, semantic, and working memory to enable\n    multi-day autonomous governance with precedent retrieval.\n    \"\"\"\n\n    def __init__(\n        self,\n        episodic_max_entries: int = 10000,\n        working_ttl_seconds: int = 3600\n    ):\n        \"\"\"\n        Initialize the Constitutional Memory System.\n\n        Args:\n            episodic_max_entries: Max precedents to store\n            working_ttl_seconds: Working memory TTL\n        \"\"\"\n        self.episodic = EpisodicMemory(max_entries=episodic_max_entries)\n        self.semantic = SemanticMemory()\n        self.working = WorkingMemory(default_ttl_seconds=working_ttl_seconds)\n\n        self._audit_log: AuditTrail = []\n        self._stats = {\n            \"precedents_retrieved\": 0,\n            \"decisions_stored\": 0,\n            \"cache_hits\": 0,\n        }\n\n        logger.info(\"Initialized ConstitutionalMemorySystem\")\n\n    async def recall_relevant_precedents(\n        self,\n        current_case: GovernanceCase,\n        top_k: int = 10\n    ) -> List[Precedent]:\n        \"\"\"\n        Retrieve relevant past governance decisions.\n\n        Args:\n            current_case: The current case to find precedents for\n            top_k: Number of precedents to retrieve\n\n        Returns:\n            List of relevant precedents\n        \"\"\"\n        # Create embedding from current case\n        if current_case.embedding:\n            query_embedding = current_case.embedding\n        else:\n            query_embedding = await self._create_case_embedding(current_case)\n\n        # Search episodic memory\n        similar_entries = await self.episodic.search(\n            query_embedding=query_embedding,\n            top_k=top_k,\n            filter_criteria={\"constitutional_hash\": CONSTITUTIONAL_HASH}\n        )\n\n        # Convert to precedents\n        precedents = []\n        for entry in similar_entries:\n            content = entry.content\n            precedent = Precedent(\n                case_id=content.get(\"case\", {}).get(\"case_id\", entry.id),\n                description=content.get(\"case\", {}).get(\"description\", \"\"),\n                decision=content.get(\"decision\", \"\"),\n                outcome=content.get(\"rationale\", \"\"),\n                timestamp=entry.timestamp,\n                relevance_score=entry.metadata.get(\"similarity_score\", 0.0),\n            )\n            precedents.append(precedent)\n\n        # Rank by relevance and recency\n        precedents = self._rank_precedents(precedents, current_case)\n\n        self._stats[\"precedents_retrieved\"] += len(precedents)\n        return precedents\n\n    async def commit_decision(self, decision: GovernanceDecision) -> str:\n        \"\"\"\n        Store a governance decision for future reference.\n\n        Args:\n            decision: The decision to store\n\n        Returns:\n            The decision ID\n        \"\"\"\n        # Store in episodic memory\n        entry_id = await self.episodic.store(decision)\n\n        # Record in audit log\n        await self._record_audit(decision)\n\n        self._stats[\"decisions_stored\"] += 1\n        logger.info(f\"Committed decision: {decision.decision_id}\")\n\n        return entry_id\n\n    async def get_constitutional_principles(self) -> List[MemoryEntry]:\n        \"\"\"Get all stored constitutional principles.\"\"\"\n        return await self.semantic.get_all_principles()\n\n    async def store_context(\n        self,\n        key: str,\n        content: JSONValue,\n        ttl_seconds: Optional[int] = None\n    ) -> str:\n        \"\"\"Store context in working memory.\"\"\"\n        return await self.working.store(key, content, ttl_seconds)\n\n    async def get_context(self, key: str) -> Optional[JSONValue]:\n        \"\"\"Retrieve context from working memory.\"\"\"\n        return await self.working.get(key)\n\n    def _rank_precedents(\n        self,\n        precedents: List[Precedent],\n        current_case: GovernanceCase\n    ) -> List[Precedent]:\n        \"\"\"\n        Rank precedents by relevance and recency.\n\n        Combined scoring: 0.7 * relevance + 0.3 * recency\n        \"\"\"\n        now = datetime.utcnow()\n        max_age_days = 365  # 1 year\n\n        for precedent in precedents:\n            # Recency score (1.0 for today, 0.0 for 1 year ago)\n            age = (now - precedent.timestamp).days\n            recency_score = max(0.0, 1.0 - (age / max_age_days))\n\n            # Combined score\n            combined_score = 0.7 * precedent.relevance_score + 0.3 * recency_score\n            precedent.relevance_score = combined_score\n\n        # Sort by combined score\n        precedents.sort(key=lambda p: p.relevance_score, reverse=True)\n        return precedents\n\n    async def _create_case_embedding(\n        self,\n        case: GovernanceCase\n    ) -> List[float]:\n        \"\"\"Create embedding from governance case.\"\"\"\n        content = json.dumps(case.to_dict(), sort_keys=True)\n        hash_bytes = hashlib.sha256(content.encode()).digest()\n        return [b / 255.0 for b in hash_bytes[:128]]\n\n    async def _record_audit(self, decision: GovernanceDecision) -> None:\n        \"\"\"Record decision in audit log.\"\"\"\n        self._audit_log.append({\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"decision_id\": decision.decision_id,\n            \"case_id\": decision.case.case_id,\n            \"constitutional_hash\": decision.constitutional_hash,\n        })\n\n    def get_stats(self) -> JSONDict:\n        \"\"\"Get memory system statistics.\"\"\"\n        return {\n            **self._stats,\n            \"episodic_entries\": len(self.episodic._entries),\n            \"semantic_principles\": len(self.semantic._principles),\n            \"working_entries\": len(self.working._entries),\n            \"audit_log_size\": len(self._audit_log),\n            \"constitutional_hash\": CONSTITUTIONAL_HASH,\n        }\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), src/core/breakthrough (79 occurrences), and src/core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.278359",
  "last_updated": "2026-01-04T05:35:58.463688"
}