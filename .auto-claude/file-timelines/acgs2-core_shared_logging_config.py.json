{
  "file_path": "acgs2-core/shared/logging_config.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nACGS-2 Structured Logging Configuration\nConstitutional Hash: cdd01ef066bc6cf2\n\nEnterprise-grade structured logging with JSON formatting, correlation ID support,\nand OpenTelemetry integration for distributed tracing.\n\nThis module provides:\n    - JSON-formatted log output for enterprise observability (Splunk, ELK, Datadog)\n    - Correlation ID binding via contextvars (async-safe)\n    - OpenTelemetry trace ID integration\n    - RFC 5424 severity levels (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n    - Performance optimization with orjson serialization\n\nUsage:\n    from shared.logging_config import configure_logging, get_logger\n\n    # Initialize at application startup (ONCE, before any logging)\n    configure_logging(service_name=\"api_gateway\")\n\n    # Get a logger instance\n    logger = get_logger(__name__)\n    logger.info(\"user_authenticated\", user_id=user.id, method=\"oauth2\")\n\nExample with FastAPI:\n    app = FastAPI()\n    configure_logging(service_name=\"api_gateway\")\n    logger = get_logger(__name__)\n\n    @app.get(\"/\")\n    async def root():\n        logger.info(\"request_received\", endpoint=\"/\")\n        return {\"status\": \"ok\"}\n\"\"\"\n\nimport logging\nimport os\nimport sys\nfrom contextvars import ContextVar\nfrom typing import Any, Dict, Optional\n\n# Try to import structlog - fall back to stdlib logging if unavailable\ntry:\n    import structlog\n    from structlog.contextvars import bind_contextvars, clear_contextvars, merge_contextvars\n\n    HAS_STRUCTLOG = True\nexcept ImportError:\n    HAS_STRUCTLOG = False\n    structlog = None  # type: ignore[assignment]\n\n# Try to import orjson for high-performance JSON serialization\ntry:\n    import orjson\n\n    def orjson_dumps(obj: Any, **kwargs: Any) -> str:\n        \"\"\"High-performance JSON serialization using orjson.\"\"\"\n        return orjson.dumps(obj, default=str).decode(\"utf-8\")\n\n    HAS_ORJSON = True\nexcept ImportError:\n    HAS_ORJSON = False\n    orjson_dumps = None  # type: ignore[assignment]\n\n# Try to import OpenTelemetry for distributed tracing\ntry:\n    from opentelemetry import trace\n    from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor\n    from opentelemetry.sdk.resources import Resource\n    from opentelemetry.sdk.trace import TracerProvider\n\n    HAS_OPENTELEMETRY = True\nexcept ImportError:\n    HAS_OPENTELEMETRY = False\n    trace = None  # type: ignore[assignment]\n    TracerProvider = None  # type: ignore[assignment]\n    Resource = None  # type: ignore[assignment]\n    FastAPIInstrumentor = None  # type: ignore[assignment]\n\n\n# Module-level state\n_configured: bool = False\n_service_name: str = \"acgs2\"\n\n# Context variable for correlation ID (async-safe)\ncorrelation_id_var: ContextVar[Optional[str]] = ContextVar(\"correlation_id\", default=None)\n\n\ndef configure_logging(\n    service_name: str = \"acgs2\",\n    log_level: Optional[str] = None,\n    json_format: bool = True,\n    use_orjson: bool = True,\n) -> None:\n    \"\"\"\n    Initialize structlog with JSON output and correlation ID support.\n\n    This function MUST be called ONCE at application startup, BEFORE any logger usage.\n    Subsequent calls will be ignored to prevent reconfiguration.\n\n    Args:\n        service_name: Service identifier for log filtering (e.g., \"api_gateway\")\n        log_level: Log level override. If None, reads from LOG_LEVEL env var (default: INFO)\n        json_format: Whether to output JSON (True) or human-readable format (False)\n        use_orjson: Whether to use orjson for JSON serialization (recommended for production)\n\n    Environment Variables:\n        LOG_LEVEL: Controls log verbosity (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n        LOG_FORMAT: Set to \"console\" for human-readable output (default: \"json\")\n\n    Example:\n        # In FastAPI startup\n        @app.on_event(\"startup\")\n        async def startup():\n            configure_logging(service_name=\"api_gateway\")\n    \"\"\"\n    global _configured, _service_name\n\n    if _configured:\n        return\n\n    _service_name = service_name\n\n    # Determine log level from parameter or environment\n    if log_level is None:\n        log_level = os.getenv(\"LOG_LEVEL\", \"INFO\").upper()\n\n    # Check environment for format preference\n    env_format = os.getenv(\"LOG_FORMAT\", \"json\").lower()\n    if env_format == \"console\":\n        json_format = False\n\n    # Map string level to logging constant\n    numeric_level = getattr(logging, log_level, logging.INFO)\n\n    if HAS_STRUCTLOG:\n        _configure_structlog(\n            service_name=service_name,\n            numeric_level=numeric_level,\n            json_format=json_format,\n            use_orjson=use_orjson and HAS_ORJSON,\n        )\n    else:\n        _configure_stdlib_logging(\n            service_name=service_name,\n            numeric_level=numeric_level,\n            json_format=json_format,\n        )\n\n    _configured = True\n\n\ndef _configure_structlog(\n    service_name: str,\n    numeric_level: int,\n    json_format: bool,\n    use_orjson: bool,\n) -> None:\n    \"\"\"Configure structlog with JSON output and correlation ID support.\"\"\"\n    # Build processor chain\n    # CRITICAL: merge_contextvars MUST be first to enable correlation ID binding\n    processors = [\n        merge_contextvars,  # Enables async-safe correlation ID injection\n        structlog.processors.add_log_level,\n        structlog.processors.TimeStamper(fmt=\"iso\", utc=True),\n        _add_service_name,  # Custom processor to add service identifier\n        structlog.processors.StackInfoRenderer(),\n        structlog.processors.format_exc_info,\n    ]\n\n    if json_format:\n        # Use orjson for production performance if available\n        if use_orjson and HAS_ORJSON:\n            processors.append(structlog.processors.JSONRenderer(serializer=orjson_dumps))\n        else:\n            processors.append(structlog.processors.JSONRenderer())\n    else:\n        # Human-readable console output for local development\n        processors.append(structlog.dev.ConsoleRenderer(colors=True))\n\n    structlog.configure(\n        processors=processors,\n        wrapper_class=structlog.make_filtering_bound_logger(numeric_level),\n        context_class=dict,\n        logger_factory=structlog.PrintLoggerFactory(),\n        cache_logger_on_first_use=True,  # Performance optimization\n    )\n\n\ndef _configure_stdlib_logging(\n    service_name: str,\n    numeric_level: int,\n    json_format: bool,\n) -> None:\n    \"\"\"Fallback configuration using stdlib logging when structlog is unavailable.\"\"\"\n    import json\n\n    class JSONFormatter(logging.Formatter):\n        \"\"\"JSON formatter for stdlib logging.\"\"\"\n\n        def format(self, record: logging.LogRecord) -> str:\n            log_entry = {\n                \"timestamp\": self.formatTime(record, datefmt=\"%Y-%m-%dT%H:%M:%S.%fZ\"),\n                \"level\": record.levelname,\n                \"logger\": record.name,\n                \"message\": record.getMessage(),\n                \"service\": service_name,\n            }\n\n            # Add correlation ID if available\n            corr_id = correlation_id_var.get()\n            if corr_id:\n                log_entry[\"correlation_id\"] = corr_id\n\n            # Add exception info if present\n            if record.exc_info:\n                log_entry[\"exception\"] = self.formatException(record.exc_info)\n\n            return json.dumps(log_entry, default=str)\n\n    # Configure root logger\n    root_logger = logging.getLogger()\n    root_logger.setLevel(numeric_level)\n\n    # Remove existing handlers to avoid duplicates\n    for handler in root_logger.handlers[:]:\n        root_logger.removeHandler(handler)\n\n    # Create console handler\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setLevel(numeric_level)\n\n    if json_format:\n        handler.setFormatter(JSONFormatter())\n    else:\n        handler.setFormatter(\n            logging.Formatter(\n                f\"%(asctime)s - {service_name} - %(name)s - %(levelname)s - %(message)s\"\n            )\n        )\n\n    root_logger.addHandler(handler)\n\n\ndef _add_service_name(\n    logger: Any,\n    method_name: str,\n    event_dict: Dict[str, Any],\n) -> Dict[str, Any]:\n    \"\"\"Structlog processor to add service name to all log entries.\"\"\"\n    event_dict[\"service\"] = _service_name\n    return event_dict\n\n\ndef get_logger(name: str) -> Any:\n    \"\"\"\n    Get a logger instance for the given module name.\n\n    Args:\n        name: Logger name (typically __name__)\n\n    Returns:\n        Configured logger instance (structlog or stdlib)\n\n    Example:\n        logger = get_logger(__name__)\n        logger.info(\"operation_completed\", duration_ms=150)\n    \"\"\"\n    if HAS_STRUCTLOG:\n        return structlog.get_logger(name)\n    else:\n        return logging.getLogger(name)\n\n\ndef bind_correlation_id(correlation_id: str, trace_id: Optional[str] = None) -> None:\n    \"\"\"\n    Bind correlation ID to the current async context.\n\n    This function should be called in request middleware to associate\n    all subsequent logs with the request's correlation ID.\n\n    Args:\n        correlation_id: Unique request identifier (from X-Request-ID header or generated UUID)\n        trace_id: Optional OpenTelemetry trace ID for distributed tracing correlation\n\n    Example:\n        @app.middleware(\"http\")\n        async def correlation_id_middleware(request, call_next):\n            correlation_id = request.headers.get(\"X-Request-ID\") or str(uuid.uuid4())\n            bind_correlation_id(correlation_id)\n            response = await call_next(request)\n            return response\n    \"\"\"\n    if HAS_STRUCTLOG:\n        context = {\"correlation_id\": correlation_id}\n        if trace_id:\n            context[\"trace_id\"] = trace_id\n        bind_contextvars(**context)\n\n    # Also set in ContextVar for stdlib logging fallback\n    correlation_id_var.set(correlation_id)\n\n\ndef clear_correlation_context() -> None:\n    \"\"\"\n    Clear correlation context at the start of a new request.\n\n    This MUST be called at the beginning of each request to prevent\n    context leakage between requests.\n\n    Example:\n        @app.middleware(\"http\")\n        async def correlation_id_middleware(request, call_next):\n            clear_correlation_context()\n            # ... bind new correlation ID\n    \"\"\"\n    if HAS_STRUCTLOG:\n        clear_contextvars()\n    correlation_id_var.set(None)\n\n\ndef get_current_trace_id() -> Optional[str]:\n    \"\"\"\n    Get the current OpenTelemetry trace ID if available.\n\n    Returns:\n        32-character hex trace ID string, or None if tracing is not active.\n    \"\"\"\n    if not HAS_OPENTELEMETRY or trace is None:\n        return None\n\n    span = trace.get_current_span()\n    if span and span.is_recording():\n        return format(span.get_span_context().trace_id, \"032x\")\n    return None\n\n\ndef setup_opentelemetry(service_name: str) -> None:\n    \"\"\"\n    Initialize OpenTelemetry TracerProvider for distributed tracing.\n\n    This function should be called ONCE at application startup, BEFORE\n    any tracing operations. For gunicorn/uwsgi deployments, call this\n    in the post_fork hook.\n\n    Args:\n        service_name: Service identifier for trace spans\n\n    Example:\n        # In FastAPI startup\n        @app.on_event(\"startup\")\n        async def startup():\n            setup_opentelemetry(\"api_gateway\")\n    \"\"\"\n    if not HAS_OPENTELEMETRY:\n        return\n\n    resource = Resource(attributes={\"service.name\": service_name})\n    provider = TracerProvider(resource=resource)\n    trace.set_tracer_provider(provider)\n\n\ndef instrument_fastapi(app: Any) -> None:\n    \"\"\"\n    Auto-instrument a FastAPI application with OpenTelemetry.\n\n    This adds automatic span creation for all HTTP requests and\n    propagates trace context through the application.\n\n    Args:\n        app: FastAPI application instance\n\n    Example:\n        app = FastAPI()\n        setup_opentelemetry(\"api_gateway\")\n        instrument_fastapi(app)\n    \"\"\"\n    if not HAS_OPENTELEMETRY or FastAPIInstrumentor is None:\n        return\n\n    FastAPIInstrumentor().instrument_app(app)\n\n\n# Convenience function for logging errors with exception info\ndef log_error(\n    logger: Any,\n    event: str,\n    error: Optional[Exception] = None,\n    **context: Any,\n) -> None:\n    \"\"\"\n    Log an error with optional exception information.\n\n    Args:\n        logger: Logger instance from get_logger()\n        event: Event name describing the error\n        error: Optional exception to include with stack trace\n        **context: Additional context fields\n\n    Example:\n        try:\n            process_payment(order_id)\n        except Exception as e:\n            log_error(logger, \"payment_failed\", error=e, order_id=order_id)\n    \"\"\"\n    if error:\n        logger.error(event, exc_info=True, error_type=type(error).__name__, **context)\n    else:\n        logger.error(event, **context)\n\n\n# Convenience function for logging success with structured data\ndef log_success(\n    logger: Any,\n    event: str,\n    **context: Any,\n) -> None:\n    \"\"\"\n    Log a successful operation with structured context.\n\n    Args:\n        logger: Logger instance from get_logger()\n        event: Event name describing the success\n        **context: Additional context fields\n\n    Example:\n        log_success(logger, \"user_created\", user_id=new_user.id, method=\"oauth\")\n    \"\"\"\n    logger.info(event, success=True, **context)\n\n\n# Export public API\n__all__ = [\n    # Core configuration\n    \"configure_logging\",\n    \"get_logger\",\n    # Correlation ID management\n    \"bind_correlation_id\",\n    \"clear_correlation_context\",\n    \"correlation_id_var\",\n    # OpenTelemetry integration\n    \"setup_opentelemetry\",\n    \"instrument_fastapi\",\n    \"get_current_trace_id\",\n    # Convenience functions\n    \"log_error\",\n    \"log_success\",\n    # Feature flags\n    \"HAS_STRUCTLOG\",\n    \"HAS_OPENTELEMETRY\",\n    \"HAS_ORJSON\",\n]\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), acgs2-core/breakthrough (79 occurrences), and acgs2-core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.228120",
  "last_updated": "2026-01-04T05:35:58.628264"
}