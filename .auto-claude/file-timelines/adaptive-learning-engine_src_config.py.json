{
  "file_path": "adaptive-learning-engine/src/config.py",
  "main_branch_history": [],
  "task_views": {
    "056-reduce-excessive-any-type-usage-in-python-codebase": {
      "task_id": "056-reduce-excessive-any-type-usage-in-python-codebase",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nAdaptive Learning Engine - Configuration\nConstitutional Hash: cdd01ef066bc6cf2\n\nConfiguration dataclass for the Adaptive Learning Engine.\nFollows the Builder pattern for clean configuration management.\n\"\"\"\n\nfrom dataclasses import dataclass, field, replace\nfrom typing import TYPE_CHECKING, Any, Optional\n\n# Import types conditionally to avoid circular imports\nif TYPE_CHECKING:\n    pass\n\n\n# Import centralized constitutional hash with fallback\ntry:\n    from shared.constants import CONSTITUTIONAL_HASH\nexcept ImportError:\n    CONSTITUTIONAL_HASH = \"cdd01ef066bc6cf2\"\n\n# Default Redis URL with fallback\ntry:\n    from shared.redis_config import get_redis_url\n\n    DEFAULT_REDIS_URL = get_redis_url()\nexcept ImportError:\n    DEFAULT_REDIS_URL = \"redis://localhost:6379/0\"\n\n\n@dataclass\nclass AdaptiveLearningConfig:\n    \"\"\"Configuration for the Adaptive Learning Engine.\n\n    Consolidates all configuration options into a single, immutable dataclass.\n    This follows the Configuration Object pattern for clean dependency management.\n\n    Example usage:\n        # Default configuration\n        config = AdaptiveLearningConfig()\n\n        # Custom configuration\n        config = AdaptiveLearningConfig(\n            safety_accuracy_threshold=0.90,\n            drift_check_interval_seconds=600,\n            enable_prometheus=True,\n        )\n\n        # Build configuration from environment\n        config = AdaptiveLearningConfig.from_environment()\n    \"\"\"\n\n    # Server settings\n    port: int = 8001\n    log_level: str = \"INFO\"\n\n    # ML Model settings\n    min_training_samples: int = 1000\n    safety_accuracy_threshold: float = 0.85\n    safety_consecutive_failures_limit: int = 3\n\n    # Drift detection settings\n    drift_check_interval_seconds: int = 300\n    drift_window_size: int = 1000\n    drift_threshold: float = 0.2  # PSI threshold for drift detection\n    min_predictions_for_drift: int = 10  # Minimum predictions per minute\n\n    # MLflow settings\n    mlflow_tracking_uri: str = \"sqlite:///mlruns/mlflow.db\"\n    mlflow_model_name: str = \"governance_model\"\n    mlflow_champion_alias: str = \"champion\"\n\n    # Integration URLs\n    redis_url: str = DEFAULT_REDIS_URL\n    kafka_bootstrap_servers: str = \"kafka:29092\"\n    agent_bus_url: str = \"http://agent-bus:8000\"\n    opa_url: str = \"http://opa:8181\"\n\n    # Feature flags\n    enable_prometheus: bool = True\n    enable_kafka: bool = False\n    enable_redis_cache: bool = True\n    enable_drift_detection: bool = True\n    enable_safety_bounds: bool = True\n\n    # Optional dependency injections (set to None for defaults)\n    # Note: These are typed as Any to avoid circular imports at runtime\n    model_manager: Optional[Any] = None\n    drift_detector: Optional[Any] = None\n    mlflow_registry: Optional[Any] = None\n\n    # Constitutional settings\n    constitutional_hash: str = field(default=CONSTITUTIONAL_HASH)\n\n    def __post_init__(self) -> None:\n        \"\"\"Validate configuration after initialization.\"\"\"\n        # Ensure constitutional hash is always set\n        if not self.constitutional_hash:\n            self.constitutional_hash = CONSTITUTIONAL_HASH\n\n        # Validate thresholds\n        if not 0.0 <= self.safety_accuracy_threshold <= 1.0:\n            raise ValueError(\n                f\"safety_accuracy_threshold must be between 0 and 1, got {self.safety_accuracy_threshold}\"\n            )\n\n        if not 0.0 <= self.drift_threshold <= 1.0:\n            raise ValueError(f\"drift_threshold must be between 0 and 1, got {self.drift_threshold}\")\n\n        if self.min_training_samples <= 0:\n            raise ValueError(\n                f\"min_training_samples must be positive, got {self.min_training_samples}\"\n            )\n\n        if self.drift_check_interval_seconds <= 0:\n            raise ValueError(\n                f\"drift_check_interval_seconds must be positive, got {self.drift_check_interval_seconds}\"\n            )\n\n    @classmethod\n    def from_environment(cls) -> \"AdaptiveLearningConfig\":\n        \"\"\"Create configuration from environment variables.\n\n        Environment variables:\n            ADAPTIVE_LEARNING_PORT: Service port (default: 8001)\n            LOG_LEVEL: Logging level (default: INFO)\n            MIN_TRAINING_SAMPLES: Minimum samples before model is active\n            SAFETY_ACCURACY_THRESHOLD: Accuracy threshold for safety bounds\n            SAFETY_CONSECUTIVE_FAILURES_LIMIT: Max consecutive safety failures\n            DRIFT_CHECK_INTERVAL_SECONDS: Interval for drift checks\n            DRIFT_WINDOW_SIZE: Window size for drift detection\n            DRIFT_THRESHOLD: PSI threshold for drift detection\n            MIN_PREDICTIONS_FOR_DRIFT: Minimum predictions for drift check\n            MLFLOW_TRACKING_URI: MLflow tracking URI\n            MLFLOW_MODEL_NAME: Model name in MLflow registry\n            REDIS_URL: Redis connection URL\n            KAFKA_BOOTSTRAP: Kafka bootstrap servers\n            AGENT_BUS_URL: Agent Bus service URL\n            OPA_URL: OPA service URL\n            PROMETHEUS_ENABLED: Enable Prometheus metrics (true/false)\n            KAFKA_ENABLED: Enable Kafka integration (true/false)\n            REDIS_CACHE_ENABLED: Enable Redis caching (true/false)\n            DRIFT_DETECTION_ENABLED: Enable drift detection (true/false)\n            SAFETY_BOUNDS_ENABLED: Enable safety bounds (true/false)\n        \"\"\"\n        import os\n\n        def _parse_bool(value: Optional[str], default: bool = False) -> bool:\n            if value is None:\n                return default\n            return value.lower() in (\"true\", \"1\", \"yes\", \"on\")\n\n        def _parse_int(value: Optional[str], default: int) -> int:\n            if value is None:\n                return default\n            try:\n                return int(value)\n            except ValueError:\n                return default\n\n        def _parse_float(value: Optional[str], default: float) -> float:\n            if value is None:\n                return default\n            try:\n                return float(value)\n            except ValueError:\n                return default\n\n        return cls(\n            # Server settings\n            port=_parse_int(os.environ.get(\"ADAPTIVE_LEARNING_PORT\"), 8001),\n            log_level=os.environ.get(\"LOG_LEVEL\", \"INFO\"),\n            # ML Model settings\n            min_training_samples=_parse_int(os.environ.get(\"MIN_TRAINING_SAMPLES\"), 1000),\n            safety_accuracy_threshold=_parse_float(\n                os.environ.get(\"SAFETY_ACCURACY_THRESHOLD\"), 0.85\n            ),\n            safety_consecutive_failures_limit=_parse_int(\n                os.environ.get(\"SAFETY_CONSECUTIVE_FAILURES_LIMIT\"), 3\n            ),\n            # Drift detection settings\n            drift_check_interval_seconds=_parse_int(\n                os.environ.get(\"DRIFT_CHECK_INTERVAL_SECONDS\"), 300\n            ),\n            drift_window_size=_parse_int(os.environ.get(\"DRIFT_WINDOW_SIZE\"), 1000),\n            drift_threshold=_parse_float(os.environ.get(\"DRIFT_THRESHOLD\"), 0.2),\n            min_predictions_for_drift=_parse_int(os.environ.get(\"MIN_PREDICTIONS_FOR_DRIFT\"), 10),\n            # MLflow settings\n            mlflow_tracking_uri=os.environ.get(\"MLFLOW_TRACKING_URI\", \"sqlite:///mlruns/mlflow.db\"),\n            mlflow_model_name=os.environ.get(\"MLFLOW_MODEL_NAME\", \"governance_model\"),\n            # Integration URLs\n            redis_url=os.environ.get(\"REDIS_URL\", DEFAULT_REDIS_URL),\n            kafka_bootstrap_servers=os.environ.get(\"KAFKA_BOOTSTRAP\", \"kafka:29092\"),\n            agent_bus_url=os.environ.get(\"AGENT_BUS_URL\", \"http://agent-bus:8000\"),\n            opa_url=os.environ.get(\"OPA_URL\", \"http://opa:8181\"),\n            # Feature flags\n            enable_prometheus=_parse_bool(os.environ.get(\"PROMETHEUS_ENABLED\"), True),\n            enable_kafka=_parse_bool(os.environ.get(\"KAFKA_ENABLED\"), False),\n            enable_redis_cache=_parse_bool(os.environ.get(\"REDIS_CACHE_ENABLED\"), True),\n            enable_drift_detection=_parse_bool(os.environ.get(\"DRIFT_DETECTION_ENABLED\"), True),\n            enable_safety_bounds=_parse_bool(os.environ.get(\"SAFETY_BOUNDS_ENABLED\"), True),\n        )\n\n    @classmethod\n    def for_testing(cls) -> \"AdaptiveLearningConfig\":\n        \"\"\"Create a minimal configuration for unit testing.\n\n        Disables all optional features for fast, isolated testing.\n        \"\"\"\n        return cls(\n            min_training_samples=10,  # Low threshold for quick tests\n            safety_accuracy_threshold=0.5,  # Relaxed for testing\n            drift_check_interval_seconds=60,  # Shorter interval for tests\n            drift_window_size=100,  # Smaller window for tests\n            enable_prometheus=False,\n            enable_kafka=False,\n            enable_redis_cache=False,\n            enable_drift_detection=False,\n            enable_safety_bounds=False,\n        )\n\n    @classmethod\n    def for_production(cls) -> \"AdaptiveLearningConfig\":\n        \"\"\"Create a configuration suitable for production use.\n\n        Enables all production features with conservative safety settings.\n        \"\"\"\n        return cls(\n            min_training_samples=1000,\n            safety_accuracy_threshold=0.85,\n            safety_consecutive_failures_limit=3,\n            drift_check_interval_seconds=300,\n            drift_window_size=1000,\n            drift_threshold=0.2,\n            enable_prometheus=True,\n            enable_kafka=True,\n            enable_redis_cache=True,\n            enable_drift_detection=True,\n            enable_safety_bounds=True,\n        )\n\n    def with_model_manager(self, model_manager: Any) -> \"AdaptiveLearningConfig\":\n        \"\"\"Return a new configuration with the specified model manager.\n\n        Builder pattern method for fluent configuration.\n        Uses dataclasses.replace() for immutable field updates.\n        \"\"\"\n        return replace(self, model_manager=model_manager)\n\n    def with_drift_detector(self, drift_detector: Any) -> \"AdaptiveLearningConfig\":\n        \"\"\"Return a new configuration with the specified drift detector.\n\n        Builder pattern method for fluent configuration.\n        Uses dataclasses.replace() for immutable field updates.\n        \"\"\"\n        return replace(self, drift_detector=drift_detector)\n\n    def with_mlflow_registry(self, mlflow_registry: Any) -> \"AdaptiveLearningConfig\":\n        \"\"\"Return a new configuration with the specified MLflow registry.\n\n        Builder pattern method for fluent configuration.\n        Uses dataclasses.replace() for immutable field updates.\n        \"\"\"\n        return replace(self, mlflow_registry=mlflow_registry)\n\n    def to_dict(self) -> dict:\n        \"\"\"Convert configuration to dictionary for logging/serialization.\"\"\"\n        return {\n            # Server settings\n            \"port\": self.port,\n            \"log_level\": self.log_level,\n            # ML Model settings\n            \"min_training_samples\": self.min_training_samples,\n            \"safety_accuracy_threshold\": self.safety_accuracy_threshold,\n            \"safety_consecutive_failures_limit\": self.safety_consecutive_failures_limit,\n            # Drift detection settings\n            \"drift_check_interval_seconds\": self.drift_check_interval_seconds,\n            \"drift_window_size\": self.drift_window_size,\n            \"drift_threshold\": self.drift_threshold,\n            \"min_predictions_for_drift\": self.min_predictions_for_drift,\n            # MLflow settings\n            \"mlflow_tracking_uri\": self.mlflow_tracking_uri,\n            \"mlflow_model_name\": self.mlflow_model_name,\n            \"mlflow_champion_alias\": self.mlflow_champion_alias,\n            # Integration URLs\n            \"redis_url\": self.redis_url,\n            \"kafka_bootstrap_servers\": self.kafka_bootstrap_servers,\n            \"agent_bus_url\": self.agent_bus_url,\n            \"opa_url\": self.opa_url,\n            # Feature flags\n            \"enable_prometheus\": self.enable_prometheus,\n            \"enable_kafka\": self.enable_kafka,\n            \"enable_redis_cache\": self.enable_redis_cache,\n            \"enable_drift_detection\": self.enable_drift_detection,\n            \"enable_safety_bounds\": self.enable_safety_bounds,\n            # Constitutional settings\n            \"constitutional_hash\": self.constitutional_hash,\n            # Dependency injection status\n            \"has_custom_model_manager\": self.model_manager is not None,\n            \"has_custom_drift_detector\": self.drift_detector is not None,\n            \"has_custom_mlflow_registry\": self.mlflow_registry is not None,\n        }\n",
        "timestamp": "2026-01-04T05:35:58.374613"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "056-reduce-excessive-any-type-usage-in-python-codebase",
        "description": "Found 373 occurrences of ': Any' type annotations across 120+ Python files, with high concentrations in integration-service (16 occurrences), acgs2-core/breakthrough (79 occurrences), and acgs2-core/enhanced_agent_bus (50+ occurrences). Excessive use of 'Any' defeats the purpose of type hints and can mask type-related bugs.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:18.129735",
  "last_updated": "2026-01-04T05:35:58.801404"
}