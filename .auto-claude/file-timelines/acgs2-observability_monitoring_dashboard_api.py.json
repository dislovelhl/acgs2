{
  "file_path": "acgs2-observability/monitoring/dashboard_api.py",
  "main_branch_history": [],
  "task_views": {
    "046-add-security-headers-middleware-to-fastapi-service": {
      "task_id": "046-add-security-headers-middleware-to-fastapi-service",
      "branch_point": {
        "commit_hash": "4a99fe22e8e0087919301b1aa185d4e2c6da716c",
        "content": "\"\"\"\nACGS-2 Unified Monitoring Dashboard API\nConstitutional Hash: cdd01ef066bc6cf2\n\nProvides a unified REST API for the monitoring dashboard, aggregating:\n- Service health from HealthChecker\n- Circuit breaker health from HealthAggregator\n- Performance metrics from system monitors\n- Alert status from alerting module\n\nEndpoints:\n- GET /dashboard/overview - System overview with all key metrics\n- GET /dashboard/health - Aggregated health status\n- GET /dashboard/metrics - Performance metrics\n- GET /dashboard/alerts - Active alerts\n- GET /dashboard/services - Detailed service status\n- WebSocket /dashboard/ws - Real-time updates\n\"\"\"\n\nimport asyncio\nimport logging\nimport os\nimport sys\nimport time\nfrom collections import deque\nfrom datetime import datetime, timedelta, timezone\nfrom enum import Enum\nfrom typing import Any, Callable, Dict, List, Optional, Set\n\n# Add project root to path for imports\nsys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\ntry:\n    from contextlib import asynccontextmanager\n\n    from fastapi import FastAPI, HTTPException, Request, WebSocket, WebSocketDisconnect\n    from fastapi.middleware.cors import CORSMiddleware\n    from fastapi.responses import JSONResponse\n    from pydantic import BaseModel, Field\n\n    # Try to import memory profiler for integration\n    try:\n        import os\n        import sys\n\n        sys.path.insert(0, os.path.join(os.path.dirname(__file__), \"../../src/core\"))\n        from enhanced_agent_bus.memory_profiler import MemorySnapshot, get_memory_profiler\n\n        MEMORY_PROFILER_AVAILABLE = True\n    except ImportError:\n        MEMORY_PROFILER_AVAILABLE = False\n\n    FASTAPI_AVAILABLE = True\nexcept ImportError:\n    FASTAPI_AVAILABLE = False\n    FastAPI = None\n    WebSocket = None\n    # Provide fallback BaseModel for when pydantic is not available\n    from dataclasses import field as dataclass_field\n\n    class BaseModel:\n        \"\"\"Fallback BaseModel when pydantic is not available.\"\"\"\n\n        pass\n\n    def Field(default=None, default_factory=None, **kwargs):\n        \"\"\"Fallback Field when pydantic is not available.\"\"\"\n        if default_factory is not None:\n            return dataclass_field(default_factory=default_factory)\n        return default\n\n\ntry:\n    import psutil\n\n    PSUTIL_AVAILABLE = True\nexcept ImportError:\n    PSUTIL_AVAILABLE = False\n    psutil = None\n\ntry:\n    import redis.asyncio as redis\n\n    REDIS_AVAILABLE = True\nexcept ImportError:\n    REDIS_AVAILABLE = False\n    redis = None\n\n# Constitutional hash for governance compliance\nCONSTITUTIONAL_HASH = \"cdd01ef066bc6cf2\"\n\nlogger = logging.getLogger(__name__)\n\n\n# ============================================================================\n# Pydantic Models for API responses\n# ============================================================================\n\n\nclass ServiceHealthStatus(str, Enum):\n    \"\"\"Service health status.\"\"\"\n\n    HEALTHY = \"healthy\"\n    DEGRADED = \"degraded\"\n    UNHEALTHY = \"unhealthy\"\n    UNKNOWN = \"unknown\"\n\n\nclass AlertSeverity(str, Enum):\n    \"\"\"Alert severity levels.\"\"\"\n\n    CRITICAL = \"critical\"\n    ERROR = \"error\"\n    WARNING = \"warning\"\n    INFO = \"info\"\n\n\nclass ServiceHealth(BaseModel):\n    \"\"\"Individual service health model.\"\"\"\n\n    name: str\n    status: ServiceHealthStatus\n    response_time_ms: Optional[float] = None\n    last_check: datetime\n    error_message: Optional[str] = None\n    details: Dict[str, Any] = Field(default_factory=dict)\n\n\nclass SystemMetrics(BaseModel):\n    \"\"\"System performance metrics.\"\"\"\n\n    cpu_percent: float\n    memory_percent: float\n    memory_used_gb: float\n    memory_total_gb: float\n    disk_percent: float\n    disk_used_gb: float\n    disk_total_gb: float\n    network_bytes_sent: int\n    network_bytes_recv: int\n    process_count: int\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n\n\nclass PerformanceMetrics(BaseModel):\n    \"\"\"ACGS-2 performance metrics.\"\"\"\n\n    p99_latency_ms: float\n    throughput_rps: float\n    cache_hit_rate: float\n    constitutional_compliance: float = 100.0\n    active_connections: int = 0\n    requests_total: int = 0\n    errors_total: int = 0\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n\n\nclass AlertInfo(BaseModel):\n    \"\"\"Alert information.\"\"\"\n\n    alert_id: str\n    title: str\n    description: str\n    severity: AlertSeverity\n    source: str\n    status: str\n    timestamp: datetime\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n\n\nclass CircuitBreakerInfo(BaseModel):\n    \"\"\"Circuit breaker status.\"\"\"\n\n    name: str\n    state: str  # closed, open, half_open\n    fail_count: int = 0\n    success_count: int = 0\n    last_failure: Optional[datetime] = None\n\n\nclass DashboardOverview(BaseModel):\n    \"\"\"Complete dashboard overview response.\"\"\"\n\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n\n    # Overall health\n    overall_status: ServiceHealthStatus\n    health_score: float  # 0.0 - 1.0\n\n    # Service summary\n    total_services: int\n    healthy_services: int\n    degraded_services: int\n    unhealthy_services: int\n\n    # Circuit breaker summary\n    total_circuit_breakers: int\n    closed_breakers: int\n    open_breakers: int\n    half_open_breakers: int\n\n    # Performance summary\n    p99_latency_ms: float\n    throughput_rps: float\n    cache_hit_rate: float\n\n    # System resources\n    cpu_percent: float\n    memory_percent: float\n    disk_percent: float\n\n    # Alerts summary\n    critical_alerts: int\n    warning_alerts: int\n    total_alerts: int\n\n\nclass HealthAggregateResponse(BaseModel):\n    \"\"\"Aggregated health response.\"\"\"\n\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n    overall_status: ServiceHealthStatus\n    health_score: float\n    services: List[ServiceHealth]\n    circuit_breakers: List[CircuitBreakerInfo]\n\n\nclass MetricsResponse(BaseModel):\n    \"\"\"Metrics response.\"\"\"\n\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n    system: SystemMetrics\n    performance: PerformanceMetrics\n    history: List[Dict[str, Any]] = Field(default_factory=list)\n\n\n# ============================================================================\n# Metrics Collector\n# ============================================================================\n\n\nclass MetricsCollector:\n    \"\"\"Collects system and application metrics.\"\"\"\n\n    def __init__(self, history_size: int = 300):\n        self.history_size = history_size\n        self.metrics_history: deque = deque(maxlen=history_size)\n        self._redis_client: Optional[Any] = None\n        self._running = False\n        self._collection_task: Optional[asyncio.Task] = None\n\n    async def start(self, collection_interval: float = 1.0) -> None:\n        \"\"\"Start metrics collection.\"\"\"\n        if self._running:\n            return\n\n        self._running = True\n\n        # Try to connect to Redis for metrics storage\n        if REDIS_AVAILABLE:\n            try:\n                redis_url = os.environ.get(\"REDIS_URL\", \"redis://localhost:6379\")\n                self._redis_client = redis.from_url(redis_url)\n                await self._redis_client.ping()\n                logger.info(f\"[{CONSTITUTIONAL_HASH}] Connected to Redis for metrics\")\n            except Exception as e:\n                logger.warning(f\"Redis connection failed: {e}, using in-memory storage\")\n                self._redis_client = None\n\n        self._collection_task = asyncio.create_task(self._collection_loop(collection_interval))\n        logger.info(f\"[{CONSTITUTIONAL_HASH}] MetricsCollector started\")\n\n    async def stop(self) -> None:\n        \"\"\"Stop metrics collection.\"\"\"\n        self._running = False\n        if self._collection_task:\n            self._collection_task.cancel()\n            try:\n                await self._collection_task\n            except asyncio.CancelledError:\n                pass\n\n        if self._redis_client:\n            await self._redis_client.close()\n\n        logger.info(f\"[{CONSTITUTIONAL_HASH}] MetricsCollector stopped\")\n\n    async def _collection_loop(self, interval: float) -> None:\n        \"\"\"Background loop for metrics collection.\"\"\"\n        while self._running:\n            try:\n                metrics = await self.collect_metrics()\n                self.metrics_history.append(metrics)\n\n                # Store in Redis if available\n                if self._redis_client:\n                    try:\n                        await self._redis_client.lpush(\n                            \"acgs2:metrics:history\", metrics[\"timestamp\"].isoformat()\n                        )\n                        await self._redis_client.ltrim(\"acgs2:metrics:history\", 0, 299)\n                    except Exception:\n                        pass\n\n                await asyncio.sleep(interval)\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Metrics collection error: {e}\")\n                await asyncio.sleep(interval)\n\n    async def collect_metrics(self) -> Dict[str, Any]:\n        \"\"\"Collect current metrics.\"\"\"\n        timestamp = datetime.now(timezone.utc)\n\n        # System metrics\n        system_metrics = self._collect_system_metrics()\n\n        # Performance metrics (from Redis or defaults)\n        performance_metrics = await self._collect_performance_metrics()\n\n        return {\n            \"timestamp\": timestamp,\n            \"system\": system_metrics,\n            \"performance\": performance_metrics,\n            \"constitutional_hash\": CONSTITUTIONAL_HASH,\n        }\n\n    def _collect_system_metrics(self) -> Dict[str, Any]:\n        \"\"\"Collect system resource metrics.\"\"\"\n        if not PSUTIL_AVAILABLE:\n            return {\n                \"cpu_percent\": 0.0,\n                \"memory_percent\": 0.0,\n                \"memory_used_gb\": 0.0,\n                \"memory_total_gb\": 0.0,\n                \"disk_percent\": 0.0,\n                \"disk_used_gb\": 0.0,\n                \"disk_total_gb\": 0.0,\n                \"network_bytes_sent\": 0,\n                \"network_bytes_recv\": 0,\n                \"process_count\": 0,\n            }\n\n        memory = psutil.virtual_memory()\n        disk = psutil.disk_usage(\"/\")\n        # Defensive: net_io_counters() can return None in some environments (containers, etc.)\n        network = psutil.net_io_counters()\n        network_bytes_sent = network.bytes_sent if network else 0\n        network_bytes_recv = network.bytes_recv if network else 0\n\n        return {\n            \"cpu_percent\": psutil.cpu_percent(interval=None),\n            \"memory_percent\": memory.percent,\n            \"memory_used_gb\": round(memory.used / (1024**3), 2),\n            \"memory_total_gb\": round(memory.total / (1024**3), 2),\n            \"disk_percent\": disk.percent,\n            \"disk_used_gb\": round(disk.used / (1024**3), 2),\n            \"disk_total_gb\": round(disk.total / (1024**3), 2),\n            \"network_bytes_sent\": network_bytes_sent,\n            \"network_bytes_recv\": network_bytes_recv,\n            \"process_count\": len(psutil.pids()),\n        }\n\n    async def _collect_performance_metrics(self) -> Dict[str, Any]:\n        \"\"\"Collect application performance metrics.\"\"\"\n        defaults = {\n            \"p99_latency_ms\": 0.278,  # Current achieved P99\n            \"throughput_rps\": 6310.0,  # Current achieved RPS\n            \"cache_hit_rate\": 0.95,\n            \"constitutional_compliance\": 100.0,\n            \"active_connections\": 0,\n            \"requests_total\": 0,\n            \"errors_total\": 0,\n        }\n\n        if self._redis_client:\n            try:\n                # Try to get actual metrics from Redis\n                p99 = await self._redis_client.get(\"acgs2:metrics:p99_latency\")\n                rps = await self._redis_client.get(\"acgs2:metrics:throughput_rps\")\n                cache_hit = await self._redis_client.get(\"acgs2:metrics:cache_hit_rate\")\n\n                if p99:\n                    defaults[\"p99_latency_ms\"] = float(p99)\n                if rps:\n                    defaults[\"throughput_rps\"] = float(rps)\n                if cache_hit:\n                    defaults[\"cache_hit_rate\"] = float(cache_hit)\n            except Exception:\n                pass\n\n        return defaults\n\n    def get_history(self, minutes: int = 5) -> List[Dict[str, Any]]:\n        \"\"\"Get metrics history for the last N minutes.\"\"\"\n        cutoff = datetime.now(timezone.utc) - timedelta(minutes=minutes)\n        return [\n            m\n            for m in self.metrics_history\n            if m.get(\"timestamp\", datetime.min.replace(tzinfo=timezone.utc)) >= cutoff\n        ]\n\n\n# ============================================================================\n# Service Health Checker\n# ============================================================================\n\n\nclass ServiceHealthChecker:\n    \"\"\"Checks health of ACGS-2 services.\"\"\"\n\n    def __init__(self):\n        self.services = {\n            \"enhanced-agent-bus\": os.environ.get(\"AGENT_BUS_URL\", \"http://localhost:8000\")\n            + \"/health\",\n            \"policy-registry\": os.environ.get(\"POLICY_REGISTRY_URL\", \"http://localhost:8000\")\n            + \"/health\",\n            \"constitutional-ai\": os.environ.get(\"CONSTITUTIONAL_AI_URL\", \"http://localhost:8001\")\n            + \"/health\",\n            \"audit-service\": os.environ.get(\"AUDIT_SERVICE_URL\", \"http://localhost:8003\")\n            + \"/health\",\n        }\n        self._health_cache: Dict[str, ServiceHealth] = {}\n        self._cache_ttl = 5  # seconds\n        self._last_check: Dict[str, datetime] = {}\n\n    async def check_service(self, name: str, url: str) -> ServiceHealth:\n        \"\"\"Check health of a single service.\"\"\"\n        import aiohttp\n\n        start_time = time.time()\n\n        try:\n            timeout = aiohttp.ClientTimeout(total=5)\n            async with aiohttp.ClientSession(timeout=timeout) as session:\n                async with session.get(url) as response:\n                    response_time = (time.time() - start_time) * 1000\n\n                    if response.status == 200:\n                        try:\n                            details = await response.json()\n                        except Exception:\n                            details = {\"raw\": await response.text()}\n\n                        return ServiceHealth(\n                            name=name,\n                            status=ServiceHealthStatus.HEALTHY,\n                            response_time_ms=response_time,\n                            last_check=datetime.now(timezone.utc),\n                            details=details,\n                        )\n                    else:\n                        return ServiceHealth(\n                            name=name,\n                            status=ServiceHealthStatus.UNHEALTHY,\n                            response_time_ms=response_time,\n                            last_check=datetime.now(timezone.utc),\n                            error_message=f\"HTTP {response.status}\",\n                        )\n        except asyncio.TimeoutError:\n            return ServiceHealth(\n                name=name,\n                status=ServiceHealthStatus.UNHEALTHY,\n                response_time_ms=(time.time() - start_time) * 1000,\n                last_check=datetime.now(timezone.utc),\n                error_message=\"Timeout\",\n            )\n        except Exception as e:\n            return ServiceHealth(\n                name=name,\n                status=ServiceHealthStatus.UNKNOWN,\n                response_time_ms=(time.time() - start_time) * 1000,\n                last_check=datetime.now(timezone.utc),\n                error_message=str(e),\n            )\n\n    async def check_all_services(self) -> List[ServiceHealth]:\n        \"\"\"Check health of all registered services.\"\"\"\n        tasks = [self.check_service(name, url) for name, url in self.services.items()]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        service_health = []\n        for i, result in enumerate(results):\n            if isinstance(result, Exception):\n                name = list(self.services.keys())[i]\n                service_health.append(\n                    ServiceHealth(\n                        name=name,\n                        status=ServiceHealthStatus.UNKNOWN,\n                        last_check=datetime.now(timezone.utc),\n                        error_message=str(result),\n                    )\n                )\n            else:\n                service_health.append(result)\n\n        return service_health\n\n\n# ============================================================================\n# Alert Manager\n# ============================================================================\n\n\nclass AlertManager:\n    \"\"\"Manages alerts for the dashboard.\"\"\"\n\n    def __init__(self):\n        self.alerts: Dict[str, AlertInfo] = {}\n        self._alert_callbacks: List[Callable[[AlertInfo], None]] = []\n\n    def add_alert(self, alert: AlertInfo) -> None:\n        \"\"\"Add a new alert.\"\"\"\n        self.alerts[alert.alert_id] = alert\n        for callback in self._alert_callbacks:\n            try:\n                callback(alert)\n            except Exception as e:\n                logger.error(f\"Alert callback error: {e}\")\n\n    def resolve_alert(self, alert_id: str) -> bool:\n        \"\"\"Resolve an alert by ID.\"\"\"\n        if alert_id in self.alerts:\n            del self.alerts[alert_id]\n            return True\n        return False\n\n    def get_active_alerts(self) -> List[AlertInfo]:\n        \"\"\"Get all active alerts.\"\"\"\n        return list(self.alerts.values())\n\n    def get_alerts_by_severity(self, severity: AlertSeverity) -> List[AlertInfo]:\n        \"\"\"Get alerts by severity.\"\"\"\n        return [a for a in self.alerts.values() if a.severity == severity]\n\n    def on_alert(self, callback: Callable[[AlertInfo], None]) -> None:\n        \"\"\"Register alert callback.\"\"\"\n        self._alert_callbacks.append(callback)\n\n\n# ============================================================================\n# Dashboard Service\n# ============================================================================\n\n\nclass DashboardService:\n    \"\"\"Main dashboard service orchestrating all monitoring components.\"\"\"\n\n    def __init__(self):\n        self.metrics_collector = MetricsCollector()\n        self.health_checker = ServiceHealthChecker()\n        self.alert_manager = AlertManager()\n        self._websocket_clients: Set[WebSocket] = set()\n        self._broadcast_task: Optional[asyncio.Task] = None\n        self._running = False\n\n    async def start(self) -> None:\n        \"\"\"Start the dashboard service.\"\"\"\n        if self._running:\n            return\n\n        self._running = True\n        await self.metrics_collector.start()\n        self._broadcast_task = asyncio.create_task(self._broadcast_loop())\n        logger.info(f\"[{CONSTITUTIONAL_HASH}] DashboardService started\")\n\n    async def stop(self) -> None:\n        \"\"\"Stop the dashboard service.\"\"\"\n        self._running = False\n        await self.metrics_collector.stop()\n\n        if self._broadcast_task:\n            self._broadcast_task.cancel()\n            try:\n                await self._broadcast_task\n            except asyncio.CancelledError:\n                pass\n\n        # Close all websocket connections\n        for ws in list(self._websocket_clients):\n            try:\n                await ws.close()\n            except Exception:\n                pass\n\n        logger.info(f\"[{CONSTITUTIONAL_HASH}] DashboardService stopped\")\n\n    async def get_overview(self) -> DashboardOverview:\n        \"\"\"Get complete dashboard overview.\"\"\"\n        # Get service health\n        services = await self.health_checker.check_all_services()\n        healthy = sum(1 for s in services if s.status == ServiceHealthStatus.HEALTHY)\n        degraded = sum(1 for s in services if s.status == ServiceHealthStatus.DEGRADED)\n        unhealthy = sum(1 for s in services if s.status == ServiceHealthStatus.UNHEALTHY)\n\n        # Calculate health score\n        if services:\n            health_score = (healthy + degraded * 0.5) / len(services)\n        else:\n            health_score = 1.0\n\n        # Determine overall status\n        if unhealthy > len(services) / 2:\n            overall_status = ServiceHealthStatus.UNHEALTHY\n        elif unhealthy > 0 or degraded > 0:\n            overall_status = ServiceHealthStatus.DEGRADED\n        else:\n            overall_status = ServiceHealthStatus.HEALTHY\n\n        # Get metrics\n        metrics = await self.metrics_collector.collect_metrics()\n        system = metrics[\"system\"]\n        performance = metrics[\"performance\"]\n\n        # Get alerts\n        alerts = self.alert_manager.get_active_alerts()\n        critical_alerts = len([a for a in alerts if a.severity == AlertSeverity.CRITICAL])\n        warning_alerts = len([a for a in alerts if a.severity == AlertSeverity.WARNING])\n\n        return DashboardOverview(\n            overall_status=overall_status,\n            health_score=round(health_score, 3),\n            total_services=len(services),\n            healthy_services=healthy,\n            degraded_services=degraded,\n            unhealthy_services=unhealthy,\n            total_circuit_breakers=0,  # Will be populated from HealthAggregator\n            closed_breakers=0,\n            open_breakers=0,\n            half_open_breakers=0,\n            p99_latency_ms=performance[\"p99_latency_ms\"],\n            throughput_rps=performance[\"throughput_rps\"],\n            cache_hit_rate=performance[\"cache_hit_rate\"],\n            cpu_percent=system[\"cpu_percent\"],\n            memory_percent=system[\"memory_percent\"],\n            disk_percent=system[\"disk_percent\"],\n            critical_alerts=critical_alerts,\n            warning_alerts=warning_alerts,\n            total_alerts=len(alerts),\n        )\n\n    async def get_health(self) -> HealthAggregateResponse:\n        \"\"\"Get aggregated health status.\"\"\"\n        services = await self.health_checker.check_all_services()\n\n        # Calculate overall\n        if not services:\n            overall_status = ServiceHealthStatus.UNKNOWN\n            health_score = 0.0\n        else:\n            healthy = sum(1 for s in services if s.status == ServiceHealthStatus.HEALTHY)\n            health_score = healthy / len(services)\n\n            if health_score >= 0.9:\n                overall_status = ServiceHealthStatus.HEALTHY\n            elif health_score >= 0.5:\n                overall_status = ServiceHealthStatus.DEGRADED\n            else:\n                overall_status = ServiceHealthStatus.UNHEALTHY\n\n        return HealthAggregateResponse(\n            overall_status=overall_status,\n            health_score=round(health_score, 3),\n            services=services,\n            circuit_breakers=[],  # Will be populated from HealthAggregator\n        )\n\n    async def get_metrics(self) -> MetricsResponse:\n        \"\"\"Get performance metrics.\"\"\"\n        metrics = await self.metrics_collector.collect_metrics()\n        history = self.metrics_collector.get_history(minutes=5)\n\n        return MetricsResponse(\n            system=SystemMetrics(**metrics[\"system\"]),\n            performance=PerformanceMetrics(**metrics[\"performance\"]),\n            history=history,\n        )\n\n    async def register_websocket(self, websocket: WebSocket) -> None:\n        \"\"\"Register a websocket client for real-time updates.\"\"\"\n        self._websocket_clients.add(websocket)\n\n    async def unregister_websocket(self, websocket: WebSocket) -> None:\n        \"\"\"Unregister a websocket client.\"\"\"\n        self._websocket_clients.discard(websocket)\n\n    async def _broadcast_loop(self) -> None:\n        \"\"\"Broadcast updates to all connected websocket clients.\"\"\"\n        while self._running:\n            try:\n                if self._websocket_clients:\n                    overview = await self.get_overview()\n                    message = overview.model_dump_json()\n\n                    for ws in list(self._websocket_clients):\n                        try:\n                            await ws.send_text(message)\n                        except Exception:\n                            self._websocket_clients.discard(ws)\n\n                await asyncio.sleep(1)  # Update every second\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Broadcast error: {e}\")\n                await asyncio.sleep(1)\n\n\n# ============================================================================\n# FastAPI Application\n# ============================================================================\n\n\ndef create_dashboard_app() -> FastAPI:\n    \"\"\"Create the FastAPI dashboard application.\"\"\"\n    if not FASTAPI_AVAILABLE:\n        raise RuntimeError(\"FastAPI not available. Install with: pip install fastapi uvicorn\")\n\n    @asynccontextmanager\n    async def lifespan(app: FastAPI):\n        \"\"\"Application lifespan context manager.\"\"\"\n        dashboard_service = DashboardService()\n        await dashboard_service.start()\n        app.state.dashboard_service = dashboard_service\n        yield\n        await dashboard_service.stop()\n\n    app = FastAPI(\n        title=\"ACGS-2 Monitoring Dashboard API\",\n        description=\"Unified monitoring dashboard for AI Constitutional Governance System\",\n        version=\"1.0.0\",\n        lifespan=lifespan,\n    )\n\n    # Configure CORS based on environment for security\n    cors_origins = os.getenv(\"CORS_ALLOWED_ORIGINS\", \"\").split(\",\")\n    if not cors_origins or cors_origins == [\"\"]:\n        # Default secure configuration - no external origins allowed\n        cors_origins = []\n\n    # Allow localhost for development (but not in production)\n    if os.getenv(\"ENVIRONMENT\", \"\").lower() == \"development\":\n        cors_origins.extend(\n            [\n                \"http://localhost:3000\",\n                \"http://localhost:8080\",\n                \"http://127.0.0.1:3000\",\n                \"http://127.0.0.1:8080\",\n            ]\n        )\n\n    # Add CORS middleware with secure configuration\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=cors_origins,\n        allow_credentials=True,\n        allow_methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"],\n        allow_headers=[\"Authorization\", \"Content-Type\", \"X-Correlation-ID\"],\n    )\n\n    @app.get(\"/dashboard/overview\", response_model=DashboardOverview)\n    async def get_overview(request: Request):\n        \"\"\"Get complete dashboard overview.\"\"\"\n        return await request.app.state.dashboard_service.get_overview()\n\n    @app.get(\"/dashboard/health\", response_model=HealthAggregateResponse)\n    async def get_health(request: Request):\n        \"\"\"Get aggregated health status.\"\"\"\n        return await request.app.state.dashboard_service.get_health()\n\n    @app.get(\"/dashboard/metrics\", response_model=MetricsResponse)\n    async def get_metrics(request: Request):\n        \"\"\"Get performance metrics.\"\"\"\n        return await request.app.state.dashboard_service.get_metrics()\n\n    @app.get(\"/dashboard/alerts\", response_model=List[AlertInfo])\n    async def get_alerts(request: Request):\n        \"\"\"Get active alerts.\"\"\"\n        return request.app.state.dashboard_service.alert_manager.get_active_alerts()\n\n    @app.get(\"/dashboard/memory\", response_model=Dict[str, Any])\n    async def get_memory_profile():\n        \"\"\"Get memory profiling information.\"\"\"\n        if not MEMORY_PROFILER_AVAILABLE:\n            return {\"status\": \"memory_profiler_not_available\"}\n\n        try:\n            from enhanced_agent_bus.memory_profiler import get_memory_profiler\n\n            profiler = get_memory_profiler()\n            if not profiler:\n                return {\"status\": \"memory_profiling_disabled\"}\n\n            # Get current memory snapshot\n            snapshot = await profiler.take_snapshot(\"dashboard_request\")\n\n            return {\n                \"status\": \"active\",\n                \"current_mb\": round(snapshot.current_mb, 2),\n                \"peak_mb\": round(snapshot.peak_bytes / (1024 * 1024), 2),\n                \"timestamp\": snapshot.timestamp,\n                \"operation\": snapshot.operation or \"unknown\",\n            }\n        except Exception as e:\n            return {\"status\": \"error\", \"message\": str(e)}\n\n    @app.get(\"/dashboard/services\", response_model=List[ServiceHealth])\n    async def get_services(request: Request):\n        \"\"\"Get detailed service status.\"\"\"\n        return await request.app.state.dashboard_service.health_checker.check_all_services()\n\n    @app.websocket(\"/dashboard/ws\")\n    async def websocket_endpoint(websocket: WebSocket):\n        \"\"\"WebSocket endpoint for real-time updates.\"\"\"\n        await websocket.accept()\n        await websocket.app.state.dashboard_service.register_websocket(websocket)\n\n        try:\n            while True:\n                # Keep connection alive, handle incoming messages\n                data = await websocket.receive_text()\n                # Echo back for ping/pong\n                await websocket.send_text(data)\n        except WebSocketDisconnect:\n            await websocket.app.state.dashboard_service.unregister_websocket(websocket)\n\n    @app.get(\"/health\")\n    async def health_check():\n        \"\"\"Health check endpoint for the dashboard API itself.\"\"\"\n        return {\n            \"status\": \"healthy\",\n            \"service\": \"monitoring-dashboard\",\n            \"constitutional_hash\": CONSTITUTIONAL_HASH,\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n        }\n\n    return app\n\n\n# Create the app instance\napp = create_dashboard_app() if FASTAPI_AVAILABLE else None\n\n\n# ============================================================================\n# CLI Entry Point\n# ============================================================================\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    logging.basicConfig(\n        level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    )\n\n    uvicorn.run(\n        \"dashboard_api:app\",\n        host=\"0.0.0.0\",\n        port=8085,\n        reload=True,\n    )\n",
        "timestamp": "2026-01-03T19:07:31.669524"
      },
      "worktree_state": {
        "content": "\"\"\"\nACGS-2 Unified Monitoring Dashboard API\nConstitutional Hash: cdd01ef066bc6cf2\n\nProvides a unified REST API for the monitoring dashboard, aggregating:\n- Service health from HealthChecker\n- Circuit breaker health from HealthAggregator\n- Performance metrics from system monitors\n- Alert status from alerting module\n\nEndpoints:\n- GET /dashboard/overview - System overview with all key metrics\n- GET /dashboard/health - Aggregated health status\n- GET /dashboard/metrics - Performance metrics\n- GET /dashboard/alerts - Active alerts\n- GET /dashboard/services - Detailed service status\n- WebSocket /dashboard/ws - Real-time updates\n\"\"\"\n\nimport asyncio\nimport logging\nimport os\nimport sys\nimport time\nfrom collections import deque\nfrom datetime import datetime, timedelta, timezone\nfrom enum import Enum\nfrom typing import Any, Callable, Dict, List, Optional, Set\n\n# Add project root to path for imports\nsys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\ntry:\n    from contextlib import asynccontextmanager\n\n    from fastapi import FastAPI, HTTPException, Request, WebSocket, WebSocketDisconnect\n    from fastapi.middleware.cors import CORSMiddleware\n    from fastapi.responses import JSONResponse\n    from pydantic import BaseModel, Field\n\n    # Try to import memory profiler for integration\n    try:\n        import os\n        import sys\n\n        sys.path.insert(0, os.path.join(os.path.dirname(__file__), \"../../src/core\"))\n        from enhanced_agent_bus.memory_profiler import MemorySnapshot, get_memory_profiler\n\n        MEMORY_PROFILER_AVAILABLE = True\n    except ImportError:\n        MEMORY_PROFILER_AVAILABLE = False\n\n    # Import security headers middleware\n    try:\n        from shared.security import SecurityHeadersConfig, SecurityHeadersMiddleware\n\n        SECURITY_HEADERS_AVAILABLE = True\n    except ImportError:\n        SECURITY_HEADERS_AVAILABLE = False\n\n    FASTAPI_AVAILABLE = True\nexcept ImportError:\n    FASTAPI_AVAILABLE = False\n    FastAPI = None\n    WebSocket = None\n    # Provide fallback BaseModel for when pydantic is not available\n    from dataclasses import field as dataclass_field\n\n    class BaseModel:\n        \"\"\"Fallback BaseModel when pydantic is not available.\"\"\"\n\n        pass\n\n    def Field(default=None, default_factory=None, **kwargs):\n        \"\"\"Fallback Field when pydantic is not available.\"\"\"\n        if default_factory is not None:\n            return dataclass_field(default_factory=default_factory)\n        return default\n\n\ntry:\n    import psutil\n\n    PSUTIL_AVAILABLE = True\nexcept ImportError:\n    PSUTIL_AVAILABLE = False\n    psutil = None\n\ntry:\n    import redis.asyncio as redis\n\n    REDIS_AVAILABLE = True\nexcept ImportError:\n    REDIS_AVAILABLE = False\n    redis = None\n\n# Constitutional hash for governance compliance\nCONSTITUTIONAL_HASH = \"cdd01ef066bc6cf2\"\n\nlogger = logging.getLogger(__name__)\n\n\n# ============================================================================\n# Pydantic Models for API responses\n# ============================================================================\n\n\nclass ServiceHealthStatus(str, Enum):\n    \"\"\"Service health status.\"\"\"\n\n    HEALTHY = \"healthy\"\n    DEGRADED = \"degraded\"\n    UNHEALTHY = \"unhealthy\"\n    UNKNOWN = \"unknown\"\n\n\nclass AlertSeverity(str, Enum):\n    \"\"\"Alert severity levels.\"\"\"\n\n    CRITICAL = \"critical\"\n    ERROR = \"error\"\n    WARNING = \"warning\"\n    INFO = \"info\"\n\n\nclass ServiceHealth(BaseModel):\n    \"\"\"Individual service health model.\"\"\"\n\n    name: str\n    status: ServiceHealthStatus\n    response_time_ms: Optional[float] = None\n    last_check: datetime\n    error_message: Optional[str] = None\n    details: Dict[str, Any] = Field(default_factory=dict)\n\n\nclass SystemMetrics(BaseModel):\n    \"\"\"System performance metrics.\"\"\"\n\n    cpu_percent: float\n    memory_percent: float\n    memory_used_gb: float\n    memory_total_gb: float\n    disk_percent: float\n    disk_used_gb: float\n    disk_total_gb: float\n    network_bytes_sent: int\n    network_bytes_recv: int\n    process_count: int\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n\n\nclass PerformanceMetrics(BaseModel):\n    \"\"\"ACGS-2 performance metrics.\"\"\"\n\n    p99_latency_ms: float\n    throughput_rps: float\n    cache_hit_rate: float\n    constitutional_compliance: float = 100.0\n    active_connections: int = 0\n    requests_total: int = 0\n    errors_total: int = 0\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n\n\nclass AlertInfo(BaseModel):\n    \"\"\"Alert information.\"\"\"\n\n    alert_id: str\n    title: str\n    description: str\n    severity: AlertSeverity\n    source: str\n    status: str\n    timestamp: datetime\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n\n\nclass CircuitBreakerInfo(BaseModel):\n    \"\"\"Circuit breaker status.\"\"\"\n\n    name: str\n    state: str  # closed, open, half_open\n    fail_count: int = 0\n    success_count: int = 0\n    last_failure: Optional[datetime] = None\n\n\nclass DashboardOverview(BaseModel):\n    \"\"\"Complete dashboard overview response.\"\"\"\n\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n\n    # Overall health\n    overall_status: ServiceHealthStatus\n    health_score: float  # 0.0 - 1.0\n\n    # Service summary\n    total_services: int\n    healthy_services: int\n    degraded_services: int\n    unhealthy_services: int\n\n    # Circuit breaker summary\n    total_circuit_breakers: int\n    closed_breakers: int\n    open_breakers: int\n    half_open_breakers: int\n\n    # Performance summary\n    p99_latency_ms: float\n    throughput_rps: float\n    cache_hit_rate: float\n\n    # System resources\n    cpu_percent: float\n    memory_percent: float\n    disk_percent: float\n\n    # Alerts summary\n    critical_alerts: int\n    warning_alerts: int\n    total_alerts: int\n\n\nclass HealthAggregateResponse(BaseModel):\n    \"\"\"Aggregated health response.\"\"\"\n\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n    overall_status: ServiceHealthStatus\n    health_score: float\n    services: List[ServiceHealth]\n    circuit_breakers: List[CircuitBreakerInfo]\n\n\nclass MetricsResponse(BaseModel):\n    \"\"\"Metrics response.\"\"\"\n\n    constitutional_hash: str = CONSTITUTIONAL_HASH\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))\n    system: SystemMetrics\n    performance: PerformanceMetrics\n    history: List[Dict[str, Any]] = Field(default_factory=list)\n\n\n# ============================================================================\n# Metrics Collector\n# ============================================================================\n\n\nclass MetricsCollector:\n    \"\"\"Collects system and application metrics.\"\"\"\n\n    def __init__(self, history_size: int = 300):\n        self.history_size = history_size\n        self.metrics_history: deque = deque(maxlen=history_size)\n        self._redis_client: Optional[Any] = None\n        self._running = False\n        self._collection_task: Optional[asyncio.Task] = None\n\n    async def start(self, collection_interval: float = 1.0) -> None:\n        \"\"\"Start metrics collection.\"\"\"\n        if self._running:\n            return\n\n        self._running = True\n\n        # Try to connect to Redis for metrics storage\n        if REDIS_AVAILABLE:\n            try:\n                redis_url = os.environ.get(\"REDIS_URL\", \"redis://localhost:6379\")\n                self._redis_client = redis.from_url(redis_url)\n                await self._redis_client.ping()\n                logger.info(f\"[{CONSTITUTIONAL_HASH}] Connected to Redis for metrics\")\n            except Exception as e:\n                logger.warning(f\"Redis connection failed: {e}, using in-memory storage\")\n                self._redis_client = None\n\n        self._collection_task = asyncio.create_task(self._collection_loop(collection_interval))\n        logger.info(f\"[{CONSTITUTIONAL_HASH}] MetricsCollector started\")\n\n    async def stop(self) -> None:\n        \"\"\"Stop metrics collection.\"\"\"\n        self._running = False\n        if self._collection_task:\n            self._collection_task.cancel()\n            try:\n                await self._collection_task\n            except asyncio.CancelledError:\n                pass\n\n        if self._redis_client:\n            await self._redis_client.close()\n\n        logger.info(f\"[{CONSTITUTIONAL_HASH}] MetricsCollector stopped\")\n\n    async def _collection_loop(self, interval: float) -> None:\n        \"\"\"Background loop for metrics collection.\"\"\"\n        while self._running:\n            try:\n                metrics = await self.collect_metrics()\n                self.metrics_history.append(metrics)\n\n                # Store in Redis if available\n                if self._redis_client:\n                    try:\n                        await self._redis_client.lpush(\n                            \"acgs2:metrics:history\", metrics[\"timestamp\"].isoformat()\n                        )\n                        await self._redis_client.ltrim(\"acgs2:metrics:history\", 0, 299)\n                    except Exception:\n                        pass\n\n                await asyncio.sleep(interval)\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Metrics collection error: {e}\")\n                await asyncio.sleep(interval)\n\n    async def collect_metrics(self) -> Dict[str, Any]:\n        \"\"\"Collect current metrics.\"\"\"\n        timestamp = datetime.now(timezone.utc)\n\n        # System metrics\n        system_metrics = self._collect_system_metrics()\n\n        # Performance metrics (from Redis or defaults)\n        performance_metrics = await self._collect_performance_metrics()\n\n        return {\n            \"timestamp\": timestamp,\n            \"system\": system_metrics,\n            \"performance\": performance_metrics,\n            \"constitutional_hash\": CONSTITUTIONAL_HASH,\n        }\n\n    def _collect_system_metrics(self) -> Dict[str, Any]:\n        \"\"\"Collect system resource metrics.\"\"\"\n        if not PSUTIL_AVAILABLE:\n            return {\n                \"cpu_percent\": 0.0,\n                \"memory_percent\": 0.0,\n                \"memory_used_gb\": 0.0,\n                \"memory_total_gb\": 0.0,\n                \"disk_percent\": 0.0,\n                \"disk_used_gb\": 0.0,\n                \"disk_total_gb\": 0.0,\n                \"network_bytes_sent\": 0,\n                \"network_bytes_recv\": 0,\n                \"process_count\": 0,\n            }\n\n        memory = psutil.virtual_memory()\n        disk = psutil.disk_usage(\"/\")\n        # Defensive: net_io_counters() can return None in some environments (containers, etc.)\n        network = psutil.net_io_counters()\n        network_bytes_sent = network.bytes_sent if network else 0\n        network_bytes_recv = network.bytes_recv if network else 0\n\n        return {\n            \"cpu_percent\": psutil.cpu_percent(interval=None),\n            \"memory_percent\": memory.percent,\n            \"memory_used_gb\": round(memory.used / (1024**3), 2),\n            \"memory_total_gb\": round(memory.total / (1024**3), 2),\n            \"disk_percent\": disk.percent,\n            \"disk_used_gb\": round(disk.used / (1024**3), 2),\n            \"disk_total_gb\": round(disk.total / (1024**3), 2),\n            \"network_bytes_sent\": network_bytes_sent,\n            \"network_bytes_recv\": network_bytes_recv,\n            \"process_count\": len(psutil.pids()),\n        }\n\n    async def _collect_performance_metrics(self) -> Dict[str, Any]:\n        \"\"\"Collect application performance metrics.\"\"\"\n        defaults = {\n            \"p99_latency_ms\": 0.278,  # Current achieved P99\n            \"throughput_rps\": 6310.0,  # Current achieved RPS\n            \"cache_hit_rate\": 0.95,\n            \"constitutional_compliance\": 100.0,\n            \"active_connections\": 0,\n            \"requests_total\": 0,\n            \"errors_total\": 0,\n        }\n\n        if self._redis_client:\n            try:\n                # Try to get actual metrics from Redis\n                p99 = await self._redis_client.get(\"acgs2:metrics:p99_latency\")\n                rps = await self._redis_client.get(\"acgs2:metrics:throughput_rps\")\n                cache_hit = await self._redis_client.get(\"acgs2:metrics:cache_hit_rate\")\n\n                if p99:\n                    defaults[\"p99_latency_ms\"] = float(p99)\n                if rps:\n                    defaults[\"throughput_rps\"] = float(rps)\n                if cache_hit:\n                    defaults[\"cache_hit_rate\"] = float(cache_hit)\n            except Exception:\n                pass\n\n        return defaults\n\n    def get_history(self, minutes: int = 5) -> List[Dict[str, Any]]:\n        \"\"\"Get metrics history for the last N minutes.\"\"\"\n        cutoff = datetime.now(timezone.utc) - timedelta(minutes=minutes)\n        return [\n            m\n            for m in self.metrics_history\n            if m.get(\"timestamp\", datetime.min.replace(tzinfo=timezone.utc)) >= cutoff\n        ]\n\n\n# ============================================================================\n# Service Health Checker\n# ============================================================================\n\n\nclass ServiceHealthChecker:\n    \"\"\"Checks health of ACGS-2 services.\"\"\"\n\n    def __init__(self):\n        self.services = {\n            \"enhanced-agent-bus\": os.environ.get(\"AGENT_BUS_URL\", \"http://localhost:8000\")\n            + \"/health\",\n            \"policy-registry\": os.environ.get(\"POLICY_REGISTRY_URL\", \"http://localhost:8000\")\n            + \"/health\",\n            \"constitutional-ai\": os.environ.get(\"CONSTITUTIONAL_AI_URL\", \"http://localhost:8001\")\n            + \"/health\",\n            \"audit-service\": os.environ.get(\"AUDIT_SERVICE_URL\", \"http://localhost:8003\")\n            + \"/health\",\n        }\n        self._health_cache: Dict[str, ServiceHealth] = {}\n        self._cache_ttl = 5  # seconds\n        self._last_check: Dict[str, datetime] = {}\n\n    async def check_service(self, name: str, url: str) -> ServiceHealth:\n        \"\"\"Check health of a single service.\"\"\"\n        import aiohttp\n\n        start_time = time.time()\n\n        try:\n            timeout = aiohttp.ClientTimeout(total=5)\n            async with aiohttp.ClientSession(timeout=timeout) as session:\n                async with session.get(url) as response:\n                    response_time = (time.time() - start_time) * 1000\n\n                    if response.status == 200:\n                        try:\n                            details = await response.json()\n                        except Exception:\n                            details = {\"raw\": await response.text()}\n\n                        return ServiceHealth(\n                            name=name,\n                            status=ServiceHealthStatus.HEALTHY,\n                            response_time_ms=response_time,\n                            last_check=datetime.now(timezone.utc),\n                            details=details,\n                        )\n                    else:\n                        return ServiceHealth(\n                            name=name,\n                            status=ServiceHealthStatus.UNHEALTHY,\n                            response_time_ms=response_time,\n                            last_check=datetime.now(timezone.utc),\n                            error_message=f\"HTTP {response.status}\",\n                        )\n        except asyncio.TimeoutError:\n            return ServiceHealth(\n                name=name,\n                status=ServiceHealthStatus.UNHEALTHY,\n                response_time_ms=(time.time() - start_time) * 1000,\n                last_check=datetime.now(timezone.utc),\n                error_message=\"Timeout\",\n            )\n        except Exception as e:\n            return ServiceHealth(\n                name=name,\n                status=ServiceHealthStatus.UNKNOWN,\n                response_time_ms=(time.time() - start_time) * 1000,\n                last_check=datetime.now(timezone.utc),\n                error_message=str(e),\n            )\n\n    async def check_all_services(self) -> List[ServiceHealth]:\n        \"\"\"Check health of all registered services.\"\"\"\n        tasks = [self.check_service(name, url) for name, url in self.services.items()]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        service_health = []\n        for i, result in enumerate(results):\n            if isinstance(result, Exception):\n                name = list(self.services.keys())[i]\n                service_health.append(\n                    ServiceHealth(\n                        name=name,\n                        status=ServiceHealthStatus.UNKNOWN,\n                        last_check=datetime.now(timezone.utc),\n                        error_message=str(result),\n                    )\n                )\n            else:\n                service_health.append(result)\n\n        return service_health\n\n\n# ============================================================================\n# Alert Manager\n# ============================================================================\n\n\nclass AlertManager:\n    \"\"\"Manages alerts for the dashboard.\"\"\"\n\n    def __init__(self):\n        self.alerts: Dict[str, AlertInfo] = {}\n        self._alert_callbacks: List[Callable[[AlertInfo], None]] = []\n\n    def add_alert(self, alert: AlertInfo) -> None:\n        \"\"\"Add a new alert.\"\"\"\n        self.alerts[alert.alert_id] = alert\n        for callback in self._alert_callbacks:\n            try:\n                callback(alert)\n            except Exception as e:\n                logger.error(f\"Alert callback error: {e}\")\n\n    def resolve_alert(self, alert_id: str) -> bool:\n        \"\"\"Resolve an alert by ID.\"\"\"\n        if alert_id in self.alerts:\n            del self.alerts[alert_id]\n            return True\n        return False\n\n    def get_active_alerts(self) -> List[AlertInfo]:\n        \"\"\"Get all active alerts.\"\"\"\n        return list(self.alerts.values())\n\n    def get_alerts_by_severity(self, severity: AlertSeverity) -> List[AlertInfo]:\n        \"\"\"Get alerts by severity.\"\"\"\n        return [a for a in self.alerts.values() if a.severity == severity]\n\n    def on_alert(self, callback: Callable[[AlertInfo], None]) -> None:\n        \"\"\"Register alert callback.\"\"\"\n        self._alert_callbacks.append(callback)\n\n\n# ============================================================================\n# Dashboard Service\n# ============================================================================\n\n\nclass DashboardService:\n    \"\"\"Main dashboard service orchestrating all monitoring components.\"\"\"\n\n    def __init__(self):\n        self.metrics_collector = MetricsCollector()\n        self.health_checker = ServiceHealthChecker()\n        self.alert_manager = AlertManager()\n        self._websocket_clients: Set[WebSocket] = set()\n        self._broadcast_task: Optional[asyncio.Task] = None\n        self._running = False\n\n    async def start(self) -> None:\n        \"\"\"Start the dashboard service.\"\"\"\n        if self._running:\n            return\n\n        self._running = True\n        await self.metrics_collector.start()\n        self._broadcast_task = asyncio.create_task(self._broadcast_loop())\n        logger.info(f\"[{CONSTITUTIONAL_HASH}] DashboardService started\")\n\n    async def stop(self) -> None:\n        \"\"\"Stop the dashboard service.\"\"\"\n        self._running = False\n        await self.metrics_collector.stop()\n\n        if self._broadcast_task:\n            self._broadcast_task.cancel()\n            try:\n                await self._broadcast_task\n            except asyncio.CancelledError:\n                pass\n\n        # Close all websocket connections\n        for ws in list(self._websocket_clients):\n            try:\n                await ws.close()\n            except Exception:\n                pass\n\n        logger.info(f\"[{CONSTITUTIONAL_HASH}] DashboardService stopped\")\n\n    async def get_overview(self) -> DashboardOverview:\n        \"\"\"Get complete dashboard overview.\"\"\"\n        # Get service health\n        services = await self.health_checker.check_all_services()\n        healthy = sum(1 for s in services if s.status == ServiceHealthStatus.HEALTHY)\n        degraded = sum(1 for s in services if s.status == ServiceHealthStatus.DEGRADED)\n        unhealthy = sum(1 for s in services if s.status == ServiceHealthStatus.UNHEALTHY)\n\n        # Calculate health score\n        if services:\n            health_score = (healthy + degraded * 0.5) / len(services)\n        else:\n            health_score = 1.0\n\n        # Determine overall status\n        if unhealthy > len(services) / 2:\n            overall_status = ServiceHealthStatus.UNHEALTHY\n        elif unhealthy > 0 or degraded > 0:\n            overall_status = ServiceHealthStatus.DEGRADED\n        else:\n            overall_status = ServiceHealthStatus.HEALTHY\n\n        # Get metrics\n        metrics = await self.metrics_collector.collect_metrics()\n        system = metrics[\"system\"]\n        performance = metrics[\"performance\"]\n\n        # Get alerts\n        alerts = self.alert_manager.get_active_alerts()\n        critical_alerts = len([a for a in alerts if a.severity == AlertSeverity.CRITICAL])\n        warning_alerts = len([a for a in alerts if a.severity == AlertSeverity.WARNING])\n\n        return DashboardOverview(\n            overall_status=overall_status,\n            health_score=round(health_score, 3),\n            total_services=len(services),\n            healthy_services=healthy,\n            degraded_services=degraded,\n            unhealthy_services=unhealthy,\n            total_circuit_breakers=0,  # Will be populated from HealthAggregator\n            closed_breakers=0,\n            open_breakers=0,\n            half_open_breakers=0,\n            p99_latency_ms=performance[\"p99_latency_ms\"],\n            throughput_rps=performance[\"throughput_rps\"],\n            cache_hit_rate=performance[\"cache_hit_rate\"],\n            cpu_percent=system[\"cpu_percent\"],\n            memory_percent=system[\"memory_percent\"],\n            disk_percent=system[\"disk_percent\"],\n            critical_alerts=critical_alerts,\n            warning_alerts=warning_alerts,\n            total_alerts=len(alerts),\n        )\n\n    async def get_health(self) -> HealthAggregateResponse:\n        \"\"\"Get aggregated health status.\"\"\"\n        services = await self.health_checker.check_all_services()\n\n        # Calculate overall\n        if not services:\n            overall_status = ServiceHealthStatus.UNKNOWN\n            health_score = 0.0\n        else:\n            healthy = sum(1 for s in services if s.status == ServiceHealthStatus.HEALTHY)\n            health_score = healthy / len(services)\n\n            if health_score >= 0.9:\n                overall_status = ServiceHealthStatus.HEALTHY\n            elif health_score >= 0.5:\n                overall_status = ServiceHealthStatus.DEGRADED\n            else:\n                overall_status = ServiceHealthStatus.UNHEALTHY\n\n        return HealthAggregateResponse(\n            overall_status=overall_status,\n            health_score=round(health_score, 3),\n            services=services,\n            circuit_breakers=[],  # Will be populated from HealthAggregator\n        )\n\n    async def get_metrics(self) -> MetricsResponse:\n        \"\"\"Get performance metrics.\"\"\"\n        metrics = await self.metrics_collector.collect_metrics()\n        history = self.metrics_collector.get_history(minutes=5)\n\n        return MetricsResponse(\n            system=SystemMetrics(**metrics[\"system\"]),\n            performance=PerformanceMetrics(**metrics[\"performance\"]),\n            history=history,\n        )\n\n    async def register_websocket(self, websocket: WebSocket) -> None:\n        \"\"\"Register a websocket client for real-time updates.\"\"\"\n        self._websocket_clients.add(websocket)\n\n    async def unregister_websocket(self, websocket: WebSocket) -> None:\n        \"\"\"Unregister a websocket client.\"\"\"\n        self._websocket_clients.discard(websocket)\n\n    async def _broadcast_loop(self) -> None:\n        \"\"\"Broadcast updates to all connected websocket clients.\"\"\"\n        while self._running:\n            try:\n                if self._websocket_clients:\n                    overview = await self.get_overview()\n                    message = overview.model_dump_json()\n\n                    for ws in list(self._websocket_clients):\n                        try:\n                            await ws.send_text(message)\n                        except Exception:\n                            self._websocket_clients.discard(ws)\n\n                await asyncio.sleep(1)  # Update every second\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Broadcast error: {e}\")\n                await asyncio.sleep(1)\n\n\n# ============================================================================\n# FastAPI Application\n# ============================================================================\n\n\ndef create_dashboard_app() -> FastAPI:\n    \"\"\"Create the FastAPI dashboard application.\"\"\"\n    if not FASTAPI_AVAILABLE:\n        raise RuntimeError(\"FastAPI not available. Install with: pip install fastapi uvicorn\")\n\n    @asynccontextmanager\n    async def lifespan(app: FastAPI):\n        \"\"\"Application lifespan context manager.\"\"\"\n        dashboard_service = DashboardService()\n        await dashboard_service.start()\n        app.state.dashboard_service = dashboard_service\n        yield\n        await dashboard_service.stop()\n\n    app = FastAPI(\n        title=\"ACGS-2 Monitoring Dashboard API\",\n        description=\"Unified monitoring dashboard for AI Constitutional Governance System\",\n        version=\"1.0.0\",\n        lifespan=lifespan,\n    )\n\n    # Configure CORS based on environment for security\n    cors_origins = os.getenv(\"CORS_ALLOWED_ORIGINS\", \"\").split(\",\")\n    if not cors_origins or cors_origins == [\"\"]:\n        # Default secure configuration - no external origins allowed\n        cors_origins = []\n\n    # Allow localhost for development (but not in production)\n    if os.getenv(\"ENVIRONMENT\", \"\").lower() == \"development\":\n        cors_origins.extend(\n            [\n                \"http://localhost:3000\",\n                \"http://localhost:8080\",\n                \"http://127.0.0.1:3000\",\n                \"http://127.0.0.1:8080\",\n            ]\n        )\n\n    # Add CORS middleware with secure configuration\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=cors_origins,\n        allow_credentials=True,\n        allow_methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"],\n        allow_headers=[\"Authorization\", \"Content-Type\", \"X-Correlation-ID\"],\n    )\n\n    # Add security headers middleware\n    # Configure for WebSocket service to allow ws:// and wss:// connections for /dashboard/ws endpoint\n    if SECURITY_HEADERS_AVAILABLE:\n        security_config = SecurityHeadersConfig.for_websocket_service()\n        app.add_middleware(SecurityHeadersMiddleware, config=security_config)\n        environment = os.getenv(\"ENVIRONMENT\", \"production\")\n        logger.info(\n            f\"[{CONSTITUTIONAL_HASH}] Security headers middleware configured for monitoring dashboard (environment: {environment})\"\n        )\n    else:\n        logger.warning(\n            f\"[{CONSTITUTIONAL_HASH}] Security headers middleware not available - install shared security module\"\n        )\n\n    @app.get(\"/dashboard/overview\", response_model=DashboardOverview)\n    async def get_overview(request: Request):\n        \"\"\"Get complete dashboard overview.\"\"\"\n        return await request.app.state.dashboard_service.get_overview()\n\n    @app.get(\"/dashboard/health\", response_model=HealthAggregateResponse)\n    async def get_health(request: Request):\n        \"\"\"Get aggregated health status.\"\"\"\n        return await request.app.state.dashboard_service.get_health()\n\n    @app.get(\"/dashboard/metrics\", response_model=MetricsResponse)\n    async def get_metrics(request: Request):\n        \"\"\"Get performance metrics.\"\"\"\n        return await request.app.state.dashboard_service.get_metrics()\n\n    @app.get(\"/dashboard/alerts\", response_model=List[AlertInfo])\n    async def get_alerts(request: Request):\n        \"\"\"Get active alerts.\"\"\"\n        return request.app.state.dashboard_service.alert_manager.get_active_alerts()\n\n    @app.get(\"/dashboard/memory\", response_model=Dict[str, Any])\n    async def get_memory_profile():\n        \"\"\"Get memory profiling information.\"\"\"\n        if not MEMORY_PROFILER_AVAILABLE:\n            return {\"status\": \"memory_profiler_not_available\"}\n\n        try:\n            from enhanced_agent_bus.memory_profiler import get_memory_profiler\n\n            profiler = get_memory_profiler()\n            if not profiler:\n                return {\"status\": \"memory_profiling_disabled\"}\n\n            # Get current memory snapshot\n            snapshot = await profiler.take_snapshot(\"dashboard_request\")\n\n            return {\n                \"status\": \"active\",\n                \"current_mb\": round(snapshot.current_mb, 2),\n                \"peak_mb\": round(snapshot.peak_bytes / (1024 * 1024), 2),\n                \"timestamp\": snapshot.timestamp,\n                \"operation\": snapshot.operation or \"unknown\",\n            }\n        except Exception as e:\n            return {\"status\": \"error\", \"message\": str(e)}\n\n    @app.get(\"/dashboard/services\", response_model=List[ServiceHealth])\n    async def get_services(request: Request):\n        \"\"\"Get detailed service status.\"\"\"\n        return await request.app.state.dashboard_service.health_checker.check_all_services()\n\n    @app.websocket(\"/dashboard/ws\")\n    async def websocket_endpoint(websocket: WebSocket):\n        \"\"\"WebSocket endpoint for real-time updates.\"\"\"\n        await websocket.accept()\n        await websocket.app.state.dashboard_service.register_websocket(websocket)\n\n        try:\n            while True:\n                # Keep connection alive, handle incoming messages\n                data = await websocket.receive_text()\n                # Echo back for ping/pong\n                await websocket.send_text(data)\n        except WebSocketDisconnect:\n            await websocket.app.state.dashboard_service.unregister_websocket(websocket)\n\n    @app.get(\"/health\")\n    async def health_check():\n        \"\"\"Health check endpoint for the dashboard API itself.\"\"\"\n        return {\n            \"status\": \"healthy\",\n            \"service\": \"monitoring-dashboard\",\n            \"constitutional_hash\": CONSTITUTIONAL_HASH,\n            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n        }\n\n    return app\n\n\n# Create the app instance\napp = create_dashboard_app() if FASTAPI_AVAILABLE else None\n\n\n# ============================================================================\n# CLI Entry Point\n# ============================================================================\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    logging.basicConfig(\n        level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    )\n\n    uvicorn.run(\n        \"dashboard_api:app\",\n        host=\"0.0.0.0\",\n        port=8085,\n        reload=True,\n    )\n",
        "last_modified": "2026-01-03T19:08:32.490196"
      },
      "task_intent": {
        "title": "046-add-security-headers-middleware-to-fastapi-service",
        "description": "Multiple FastAPI services (integration-service, compliance-docs, observability dashboard) lack security headers middleware. Missing headers include Content-Security-Policy, X-Content-Type-Options, X-Frame-Options, Strict-Transport-Security, X-XSS-Protection, and Referrer-Policy.",
        "from_plan": true
      },
      "commits_behind_main": 11,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:07:31.774753",
  "last_updated": "2026-01-03T19:07:31.777902"
}