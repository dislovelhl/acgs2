{
  "file_path": "acgs2-core/services/audit_service/app/api/governance.py",
  "main_branch_history": [],
  "task_views": {
    "060-document-error-codes-and-troubleshooting-for-commo": {
      "task_id": "060-document-error-codes-and-troubleshooting-for-commo",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "\"\"\"\nGovernance KPI and Trend Analysis API Endpoints\n\nProvides executive dashboard endpoints for governance metrics,\ncompliance scores, and trend analysis.\n\nConstitutional Hash: cdd01ef066bc6cf2\n\"\"\"\n\nimport logging\nfrom datetime import date, datetime, timedelta, timezone\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, HTTPException, Query\n\nfrom ..models.governance_metrics import (\n    GovernanceKPIs,\n    GovernanceTrendPoint,\n    GovernanceTrends,\n    TrendDirection,\n)\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter()\n\n\n# Constants for data freshness check\nDATA_STALE_THRESHOLD_DAYS = 7\n\n\nasync def _calculate_kpis_from_ledger(tenant_id: str) -> Dict[str, Any]:\n    \"\"\"\n    Calculate governance KPIs from audit ledger data.\n\n    This is a placeholder implementation that returns sample data.\n    In production, this would query the audit ledger or metrics database.\n    \"\"\"\n    # TODO: Integrate with audit_ledger to calculate real metrics\n    # For now, return sample data for API verification\n    return {\n        \"compliance_score\": 87.5,\n        \"controls_passing\": 42,\n        \"controls_failing\": 6,\n        \"controls_total\": 48,\n        \"recent_audits\": 12,\n        \"high_risk_incidents\": 2,\n        \"last_updated\": datetime.now(timezone.utc),\n        \"data_stale\": False,\n    }\n\n\nasync def _calculate_trend(\n    current_score: float, previous_score: float, threshold: float = 2.0\n) -> tuple[TrendDirection, float]:\n    \"\"\"\n    Calculate trend direction based on score change.\n\n    Args:\n        current_score: Current compliance score\n        previous_score: Previous period compliance score\n        threshold: Minimum change to be considered improving/declining\n\n    Returns:\n        Tuple of (trend_direction, change_percent)\n    \"\"\"\n    if previous_score == 0:\n        return TrendDirection.STABLE, 0.0\n\n    change_percent = ((current_score - previous_score) / previous_score) * 100\n\n    if change_percent > threshold:\n        return TrendDirection.IMPROVING, change_percent\n    elif change_percent < -threshold:\n        return TrendDirection.DECLINING, change_percent\n    else:\n        return TrendDirection.STABLE, change_percent\n\n\n@router.get(\"/kpis\", response_model=Dict[str, Any])\nasync def get_governance_kpis(\n    tenant_id: Optional[str] = Query(\n        default=\"default\",\n        description=\"Tenant identifier for multi-tenant deployments\",\n    ),\n) -> Dict[str, Any]:\n    \"\"\"\n    Get current governance KPIs for executive dashboard.\n\n    Returns real-time compliance metrics including:\n    - Overall compliance score (0-100)\n    - Number of passing and failing controls\n    - Recent audit count (last 30 days)\n    - High-risk incident count\n    - Trend direction (improving, stable, declining)\n    - Data freshness warning if data is stale\n\n    Executive and Compliance Officer roles have access to this endpoint.\n    \"\"\"\n    try:\n        # Calculate KPIs from ledger data\n        kpi_data = await _calculate_kpis_from_ledger(tenant_id)\n\n        # Calculate trend from historical data\n        # For now, assume previous score was 85.0 for trend calculation\n        previous_score = 85.0\n        trend_direction, trend_change = await _calculate_trend(\n            kpi_data[\"compliance_score\"], previous_score\n        )\n\n        # Check data freshness\n        data_stale = kpi_data.get(\"data_stale\", False)\n        last_updated = kpi_data.get(\"last_updated\", datetime.now(timezone.utc))\n\n        # Build KPIs response using the model\n        kpis = GovernanceKPIs(\n            tenant_id=tenant_id,\n            compliance_score=kpi_data[\"compliance_score\"],\n            controls_passing=kpi_data[\"controls_passing\"],\n            controls_failing=kpi_data[\"controls_failing\"],\n            controls_total=kpi_data[\"controls_total\"],\n            recent_audits=kpi_data[\"recent_audits\"],\n            high_risk_incidents=kpi_data[\"high_risk_incidents\"],\n            trend_direction=trend_direction,\n            trend_change_percent=round(trend_change, 2),\n            last_updated=last_updated,\n            data_stale_warning=data_stale,\n        )\n\n        return kpis.to_dict()\n\n    except Exception as e:\n        logger.error(f\"Failed to calculate governance KPIs: {e}\")\n        raise HTTPException(\n            status_code=500,\n            detail=\"Failed to retrieve governance KPIs. Please try again later.\",\n        ) from None\n\n\n@router.get(\"/trends\", response_model=Dict[str, Any])\nasync def get_governance_trends(\n    days: int = Query(\n        default=90,\n        ge=1,\n        le=365,\n        description=\"Number of days of trend data to retrieve\",\n    ),\n    tenant_id: Optional[str] = Query(\n        default=\"default\",\n        description=\"Tenant identifier for multi-tenant deployments\",\n    ),\n) -> Dict[str, Any]:\n    \"\"\"\n    Get historical trend data for governance dashboard charts.\n\n    Returns time-series data for specified period including:\n    - Daily compliance scores\n    - Control counts (passing/failing/total)\n    - Period statistics (min, max, average)\n    - Trend direction and slope\n\n    Supports 30, 60, 90 day analysis periods.\n    Executive and Compliance Officer roles have access to this endpoint.\n    \"\"\"\n    try:\n        # Calculate date range\n        end_date = date.today()\n        start_date = end_date - timedelta(days=days)\n\n        # TODO: Integrate with audit_ledger/metrics database for real data\n        # For now, generate sample trend data for API verification\n        data_points = []\n        base_score = 82.0\n        score_increment = 0.1  # Slight improvement trend\n\n        for i in range(days):\n            point_date = start_date + timedelta(days=i)\n            # Simulate some variance in scores\n            variance = (i % 7) * 0.3 - 1.0\n            score = min(100.0, max(0.0, base_score + (i * score_increment) + variance))\n\n            data_points.append(\n                GovernanceTrendPoint(\n                    date=point_date,\n                    compliance_score=round(score, 2),\n                    controls_passing=40 + (i // 10),\n                    controls_failing=8 - (i // 15),\n                    controls_total=48 + (i // 10) - (i // 15),\n                    audit_count=i // 7,  # Roughly weekly audits\n                )\n            )\n\n        # Calculate aggregate statistics\n        scores = [dp.compliance_score for dp in data_points]\n        avg_score = sum(scores) / len(scores) if scores else 0.0\n        min_score = min(scores) if scores else 0.0\n        max_score = max(scores) if scores else 0.0\n\n        # Calculate trend slope (simple linear approximation)\n        if len(scores) >= 2:\n            slope = (scores[-1] - scores[0]) / len(scores)\n        else:\n            slope = 0.0\n\n        # Determine trend direction based on slope\n        if slope > 0.05:\n            trend_direction = TrendDirection.IMPROVING\n        elif slope < -0.05:\n            trend_direction = TrendDirection.DECLINING\n        else:\n            trend_direction = TrendDirection.STABLE\n\n        # Build trends response using the model\n        trends = GovernanceTrends(\n            tenant_id=tenant_id,\n            days=days,\n            data_points=data_points,\n            period_start=start_date,\n            period_end=end_date,\n            avg_compliance_score=round(avg_score, 2),\n            min_compliance_score=round(min_score, 2),\n            max_compliance_score=round(max_score, 2),\n            trend_direction=trend_direction,\n            trend_slope=round(slope, 4),\n        )\n\n        return trends.to_dict()\n\n    except Exception as e:\n        logger.error(f\"Failed to calculate governance trends: {e}\")\n        raise HTTPException(\n            status_code=500,\n            detail=\"Failed to retrieve governance trends. Please try again later.\",\n        ) from None\n\n\n@router.get(\"/health\", response_model=Dict[str, Any])\nasync def governance_health() -> Dict[str, Any]:\n    \"\"\"\n    Health check for governance API.\n\n    Returns service status and data availability information.\n    \"\"\"\n    return {\n        \"status\": \"healthy\",\n        \"api\": \"governance\",\n        \"version\": \"1.0.0\",\n        \"endpoints\": [\"/kpis\", \"/trends\", \"/health\"],\n        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n    }\n",
        "timestamp": "2026-01-04T05:35:51.134105"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "060-document-error-codes-and-troubleshooting-for-commo",
        "description": "The codebase has 13 TODO/FIXME comments across critical files including webhooks.py, approval_chain_engine.py, and config_validator.py. Additionally, there's no centralized documentation for error codes, failure modes, or troubleshooting guides. Users encountering errors have no reference for resolution.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:08.617813",
  "last_updated": "2026-01-04T05:35:51.156438"
}