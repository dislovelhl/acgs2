{
  "file_path": "./examples/04-end-to-end-governance-workflow/src/governance_workflow.py",
  "main_branch_history": [],
  "task_views": {
    "061-create-end-to-end-governance-workflow-examples-wit": {
      "task_id": "061-create-end-to-end-governance-workflow-examples-wit",
      "branch_point": {
        "commit_hash": "fc6e42927298263034acf989773f3200e422ad17",
        "content": "#!/usr/bin/env python3\n\"\"\"\nGovernance Workflow Orchestrator for ACGS-2\n\nMain orchestrator that coordinates the complete end-to-end governance workflow:\n1. Constitutional validation (constitutional.rego)\n2. Action evaluation and risk assessment (agent_actions.rego)\n3. HITL determination (hitl_approval.rego)\n4. Human approval workflow (if required)\n5. Audit logging (audit.rego + PostgreSQL)\n6. Final decision response\n\nThis module integrates OPAClient, AuditLogger, and HITLHandler to provide\na complete governance decision-making pipeline.\n\nUsage:\n    from src.governance_workflow import GovernanceWorkflow, GovernanceDecision\n    from src.opa_client import OPAClient, OPAConfig\n    from src.audit_logger import AuditLogger, DatabaseConfig\n    from src.hitl_handler import HITLHandler, HITLConfig\n\n    # Initialize components\n    opa = OPAClient(OPAConfig(url=\"http://localhost:8181\"))\n    audit = AuditLogger(DatabaseConfig(password=\"secret\"))\n    hitl = HITLHandler(HITLConfig())\n\n    # Create workflow orchestrator\n    workflow = GovernanceWorkflow(opa, audit, hitl)\n\n    # Evaluate an action\n    decision = workflow.evaluate_action({\n        \"action\": {\"type\": \"deploy_model\", \"resource\": \"prod/model-v2\"},\n        \"requester\": {\"id\": \"agent-001\", \"type\": \"ai_agent\"},\n        \"context\": {\"environment\": \"production\"}\n    })\n\n    print(f\"Decision: {decision.decision}\")\n    print(f\"Audit ID: {decision.audit_id}\")\n\nConstitutional Hash: cdd01ef066bc6cf2\n\"\"\"\n\nimport logging\nimport time\nfrom dataclasses import dataclass\nfrom datetime import UTC, datetime\nfrom uuid import UUID\n\nfrom src.audit_logger import AuditEntry, AuditLogger\nfrom src.hitl_handler import HITLHandler\nfrom src.opa_client import OPAClient, OPAConnectionError, OPAPolicyError\n\n# Configure logging\nlogger = logging.getLogger(__name__)\n\n\n# Custom exceptions for governance workflow errors\nclass GovernanceWorkflowError(Exception):\n    \"\"\"Base exception for governance workflow errors\"\"\"\n\n    pass\n\n\nclass GovernanceValidationError(GovernanceWorkflowError):\n    \"\"\"Raised when validation fails\"\"\"\n\n    pass\n\n\nclass GovernanceEvaluationError(GovernanceWorkflowError):\n    \"\"\"Raised when policy evaluation fails\"\"\"\n\n    pass\n\n\n@dataclass\nclass GovernanceDecision:\n    \"\"\"\n    Final governance decision response.\n\n    This dataclass encapsulates the complete decision result including\n    risk assessment, HITL workflow details, audit trail reference,\n    and denial reasons (if applicable).\n    \"\"\"\n\n    # Final decision\n    decision: str  # \"allow\" or \"deny\"\n    audit_id: UUID  # Reference to audit log entry\n\n    # Risk assessment details\n    risk_assessment: dict  # Full risk evaluation from agent_actions.rego\n    risk_score: float  # Calculated risk score (0.0-1.0)\n    risk_category: str  # Risk category (low, medium, high, critical)\n\n    # Constitutional validation\n    constitutional_valid: bool  # Whether action passed constitutional validation\n    constitutional_violations: list[str]  # List of violated principles\n\n    # HITL workflow details\n    hitl_required: bool  # Whether HITL approval was required\n    hitl_workflow: dict | None  # HITL workflow details (if applicable)\n\n    # Decision metadata\n    denial_reasons: list[str]  # Reasons for denial (if denied)\n    processing_time_ms: float  # Total processing time in milliseconds\n    metadata: dict  # Additional metadata and context\n\n    def to_dict(self) -> dict:\n        \"\"\"Convert decision to dictionary for JSON serialization\"\"\"\n        return {\n            \"decision\": self.decision,\n            \"audit_id\": str(self.audit_id),\n            \"risk_assessment\": {\n                \"risk_score\": self.risk_score,\n                \"risk_category\": self.risk_category,\n                \"details\": self.risk_assessment,\n            },\n            \"constitutional\": {\n                \"valid\": self.constitutional_valid,\n                \"violations\": self.constitutional_violations,\n            },\n            \"hitl\": {\n                \"required\": self.hitl_required,\n                \"workflow\": self.hitl_workflow,\n            },\n            \"denial_reasons\": self.denial_reasons,\n            \"processing_time_ms\": self.processing_time_ms,\n            \"metadata\": self.metadata,\n        }\n\n\nclass GovernanceWorkflow:\n    \"\"\"\n    Orchestrates the complete end-to-end governance workflow.\n\n    This class coordinates policy evaluation, HITL approvals, and audit logging\n    to provide comprehensive governance decision-making for AI agent actions.\n\n    The workflow consists of 6 steps:\n    1. Constitutional validation - Verify action complies with constitutional principles\n    2. Action evaluation - Assess risk and determine if action is allowed\n    3. HITL determination - Check if human approval is required\n    4. Approval handling - Process HITL workflow if needed\n    5. Audit logging - Record decision to immutable audit trail\n    6. Decision response - Return final decision with full context\n\n    Attributes:\n        opa: OPAClient instance for policy evaluation\n        audit: AuditLogger instance for audit trail logging\n        hitl: HITLHandler instance for human approval workflow\n    \"\"\"\n\n    def __init__(\n        self,\n        opa_client: OPAClient,\n        audit_logger: AuditLogger,\n        hitl_handler: HITLHandler,\n    ):\n        \"\"\"\n        Initialize governance workflow orchestrator.\n\n        Args:\n            opa_client: OPAClient instance for policy evaluation\n            audit_logger: AuditLogger instance for audit logging\n            hitl_handler: HITLHandler instance for HITL workflow\n\n        Raises:\n            ValueError: If any required component is None\n        \"\"\"\n        if opa_client is None:\n            raise ValueError(\"opa_client is required\")\n        if audit_logger is None:\n            raise ValueError(\"audit_logger is required\")\n        if hitl_handler is None:\n            raise ValueError(\"hitl_handler is required\")\n\n        self.opa = opa_client\n        self.audit = audit_logger\n        self.hitl = hitl_handler\n\n        logger.info(\"Governance workflow orchestrator initialized\")\n\n    def evaluate_action(self, action_request: dict) -> GovernanceDecision:\n        \"\"\"\n        Main entry point: evaluate an action through the full governance workflow.\n\n        This method orchestrates the complete workflow from constitutional validation\n        through final decision and audit logging. It handles all error cases and\n        ensures consistent logging regardless of the decision path.\n\n        Args:\n            action_request: Complete action request with structure:\n                {\n                    \"action\": {\"type\": \"...\", \"resource\": \"...\", \"parameters\": {}},\n                    \"requester\": {\"id\": \"...\", \"type\": \"...\", \"role\": \"...\"},\n                    \"context\": {\"environment\": \"...\", \"constitutional_hash\": \"...\"}\n                }\n\n        Returns:\n            GovernanceDecision with complete decision details\n\n        Raises:\n            GovernanceWorkflowError: If workflow execution fails\n        \"\"\"\n        start_time = time.time()\n        logger.info(\n            f\"Evaluating action: {action_request.get('action', {}).get('type', 'unknown')}\"\n        )\n\n        # Initialize tracking variables\n        constitutional_valid = False\n        constitutional_violations = []\n        action_allowed = False\n        risk_score = 0.0\n        risk_assessment = {}\n        hitl_required = False\n        hitl_info = {}\n        hitl_workflow_result = None\n        denial_reasons = []\n        final_decision = \"deny\"  # Default deny\n\n        try:\n            # Step 1: Validate constitutional compliance\n            logger.debug(\"Step 1: Validating constitutional compliance\")\n            constitutional_valid, constitutional_violations = self._validate_constitution(\n                action_request\n            )\n\n            if not constitutional_valid:\n                # Early exit: Constitutional violation\n                denial_reasons.extend(constitutional_violations)\n                logger.warning(\n                    f\"Constitutional validation failed: {len(constitutional_violations)} violations\"\n                )\n            else:\n                # Step 2: Evaluate action and assess risk\n                logger.debug(\"Step 2: Evaluating action and assessing risk\")\n                action_allowed, risk_score, risk_assessment = self._evaluate_action(\n                    action_request\n                )\n\n                if not action_allowed:\n                    # Early exit: Policy denial\n                    denial_reasons = risk_assessment.get(\"denial_reasons\", [])\n                    logger.warning(f\"Action evaluation denied: {denial_reasons}\")\n                else:\n                    # Step 3: Determine if HITL approval required\n                    logger.debug(\"Step 3: Determining HITL requirement\")\n                    hitl_required, hitl_info = self._determine_hitl(\n                        action_request, risk_score\n                    )\n\n                    if hitl_required:\n                        # Step 4: Handle HITL approval workflow\n                        logger.debug(\"Step 4: Processing HITL approval workflow\")\n                        hitl_approved, hitl_workflow_result = self._handle_approval(\n                            action_request, hitl_info\n                        )\n\n                        if hitl_approved:\n                            final_decision = \"allow\"\n                            logger.info(\n                                f\"Action approved by HITL reviewer: {hitl_workflow_result.get('reviewer_id')}\"\n                            )\n                        else:\n                            final_decision = \"deny\"\n                            denial_reasons.append(\n                                hitl_workflow_result.get(\n                                    \"decision_note\", \"Denied by human reviewer\"\n                                )\n                            )\n                            logger.warning(\n                                f\"Action denied by HITL reviewer: {denial_reasons[-1]}\"\n                            )\n                    else:\n                        # Auto-approved (no HITL required)\n                        final_decision = \"allow\"\n                        logger.info(\n                            f\"Action auto-approved (risk score: {risk_score:.3f})\"\n                        )\n\n            # Step 5: Log decision to audit trail\n            logger.debug(\"Step 5: Logging decision to audit trail\")\n            audit_id = self._log_decision(\n                action_request=action_request,\n                decision=final_decision,\n                risk_score=risk_score,\n                risk_assessment=risk_assessment,\n                constitutional_valid=constitutional_valid,\n                constitutional_violations=constitutional_violations,\n                hitl_required=hitl_required,\n                hitl_workflow=hitl_workflow_result,\n                denial_reasons=denial_reasons,\n            )\n\n            # Step 6: Build final decision response\n            processing_time = (time.time() - start_time) * 1000  # Convert to ms\n            logger.debug(\"Step 6: Building decision response\")\n\n            decision = self._build_decision_response(\n                decision=final_decision,\n                audit_id=audit_id,\n                risk_score=risk_score,\n                risk_assessment=risk_assessment,\n                constitutional_valid=constitutional_valid,\n                constitutional_violations=constitutional_violations,\n                hitl_required=hitl_required,\n                hitl_workflow=hitl_workflow_result,\n                denial_reasons=denial_reasons,\n                processing_time=processing_time,\n            )\n\n            logger.info(\n                f\"Workflow complete: {final_decision} (processing time: {processing_time:.2f}ms)\"\n            )\n            return decision\n\n        except Exception as e:\n            # Handle any unexpected errors\n            logger.error(f\"Governance workflow error: {e}\", exc_info=True)\n\n            # Log the error to audit trail\n            processing_time = (time.time() - start_time) * 1000\n            error_message = f\"Workflow error: {str(e)}\"\n            denial_reasons.append(error_message)\n\n            try:\n                audit_id = self._log_decision(\n                    action_request=action_request,\n                    decision=\"deny\",\n                    risk_score=risk_score,\n                    risk_assessment=risk_assessment,\n                    constitutional_valid=constitutional_valid,\n                    constitutional_violations=constitutional_violations,\n                    hitl_required=hitl_required,\n                    hitl_workflow=None,\n                    denial_reasons=denial_reasons,\n                )\n            except Exception as audit_error:\n                logger.error(f\"Failed to log error to audit trail: {audit_error}\")\n                audit_id = None\n\n            # Return error decision\n            return self._build_decision_response(\n                decision=\"deny\",\n                audit_id=audit_id,\n                risk_score=risk_score,\n                risk_assessment=risk_assessment,\n                constitutional_valid=constitutional_valid,\n                constitutional_violations=constitutional_violations,\n                hitl_required=hitl_required,\n                hitl_workflow=None,\n                denial_reasons=denial_reasons,\n                processing_time=processing_time,\n            )\n\n    def _validate_constitution(\n        self, action_request: dict\n    ) -> tuple[bool, list[str]]:\n        \"\"\"\n        Step 1: Validate action against constitutional principles.\n\n        Evaluates the action_request against constitutional.rego policy to ensure\n        it complies with all constitutional principles.\n\n        Args:\n            action_request: Complete action request dictionary\n\n        Returns:\n            Tuple of (valid: bool, violations: list[str])\n            - valid: True if action passes constitutional validation\n            - violations: List of violated principles (empty if valid)\n\n        Raises:\n            GovernanceEvaluationError: If policy evaluation fails\n        \"\"\"\n        try:\n            result = self.opa.evaluate_policy(\n                policy_path=\"acgs2/constitutional/validate\",\n                input_data=action_request,\n            )\n\n            # Extract result from OPA response\n            policy_result = result.get(\"result\", {})\n            valid = policy_result.get(\"valid\", False)\n            violations = policy_result.get(\"denial_reasons\", [])\n\n            logger.debug(\n                f\"Constitutional validation: valid={valid}, violations={len(violations)}\"\n            )\n            return valid, violations\n\n        except (OPAConnectionError, OPAPolicyError) as e:\n            logger.error(f\"Constitutional validation failed: {e}\")\n            raise GovernanceEvaluationError(\n                f\"Failed to validate constitutional compliance: {e}\"\n            ) from e\n\n    def _evaluate_action(\n        self, action_request: dict\n    ) -> tuple[bool, float, dict]:\n        \"\"\"\n        Step 2: Evaluate action and calculate risk score.\n\n        Evaluates the action_request against agent_actions.rego policy to determine\n        if the action is allowed and calculate its risk score.\n\n        Args:\n            action_request: Complete action request dictionary\n\n        Returns:\n            Tuple of (allowed: bool, risk_score: float, assessment: dict)\n            - allowed: True if action is permitted by policy\n            - risk_score: Calculated risk score (0.0-1.0)\n            - assessment: Complete risk assessment details\n\n        Raises:\n            GovernanceEvaluationError: If policy evaluation fails\n        \"\"\"\n        try:\n            result = self.opa.evaluate_policy(\n                policy_path=\"acgs2/agent_actions/evaluate\",\n                input_data=action_request,\n            )\n\n            # Extract result from OPA response\n            policy_result = result.get(\"result\", {})\n            allowed = policy_result.get(\"allowed\", False)\n            risk_score = policy_result.get(\"risk_score\", 0.0)\n\n            logger.debug(\n                f\"Action evaluation: allowed={allowed}, risk_score={risk_score:.3f}\"\n            )\n            return allowed, risk_score, policy_result\n\n        except (OPAConnectionError, OPAPolicyError) as e:\n            logger.error(f\"Action evaluation failed: {e}\")\n            raise GovernanceEvaluationError(\n                f\"Failed to evaluate action: {e}\"\n            ) from e\n\n    def _determine_hitl(\n        self, action_request: dict, risk_score: float\n    ) -> tuple[bool, dict]:\n        \"\"\"\n        Step 3: Determine if human-in-the-loop approval is required.\n\n        Evaluates against hitl_approval.rego policy to determine if the action\n        requires human review based on risk score and action type.\n\n        Args:\n            action_request: Complete action request dictionary\n            risk_score: Calculated risk score from action evaluation\n\n        Returns:\n            Tuple of (required: bool, hitl_info: dict)\n            - required: True if HITL approval is needed\n            - hitl_info: HITL workflow details (expertise, timeout, escalation, etc.)\n\n        Raises:\n            GovernanceEvaluationError: If policy evaluation fails\n        \"\"\"\n        try:\n            # Add risk_score to input for HITL policy\n            hitl_input = {**action_request, \"risk_score\": risk_score}\n\n            result = self.opa.evaluate_policy(\n                policy_path=\"acgs2/hitl/determine\",\n                input_data=hitl_input,\n            )\n\n            # Extract result from OPA response\n            policy_result = result.get(\"result\", {})\n            required = policy_result.get(\"hitl_required\", False)\n\n            logger.debug(f\"HITL determination: required={required}\")\n            return required, policy_result\n\n        except (OPAConnectionError, OPAPolicyError) as e:\n            logger.error(f\"HITL determination failed: {e}\")\n            raise GovernanceEvaluationError(\n                f\"Failed to determine HITL requirement: {e}\"\n            ) from e\n\n    def _handle_approval(\n        self, action_request: dict, hitl_info: dict\n    ) -> tuple[bool, dict]:\n        \"\"\"\n        Step 4: Handle human-in-the-loop approval workflow.\n\n        Creates an approval request, simulates the review process, and waits\n        for the reviewer decision.\n\n        Args:\n            action_request: Complete action request dictionary\n            hitl_info: HITL workflow details from policy evaluation\n\n        Returns:\n            Tuple of (approved: bool, workflow_result: dict)\n            - approved: True if reviewer approved the action\n            - workflow_result: Complete HITL workflow details including decision\n\n        Raises:\n            GovernanceWorkflowError: If HITL workflow fails\n        \"\"\"\n        try:\n            # Create approval request\n            approval_request = self.hitl.create_approval_request(\n                action_request=action_request,\n                risk_score=hitl_info.get(\"risk_score\", 0.0),\n                required_expertise=hitl_info.get(\"required_expertise\", \"senior_devops\"),\n                timeout_seconds=hitl_info.get(\"timeout_seconds\", 7200),\n                priority=hitl_info.get(\"priority\", \"normal\"),\n            )\n\n            logger.info(\n                f\"Created HITL approval request: {approval_request.request_id}\"\n            )\n\n            # Simulate reviewer assignment and decision\n            reviewer_id = self.hitl.assign_reviewer(\n                approval_request.required_expertise\n            )\n            logger.debug(f\"Assigned reviewer: {reviewer_id}\")\n\n            # Simulate review process\n            decision = self.hitl.simulate_review(approval_request, reviewer_id)\n\n            # Build workflow result\n            workflow_result = {\n                \"request_id\": str(approval_request.request_id),\n                \"approved\": decision.approved,\n                \"reviewer_id\": decision.reviewer_id,\n                \"reviewer_role\": decision.reviewer_role,\n                \"decision_note\": decision.decision_note,\n                \"reviewed_at\": decision.reviewed_at.isoformat(),\n                \"review_duration_seconds\": decision.review_duration_seconds,\n                \"escalated\": decision.escalated,\n                \"escalated_to\": decision.escalated_to,\n            }\n\n            logger.info(\n                f\"HITL review completed: approved={decision.approved}, reviewer={decision.reviewer_id}\"\n            )\n            return decision.approved, workflow_result\n\n        except Exception as e:\n            logger.error(f\"HITL approval workflow failed: {e}\")\n            raise GovernanceWorkflowError(\n                f\"Failed to process HITL approval: {e}\"\n            ) from e\n\n    def _log_decision(\n        self,\n        action_request: dict,\n        decision: str,\n        risk_score: float,\n        risk_assessment: dict,\n        constitutional_valid: bool,\n        constitutional_violations: list[str],\n        hitl_required: bool,\n        hitl_workflow: dict | None,\n        denial_reasons: list[str],\n    ) -> UUID | None:\n        \"\"\"\n        Step 5: Log governance decision to audit trail.\n\n        Records the complete decision chain to the immutable audit log with\n        full context, risk assessment, and compliance metadata.\n\n        Args:\n            action_request: Original action request\n            decision: Final decision (\"allow\" or \"deny\")\n            risk_score: Calculated risk score\n            risk_assessment: Complete risk assessment details\n            constitutional_valid: Constitutional validation result\n            constitutional_violations: List of constitutional violations\n            hitl_required: Whether HITL was required\n            hitl_workflow: HITL workflow details (if applicable)\n            denial_reasons: List of denial reasons (if denied)\n\n        Returns:\n            UUID of the audit log entry, or None if logging fails\n\n        Raises:\n            GovernanceWorkflowError: If audit logging fails critically\n        \"\"\"\n        try:\n            # Evaluate audit policy to get retention and compliance metadata\n            audit_input = {\n                **action_request,\n                \"decision\": decision,\n                \"risk_score\": risk_score,\n                \"hitl_required\": hitl_required,\n            }\n\n            audit_policy_result = self.opa.evaluate_policy(\n                policy_path=\"acgs2/audit/requirements\",\n                input_data=audit_input,\n            )\n\n            audit_requirements = audit_policy_result.get(\"result\", {})\n\n            # Extract action details\n            action = action_request.get(\"action\", {})\n            requester = action_request.get(\"requester\", {})\n            context = action_request.get(\"context\", {})\n\n            # Create audit entry\n            entry = AuditEntry(\n                timestamp=datetime.now(UTC),\n                action_type=action.get(\"type\", \"unknown\"),\n                requester_id=requester.get(\"id\", \"unknown\"),\n                requester_type=requester.get(\"type\"),\n                resource=action.get(\"resource\", \"\"),\n                resource_type=action.get(\"parameters\", {}).get(\"resource_type\"),\n                decision=decision,\n                environment=context.get(\"environment\"),\n                risk_score=risk_score,\n                risk_category=risk_assessment.get(\"category\", \"unknown\"),\n                constitutional_valid=constitutional_valid,\n                constitutional_violations=constitutional_violations,\n                hitl_required=hitl_required,\n                hitl_decision=hitl_workflow,\n                denial_reasons=denial_reasons if denial_reasons else None,\n                compliance_tags=audit_requirements.get(\"compliance_tags\", []),\n                retention_days=audit_requirements.get(\"retention_days\", 365),\n                log_level=audit_requirements.get(\"log_level\", \"normal\"),\n                metadata={\n                    \"risk_factors\": risk_assessment.get(\"factors\", {}),\n                    \"session_id\": context.get(\"session_id\"),\n                    \"constitutional_hash\": context.get(\"constitutional_hash\"),\n                },\n            )\n\n            # Log to audit trail\n            audit_id = self.audit.log_decision(entry)\n            logger.info(f\"Decision logged to audit trail: {audit_id}\")\n            return audit_id\n\n        except Exception as e:\n            logger.error(f\"Failed to log decision to audit trail: {e}\")\n            # Don't fail the workflow on audit logging errors\n            return None\n\n    def _build_decision_response(\n        self,\n        decision: str,\n        audit_id: UUID | None,\n        risk_score: float,\n        risk_assessment: dict,\n        constitutional_valid: bool,\n        constitutional_violations: list[str],\n        hitl_required: bool,\n        hitl_workflow: dict | None,\n        denial_reasons: list[str],\n        processing_time: float,\n    ) -> GovernanceDecision:\n        \"\"\"\n        Step 6: Build final governance decision response.\n\n        Constructs a comprehensive GovernanceDecision object with all context,\n        risk assessment, HITL details, and audit trail reference.\n\n        Args:\n            decision: Final decision (\"allow\" or \"deny\")\n            audit_id: UUID of audit log entry\n            risk_score: Calculated risk score\n            risk_assessment: Complete risk assessment details\n            constitutional_valid: Constitutional validation result\n            constitutional_violations: List of constitutional violations\n            hitl_required: Whether HITL was required\n            hitl_workflow: HITL workflow details (if applicable)\n            denial_reasons: List of denial reasons (if denied)\n            processing_time: Total workflow processing time in milliseconds\n\n        Returns:\n            GovernanceDecision instance with complete decision details\n        \"\"\"\n        return GovernanceDecision(\n            decision=decision,\n            audit_id=audit_id,\n            risk_assessment=risk_assessment,\n            risk_score=risk_score,\n            risk_category=risk_assessment.get(\"category\", \"unknown\"),\n            constitutional_valid=constitutional_valid,\n            constitutional_violations=constitutional_violations,\n            hitl_required=hitl_required,\n            hitl_workflow=hitl_workflow,\n            denial_reasons=denial_reasons,\n            processing_time_ms=processing_time,\n            metadata={\n                \"workflow_version\": \"1.0.0\",\n                \"constitutional_hash\": \"cdd01ef066bc6cf2\",\n            },\n        )\n",
        "timestamp": "2026-01-04T05:35:49.744738"
      },
      "worktree_state": null,
      "task_intent": {
        "title": "061-create-end-to-end-governance-workflow-examples-wit",
        "description": "Create comprehensive examples demonstrating complete governance workflows from policy creation through enforcement to audit logging, targeting Enterprise DevOps/MLOps engineers deploying AI systems. The examples will show: defining constitutional policies, enforcing them on agent actions, handling HITL approvals, and auditing decisions.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T19:36:07.576697",
  "last_updated": "2026-01-04T05:35:49.817955"
}