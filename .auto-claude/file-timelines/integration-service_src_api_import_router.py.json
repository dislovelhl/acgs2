{
  "file_path": "integration-service/src/api/import_router.py",
  "main_branch_history": [],
  "task_views": {
    "003-import-your-data": {
      "task_id": "003-import-your-data",
      "branch_point": {
        "commit_hash": "cc53a509f89115bbb36940c140031e6159320791",
        "content": "",
        "timestamp": "2026-01-03T17:00:00.287145"
      },
      "worktree_state": {
        "content": "\"\"\"\nImport API endpoints for managing data import operations.\n\nProvides endpoints for previewing, executing, and monitoring data imports\nfrom external sources like JIRA, ServiceNow, GitHub, and GitLab.\n\"\"\"\n\nimport logging\nfrom datetime import datetime, timezone\nfrom typing import Optional\nfrom uuid import uuid4\n\nfrom fastapi import APIRouter, HTTPException, Query, Request, status\nfrom pydantic import BaseModel, Field\n\nfrom ..models.import_models import (\n    ImportListResponse,\n    ImportRequest,\n    ImportResponse,\n    ImportStatus,\n    PreviewResponse,\n    SourceConfig,\n    SourceType,\n)\n\n# Configure logging\nlogger = logging.getLogger(__name__)\n\n# Create router\nrouter = APIRouter(prefix=\"/api/imports\", tags=[\"Imports\"])\n\n# Redis key prefix for import jobs\nREDIS_JOB_PREFIX = \"import:job:\"\nREDIS_JOB_TTL = 86400  # 24 hours in seconds\n\n\n# Dependency for getting Redis client\ndef get_redis_client(request: Request):\n    \"\"\"Get Redis client from app state.\"\"\"\n    # Access the redis_client from main.py\n    import sys\n    if 'src.main' in sys.modules:\n        from src.main import redis_client\n        return redis_client\n    return None\n\n\nasync def save_job_to_redis(redis_client, job: ImportResponse) -> None:\n    \"\"\"Save import job to Redis with TTL.\"\"\"\n    if not redis_client:\n        logger.warning(\"Redis client not available, skipping job persistence\")\n        return\n\n    try:\n        # Serialize job to JSON\n        job_data = job.model_dump_json()\n\n        # Save to Redis with TTL\n        key = f\"{REDIS_JOB_PREFIX}{job.job_id}\"\n        await redis_client.set(key, job_data, ex=REDIS_JOB_TTL)\n\n        logger.debug(f\"Saved job {job.job_id} to Redis with TTL={REDIS_JOB_TTL}s\")\n    except Exception as e:\n        logger.error(f\"Failed to save job to Redis: {e}\")\n\n\nasync def get_job_from_redis(redis_client, job_id: str) -> Optional[ImportResponse]:\n    \"\"\"Retrieve import job from Redis.\"\"\"\n    if not redis_client:\n        logger.warning(\"Redis client not available\")\n        return None\n\n    try:\n        key = f\"{REDIS_JOB_PREFIX}{job_id}\"\n        job_data = await redis_client.get(key)\n\n        if not job_data:\n            return None\n\n        # Deserialize from JSON\n        return ImportResponse.model_validate_json(job_data)\n    except Exception as e:\n        logger.error(f\"Failed to retrieve job from Redis: {e}\")\n        return None\n\n\nasync def list_jobs_from_redis(redis_client) -> list[ImportResponse]:\n    \"\"\"List all import jobs from Redis.\"\"\"\n    if not redis_client:\n        logger.warning(\"Redis client not available\")\n        return []\n\n    try:\n        # Find all job keys\n        pattern = f\"{REDIS_JOB_PREFIX}*\"\n        keys = []\n        async for key in redis_client.scan_iter(match=pattern):\n            keys.append(key)\n\n        # Retrieve all jobs\n        jobs = []\n        for key in keys:\n            job_data = await redis_client.get(key)\n            if job_data:\n                try:\n                    job = ImportResponse.model_validate_json(job_data)\n                    jobs.append(job)\n                except Exception as e:\n                    logger.warning(f\"Failed to parse job from key {key}: {e}\")\n\n        return jobs\n    except Exception as e:\n        logger.error(f\"Failed to list jobs from Redis: {e}\")\n        return []\n\n\nasync def delete_job_from_redis(redis_client, job_id: str) -> bool:\n    \"\"\"Delete import job from Redis.\"\"\"\n    if not redis_client:\n        logger.warning(\"Redis client not available\")\n        return False\n\n    try:\n        key = f\"{REDIS_JOB_PREFIX}{job_id}\"\n        result = await redis_client.delete(key)\n        return result > 0\n    except Exception as e:\n        logger.error(f\"Failed to delete job from Redis: {e}\")\n        return False\n\n\n# Request/Response models for test connection\nclass TestConnectionRequest(BaseModel):\n    \"\"\"Request to test connection to an external source.\"\"\"\n\n    source: SourceType = Field(..., description=\"Type of source to connect to\")\n    source_config: SourceConfig = Field(..., description=\"Connection configuration\")\n\n\nclass TestConnectionResponse(BaseModel):\n    \"\"\"Response from test connection attempt.\"\"\"\n\n    success: bool = Field(..., description=\"Whether connection was successful\")\n    message: str = Field(..., description=\"Success or error message\")\n    source_name: Optional[str] = Field(None, description=\"Name/identifier from the source\")\n\n\n# API Endpoints\n@router.post(\n    \"/test-connection\",\n    response_model=TestConnectionResponse,\n    status_code=status.HTTP_200_OK,\n    summary=\"Test connection to external source\",\n    description=\"Verify credentials and connectivity to an external data source\",\n)\nasync def test_connection(\n    request: TestConnectionRequest,\n) -> TestConnectionResponse:\n    \"\"\"\n    Test connection to an external source.\n\n    This endpoint verifies that the provided credentials can successfully\n    authenticate with the external source. It does not fetch or modify any data.\n    \"\"\"\n    try:\n        logger.info(f\"Testing connection to source_type={request.source}\")\n\n        # Import service modules dynamically to avoid circular imports\n        if request.source == SourceType.JIRA:\n            from ..services.jira_import_service import create_jira_import_service\n\n            # Create import service\n            try:\n                service = await create_jira_import_service(request.source_config)\n            except ValueError as e:\n                logger.warning(f\"JIRA configuration validation failed: {e}\")\n                return TestConnectionResponse(\n                    success=False,\n                    message=str(e),\n                    source_name=None,\n                )\n\n            success, error_msg = await service.test_connection()\n\n            if success:\n                logger.info(\"JIRA connection test successful\")\n                return TestConnectionResponse(\n                    success=True,\n                    message=\"Connection successful\",\n                    source_name=f\"JIRA ({request.source_config.base_url})\",\n                )\n            else:\n                logger.warning(f\"JIRA connection test failed: {error_msg}\")\n                return TestConnectionResponse(\n                    success=False,\n                    message=error_msg or \"Connection failed\",\n                    source_name=None,\n                )\n\n        elif request.source == SourceType.SERVICENOW:\n            from ..services.servicenow_import_service import create_servicenow_import_service\n\n            try:\n                service = await create_servicenow_import_service(request.source_config)\n            except ValueError as e:\n                logger.warning(f\"ServiceNow configuration validation failed: {e}\")\n                return TestConnectionResponse(\n                    success=False,\n                    message=str(e),\n                    source_name=None,\n                )\n\n            success, error_msg = await service.test_connection()\n\n            if success:\n                logger.info(\"ServiceNow connection test successful\")\n                return TestConnectionResponse(\n                    success=True,\n                    message=\"Connection successful\",\n                    source_name=f\"ServiceNow ({request.source_config.instance})\",\n                )\n            else:\n                logger.warning(f\"ServiceNow connection test failed: {error_msg}\")\n                return TestConnectionResponse(\n                    success=False,\n                    message=error_msg or \"Connection failed\",\n                    source_name=None,\n                )\n\n        elif request.source == SourceType.GITHUB:\n            from ..services.github_import_service import create_github_import_service\n\n            try:\n                service = await create_github_import_service(request.source_config)\n            except ValueError as e:\n                logger.warning(f\"GitHub configuration validation failed: {e}\")\n                return TestConnectionResponse(\n                    success=False,\n                    message=str(e),\n                    source_name=None,\n                )\n\n            success, error_msg = await service.test_connection()\n\n            if success:\n                logger.info(\"GitHub connection test successful\")\n                return TestConnectionResponse(\n                    success=True,\n                    message=\"Connection successful\",\n                    source_name=\"GitHub\",\n                )\n            else:\n                logger.warning(f\"GitHub connection test failed: {error_msg}\")\n                return TestConnectionResponse(\n                    success=False,\n                    message=error_msg or \"Connection failed\",\n                    source_name=None,\n                )\n\n        elif request.source == SourceType.GITLAB:\n            from ..services.gitlab_import_service import create_gitlab_import_service\n\n            try:\n                service = await create_gitlab_import_service(request.source_config)\n            except ValueError as e:\n                logger.warning(f\"GitLab configuration validation failed: {e}\")\n                return TestConnectionResponse(\n                    success=False,\n                    message=str(e),\n                    source_name=None,\n                )\n\n            success, error_msg = await service.test_connection()\n\n            if success:\n                logger.info(\"GitLab connection test successful\")\n                return TestConnectionResponse(\n                    success=True,\n                    message=\"Connection successful\",\n                    source_name=f\"GitLab ({request.source_config.base_url})\",\n                )\n            else:\n                logger.warning(f\"GitLab connection test failed: {error_msg}\")\n                return TestConnectionResponse(\n                    success=False,\n                    message=error_msg or \"Connection failed\",\n                    source_name=None,\n                )\n\n        else:\n            raise ValueError(f\"Unsupported source type: {request.source}\")\n\n    except ValueError as e:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e),\n        ) from None\n    except Exception as e:\n        logger.exception(f\"Error testing connection: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Connection test failed. Please verify your configuration and try again.\",\n        ) from None\n\n\n@router.post(\n    \"/preview\",\n    response_model=PreviewResponse,\n    status_code=status.HTTP_200_OK,\n    summary=\"Preview data import\",\n    description=\"Preview what data would be imported without committing changes\",\n)\nasync def preview_import(\n    request: ImportRequest,\n) -> PreviewResponse:\n    \"\"\"\n    Preview data from an external source before importing.\n\n    This endpoint connects to the specified external source and retrieves\n    a sample of items that would be imported based on the provided filters.\n    No data is committed to the system.\n    \"\"\"\n    try:\n        logger.info(\n            f\"Preview requested for source_type={request.source_type}, \"\n            f\"request_id={request.id}\"\n        )\n\n        # TODO: Integrate with actual import services based on source_type\n        # For now, return mock preview data\n\n        preview = PreviewResponse(\n            source_type=request.source_type,\n            total_available=0,\n            preview_items=[],\n            preview_count=0,\n            source_name=f\"Mock {request.source_type.value} Source\",\n            item_type_counts={},\n            status_counts={},\n            warnings=[\"Preview functionality is under development\"],\n        )\n\n        logger.info(\n            f\"Preview completed for request_id={request.id}, \"\n            f\"found {preview.total_available} items\"\n        )\n\n        return preview\n\n    except ValueError as e:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e),\n        ) from None\n    except Exception as e:\n        logger.exception(f\"Error previewing import: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Preview failed. Please verify your configuration and try again.\",\n        ) from None\n\n\n@router.post(\n    \"\",\n    response_model=ImportResponse,\n    status_code=status.HTTP_202_ACCEPTED,\n    summary=\"Execute data import\",\n    description=\"Start an asynchronous data import operation from an external source\",\n)\nasync def execute_import(\n    request: ImportRequest,\n    req: Request,\n) -> ImportResponse:\n    \"\"\"\n    Execute a data import from an external source.\n\n    This endpoint initiates an asynchronous import job. The job status\n    can be monitored using the GET /api/imports/{job_id} endpoint.\n    \"\"\"\n    try:\n        redis_client = get_redis_client(req)\n\n        # Create import job\n        job_id = str(uuid4())\n        job = ImportResponse(\n            job_id=job_id,\n            request_id=request.id,\n            status=ImportStatus.PENDING,\n            source_type=request.source_type,\n            created_at=datetime.now(timezone.utc),\n            updated_at=datetime.now(timezone.utc),\n            tenant_id=request.tenant_id,\n            correlation_id=request.correlation_id,\n        )\n\n        # Store job in Redis\n        await save_job_to_redis(redis_client, job)\n\n        logger.info(\n            f\"Import job created: job_id={job_id}, \"\n            f\"source_type={request.source_type}, \"\n            f\"request_id={request.id}\"\n        )\n\n        # TODO: Queue job for background processing\n        # For now, job remains in PENDING state\n\n        return job\n\n    except ValueError as e:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e),\n        ) from None\n    except Exception as e:\n        logger.exception(f\"Error executing import: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Import execution failed. Please verify your request and try again.\",\n        ) from None\n\n\n@router.get(\n    \"/{job_id}\",\n    response_model=ImportResponse,\n    summary=\"Get import job status\",\n    description=\"Get the status and progress of a specific import job\",\n)\nasync def get_import_status(\n    job_id: str,\n    req: Request,\n) -> ImportResponse:\n    \"\"\"Get the status and progress of an import job.\"\"\"\n    redis_client = get_redis_client(req)\n    job = await get_job_from_redis(redis_client, job_id)\n\n    if not job:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Import job not found: {job_id}\",\n        )\n\n    logger.debug(f\"Retrieved status for job_id={job_id}, status={job.status}\")\n\n    return job\n\n\n@router.get(\n    \"\",\n    response_model=ImportListResponse,\n    summary=\"List import jobs\",\n    description=\"List all import jobs with optional filtering\",\n)\nasync def list_imports(\n    source_type: Optional[SourceType] = Query(None, description=\"Filter by source type\"),\n    status_filter: Optional[ImportStatus] = Query(None, description=\"Filter by status\"),\n    tenant_id: Optional[str] = Query(None, description=\"Filter by tenant ID\"),\n    limit: int = Query(10, ge=1, le=100, description=\"Maximum number of jobs to return\"),\n    offset: int = Query(0, ge=0, description=\"Offset for pagination\"),\n    req: Request = None,\n) -> ImportListResponse:\n    \"\"\"\n    List all import jobs.\n\n    Supports filtering by source type, status, and tenant ID.\n    Results are paginated and sorted by creation time (newest first).\n    \"\"\"\n    redis_client = get_redis_client(req)\n\n    # Get all jobs from Redis\n    jobs = await list_jobs_from_redis(redis_client)\n\n    # Filter jobs\n    if source_type:\n        jobs = [j for j in jobs if j.source_type == source_type]\n\n    if status_filter:\n        jobs = [j for j in jobs if j.status == status_filter]\n\n    if tenant_id:\n        jobs = [j for j in jobs if j.tenant_id == tenant_id]\n\n    # Sort by creation time (newest first)\n    jobs.sort(key=lambda j: j.created_at, reverse=True)\n\n    # Paginate\n    total = len(jobs)\n    paginated_jobs = jobs[offset : offset + limit]\n\n    logger.debug(\n        f\"Listed {len(paginated_jobs)} jobs (total={total}, \"\n        f\"limit={limit}, offset={offset})\"\n    )\n\n    return ImportListResponse(\n        jobs=paginated_jobs,\n        total=total,\n        limit=limit,\n        offset=offset,\n    )\n\n\n@router.delete(\n    \"/{job_id}\",\n    status_code=status.HTTP_204_NO_CONTENT,\n    summary=\"Cancel import job\",\n    description=\"Cancel a pending or running import job\",\n)\nasync def cancel_import(\n    job_id: str,\n    req: Request,\n) -> None:\n    \"\"\"\n    Cancel an import job.\n\n    Only jobs in PENDING or PROCESSING status can be cancelled.\n    Completed or failed jobs cannot be cancelled.\n    \"\"\"\n    redis_client = get_redis_client(req)\n    job = await get_job_from_redis(redis_client, job_id)\n\n    if not job:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Import job not found: {job_id}\",\n        )\n\n    # Check if job can be cancelled\n    if job.status in (ImportStatus.COMPLETED, ImportStatus.FAILED, ImportStatus.CANCELLED):\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=f\"Cannot cancel job in {job.status} status\",\n        )\n\n    # Update job status\n    job.status = ImportStatus.CANCELLED\n    job.updated_at = datetime.now(timezone.utc)\n    job.completed_at = datetime.now(timezone.utc)\n\n    # Save updated job back to Redis\n    await save_job_to_redis(redis_client, job)\n\n    logger.info(f\"Cancelled import job: {job_id}\")\n",
        "last_modified": "2026-01-03T19:09:00.297950"
      },
      "task_intent": {
        "title": "003-import-your-data",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T17:00:00.293644",
  "last_updated": "2026-01-03T17:00:00.295736"
}