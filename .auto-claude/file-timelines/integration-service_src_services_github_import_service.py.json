{
  "file_path": "integration-service/src/services/github_import_service.py",
  "main_branch_history": [],
  "task_views": {
    "003-import-your-data": {
      "task_id": "003-import-your-data",
      "branch_point": {
        "commit_hash": "cc53a509f89115bbb36940c140031e6159320791",
        "content": "",
        "timestamp": "2026-01-03T17:00:00.287145"
      },
      "worktree_state": {
        "content": "\"\"\"\nGitHub Import Service\n\nHandles fetching and transforming GitHub data for import into ACGS2.\nSupports both preview mode (sample data) and full import operations.\n\nFeatures:\n- Fetches issues from GitHub repositories\n- Transforms GitHub issues to ACGS2 format\n- Supports filtering by state, labels, and date ranges\n- Handles pagination for large datasets\n- Provides progress tracking for batch operations\n- Rate limit handling\n\"\"\"\n\nimport logging\nfrom datetime import datetime, timezone\nfrom typing import Any, Dict, List, Optional, Tuple\n\nimport httpx\nfrom pydantic import BaseModel, Field, SecretStr, field_validator\n\nfrom ..models.import_models import (\n    DuplicateHandling,\n    ImportedItem,\n    ImportProgress,\n    PreviewItem,\n    PreviewResponse,\n    SourceConfig,\n    SourceType,\n)\n\nlogger = logging.getLogger(__name__)\n\n\nclass GitHubImportConfig(BaseModel):\n    \"\"\"Configuration specific to GitHub import operations.\"\"\"\n\n    api_token: SecretStr = Field(..., description=\"GitHub personal access token\")\n    repository: str = Field(..., description=\"Repository name (e.g., 'owner/repo')\")\n\n    # Optional filters\n    state: str = Field(\n        default=\"all\",\n        description=\"Filter by state: 'open', 'closed', or 'all'\"\n    )\n    labels: List[str] = Field(\n        default_factory=list,\n        description=\"Filter by labels (e.g., ['bug', 'enhancement'])\"\n    )\n    milestone: Optional[str] = Field(\n        None,\n        description=\"Filter by milestone number or title\"\n    )\n\n    @field_validator(\"repository\")\n    @classmethod\n    def validate_repository(cls, v: str) -> str:\n        \"\"\"Validate repository format (owner/repo).\"\"\"\n        if not v:\n            raise ValueError(\"Repository is required\")\n\n        v = v.strip()\n\n        if \"/\" not in v:\n            raise ValueError(\"Repository must be in 'owner/repo' format\")\n\n        parts = v.split(\"/\")\n        if len(parts) != 2:\n            raise ValueError(\"Repository must be in 'owner/repo' format\")\n\n        owner, repo = parts\n        if not owner or not repo:\n            raise ValueError(\"Both owner and repository name must be non-empty\")\n\n        return v\n\n    @field_validator(\"state\")\n    @classmethod\n    def validate_state(cls, v: str) -> str:\n        \"\"\"Validate state value.\"\"\"\n        v = v.lower()\n        if v not in [\"open\", \"closed\", \"all\"]:\n            raise ValueError(\"State must be 'open', 'closed', or 'all'\")\n        return v\n\n\nclass GitHubImportService:\n    \"\"\"\n    Service for importing data from GitHub.\n\n    Handles authentication, data fetching, and transformation of GitHub issues\n    into ACGS2 import format.\n\n    Usage:\n        config = GitHubImportConfig(\n            api_token=SecretStr(\"ghp_your_token\"),\n            repository=\"owner/repo\",\n        )\n        service = GitHubImportService(config)\n        await service.test_connection()\n        preview = await service.preview_import(max_items=10)\n        items = await service.fetch_items(batch_size=100)\n    \"\"\"\n\n    # GitHub REST API version and base URL\n    API_BASE_URL = \"https://api.github.com\"\n    API_VERSION = \"2022-11-28\"  # GitHub API version header\n\n    # Default limits\n    DEFAULT_PREVIEW_LIMIT = 10\n    DEFAULT_BATCH_SIZE = 100\n    MAX_RESULTS_PER_PAGE = 100  # GitHub API limit\n\n    def __init__(\n        self,\n        config: GitHubImportConfig,\n        timeout: float = 30.0,\n        max_retries: int = 3,\n    ):\n        \"\"\"\n        Initialize GitHub import service.\n\n        Args:\n            config: GitHub import configuration\n            timeout: HTTP request timeout in seconds\n            max_retries: Maximum retry attempts for failed requests\n        \"\"\"\n        self.config = config\n        self.timeout = timeout\n        self.max_retries = max_retries\n        self._client: Optional[httpx.AsyncClient] = None\n\n    @property\n    def repository_url(self) -> str:\n        \"\"\"Get the repository API URL.\"\"\"\n        return f\"{self.API_BASE_URL}/repos/{self.config.repository}\"\n\n    @property\n    def issues_url(self) -> str:\n        \"\"\"Get the issues API URL.\"\"\"\n        return f\"{self.repository_url}/issues\"\n\n    def _get_auth_headers(self) -> Dict[str, str]:\n        \"\"\"Get authentication headers for GitHub API requests.\"\"\"\n        return {\n            \"Authorization\": f\"Bearer {self.config.api_token.get_secret_value()}\",\n            \"Accept\": \"application/vnd.github+json\",\n            \"X-GitHub-Api-Version\": self.API_VERSION,\n        }\n\n    async def _get_client(self) -> httpx.AsyncClient:\n        \"\"\"Get or create HTTP client.\"\"\"\n        if self._client is None:\n            self._client = httpx.AsyncClient(\n                timeout=self.timeout,\n                follow_redirects=True,\n            )\n        return self._client\n\n    async def test_connection(self) -> Tuple[bool, Optional[str]]:\n        \"\"\"\n        Test connection to GitHub and verify credentials.\n\n        Returns:\n            Tuple of (success, error_message)\n        \"\"\"\n        logger.debug(f\"Testing GitHub connection for repository {self.config.repository}\")\n\n        try:\n            client = await self._get_client()\n\n            # Verify credentials by fetching authenticated user\n            user_url = f\"{self.API_BASE_URL}/user\"\n            response = await client.get(\n                user_url,\n                headers=self._get_auth_headers(),\n            )\n\n            if response.status_code == 200:\n                user_data = response.json()\n                login = user_data.get(\"login\", \"Unknown\")\n                logger.info(f\"GitHub connection successful (user: {login})\")\n\n                # Also verify repository access\n                repo_response = await client.get(\n                    self.repository_url,\n                    headers=self._get_auth_headers(),\n                )\n\n                if repo_response.status_code == 200:\n                    repo_data = repo_response.json()\n                    repo_name = repo_data.get(\"full_name\", self.config.repository)\n                    logger.info(f\"Repository access confirmed: {repo_name}\")\n                    return True, None\n                elif repo_response.status_code == 404:\n                    error_msg = f\"Repository '{self.config.repository}' not found or access denied\"\n                    logger.error(f\"GitHub repository check failed: {error_msg}\")\n                    return False, error_msg\n                elif repo_response.status_code == 403:\n                    error_msg = \"Access denied - check repository permissions\"\n                    logger.error(f\"GitHub repository check failed: {error_msg}\")\n                    return False, error_msg\n                else:\n                    error_msg = f\"Repository check failed: HTTP {repo_response.status_code}\"\n                    logger.error(f\"GitHub repository check failed: {error_msg}\")\n                    return False, error_msg\n\n            elif response.status_code == 401:\n                error_msg = \"Invalid token - check GitHub personal access token\"\n                logger.error(f\"GitHub authentication failed: {error_msg}\")\n                return False, error_msg\n\n            elif response.status_code == 403:\n                error_msg = \"Access denied - token may lack required scopes\"\n                logger.error(f\"GitHub authentication failed: {error_msg}\")\n                return False, error_msg\n\n            else:\n                error_msg = f\"Unexpected response: HTTP {response.status_code}\"\n                logger.error(f\"GitHub connection test failed: {error_msg}\")\n                return False, error_msg\n\n        except httpx.TimeoutException as e:\n            error_msg = f\"Connection timed out: {str(e)}\"\n            logger.error(f\"GitHub connection test failed: {error_msg}\")\n            return False, error_msg\n\n        except httpx.NetworkError as e:\n            error_msg = f\"Network error: {str(e)}\"\n            logger.error(f\"GitHub connection test failed: {error_msg}\")\n            return False, error_msg\n\n        except Exception as e:\n            error_msg = f\"Unexpected error: {str(e)}\"\n            logger.error(f\"GitHub connection test failed: {error_msg}\")\n            return False, error_msg\n\n    async def preview_import(\n        self,\n        source_config: Optional[SourceConfig] = None,\n        max_items: int = DEFAULT_PREVIEW_LIMIT,\n    ) -> PreviewResponse:\n        \"\"\"\n        Fetch a preview of items available for import.\n\n        Args:\n            source_config: Optional source configuration with filters\n            max_items: Maximum number of items to include in preview\n\n        Returns:\n            PreviewResponse with sample items and statistics\n\n        Raises:\n            Exception: If preview fails\n        \"\"\"\n        logger.debug(\n            f\"Fetching GitHub preview for repository {self.config.repository} \"\n            f\"(max {max_items} items)\"\n        )\n\n        try:\n            # Build query parameters\n            params = self._build_query_params(source_config)\n\n            # Fetch issues\n            issues, total = await self._fetch_issues(\n                params=params,\n                per_page=max_items,\n                page=1,\n            )\n\n            # Transform to preview items\n            preview_items = [\n                self._transform_to_preview_item(issue) for issue in issues\n            ]\n\n            # Collect statistics\n            item_type_counts: Dict[str, int] = {}\n            status_counts: Dict[str, int] = {}\n\n            for item in preview_items:\n                # Count by type\n                item_type = item.item_type\n                item_type_counts[item_type] = item_type_counts.get(item_type, 0) + 1\n\n                # Count by status\n                if item.status:\n                    status_counts[item.status] = status_counts.get(item.status, 0) + 1\n\n            # Collect warnings\n            warnings = []\n            if total > 1000:\n                warnings.append(\n                    f\"Large dataset ({total} items) will be processed in batches\"\n                )\n\n            logger.info(\n                f\"GitHub preview successful: {len(preview_items)} items \"\n                f\"({total} total available)\"\n            )\n\n            return PreviewResponse(\n                source_type=SourceType.GITHUB,\n                total_available=total,\n                preview_items=preview_items,\n                preview_count=len(preview_items),\n                source_name=self.config.repository,\n                source_url=f\"https://github.com/{self.config.repository}/issues\",\n                item_type_counts=item_type_counts,\n                status_counts=status_counts,\n                warnings=warnings,\n            )\n\n        except Exception as e:\n            logger.error(f\"GitHub preview failed: {str(e)}\")\n            raise\n\n    async def fetch_items(\n        self,\n        source_config: Optional[SourceConfig] = None,\n        batch_size: int = DEFAULT_BATCH_SIZE,\n        max_items: Optional[int] = None,\n        progress_callback: Optional[callable] = None,\n    ) -> List[ImportedItem]:\n        \"\"\"\n        Fetch all items for import with batching and progress tracking.\n\n        Args:\n            source_config: Optional source configuration with filters\n            batch_size: Number of items to fetch per batch\n            max_items: Maximum total items to fetch (None = all)\n            progress_callback: Optional callback for progress updates\n                               callback(progress: ImportProgress) -> None\n\n        Returns:\n            List of ImportedItem objects ready for import\n\n        Raises:\n            Exception: If fetch fails\n        \"\"\"\n        logger.debug(\n            f\"Fetching GitHub items for repository {self.config.repository} \"\n            f\"(batch_size={batch_size}, max_items={max_items})\"\n        )\n\n        # Build query parameters\n        params = self._build_query_params(source_config)\n\n        # Get total count first (fetch one item to get total from headers)\n        _, total = await self._fetch_issues(params=params, per_page=1, page=1)\n\n        # Apply max_items limit\n        if max_items is not None:\n            total = min(total, max_items)\n\n        logger.info(f\"Fetching {total} items from GitHub in batches of {batch_size}\")\n\n        # Initialize progress\n        progress = ImportProgress(\n            total_items=total,\n            processed_items=0,\n            successful_items=0,\n            failed_items=0,\n            skipped_items=0,\n            percentage=0.0,\n            total_batches=(total + batch_size - 1) // batch_size if total > 0 else 0,\n            current_batch=0,\n        )\n\n        imported_items: List[ImportedItem] = []\n        page = 1\n        fetched_count = 0\n\n        # Fetch in batches\n        while fetched_count < total:\n            progress.current_batch += 1\n            current_batch_size = min(batch_size, total - fetched_count)\n\n            logger.debug(\n                f\"Fetching batch {progress.current_batch}/{progress.total_batches} \"\n                f\"(page {page}, per_page {current_batch_size})\"\n            )\n\n            try:\n                issues, _ = await self._fetch_issues(\n                    params=params,\n                    per_page=current_batch_size,\n                    page=page,\n                )\n\n                if not issues:\n                    break\n\n                # Transform to imported items\n                for issue in issues:\n                    try:\n                        item = self._transform_to_imported_item(issue)\n                        imported_items.append(item)\n                        progress.successful_items += 1\n                    except Exception as e:\n                        logger.error(\n                            f\"Failed to transform issue #{issue.get('number', 'unknown')}: {str(e)}\"\n                        )\n                        progress.failed_items += 1\n\n                fetched_count += len(issues)\n                progress.processed_items = fetched_count\n\n            except Exception as e:\n                logger.error(f\"Batch {progress.current_batch} failed: {str(e)}\")\n                progress.failed_items += current_batch_size\n\n            # Update progress\n            progress.percentage = (\n                (progress.processed_items / total * 100.0) if total > 0 else 100.0\n            )\n\n            # Call progress callback if provided\n            if progress_callback:\n                progress_callback(progress)\n\n            page += 1\n\n        logger.info(\n            f\"GitHub fetch complete: {progress.successful_items} successful, \"\n            f\"{progress.failed_items} failed\"\n        )\n\n        return imported_items\n\n    def _build_query_params(self, source_config: Optional[SourceConfig] = None) -> Dict[str, Any]:\n        \"\"\"\n        Build query parameters from configuration and filters.\n\n        Args:\n            source_config: Optional source configuration with filters\n\n        Returns:\n            Dictionary of query parameters for GitHub API\n        \"\"\"\n        params: Dict[str, Any] = {\n            \"state\": self.config.state,\n        }\n\n        # Add labels filter\n        if self.config.labels:\n            params[\"labels\"] = \",\".join(self.config.labels)\n\n        # Add milestone filter\n        if self.config.milestone:\n            params[\"milestone\"] = self.config.milestone\n\n        # Add filters from source_config if provided\n        if source_config:\n            # Status filter (maps to state in GitHub)\n            if source_config.status_filter:\n                # Map common status values to GitHub states\n                states = []\n                for status in source_config.status_filter:\n                    status_lower = status.lower()\n                    if status_lower in [\"open\", \"closed\"]:\n                        states.append(status_lower)\n\n                if states:\n                    # GitHub only supports one state value, use first\n                    params[\"state\"] = states[0]\n\n            # Label filter\n            if source_config.label_filter:\n                params[\"labels\"] = \",\".join(source_config.label_filter)\n\n            # Date filters (GitHub uses since parameter for created date)\n            if source_config.date_from:\n                params[\"since\"] = source_config.date_from.isoformat()\n\n        # Sort by created date (oldest first for consistent pagination)\n        params[\"sort\"] = \"created\"\n        params[\"direction\"] = \"asc\"\n\n        logger.debug(f\"Built GitHub query params: {params}\")\n        return params\n\n    async def _fetch_issues(\n        self,\n        params: Dict[str, Any],\n        per_page: int,\n        page: int = 1,\n    ) -> Tuple[List[Dict[str, Any]], int]:\n        \"\"\"\n        Fetch issues from GitHub repository.\n\n        Args:\n            params: Query parameters\n            per_page: Number of results per page\n            page: Page number (1-indexed)\n\n        Returns:\n            Tuple of (issues list, total count)\n\n        Raises:\n            Exception: If fetch fails\n        \"\"\"\n        client = await self._get_client()\n\n        request_params = {\n            **params,\n            \"per_page\": min(per_page, self.MAX_RESULTS_PER_PAGE),\n            \"page\": page,\n        }\n\n        response = await client.get(\n            self.issues_url,\n            headers=self._get_auth_headers(),\n            params=request_params,\n        )\n\n        if response.status_code == 200:\n            issues = response.json()\n\n            # GitHub doesn't provide total count directly\n            # We estimate from Link header or use returned count\n            total = len(issues)\n\n            # Check Link header for pagination info\n            link_header = response.headers.get(\"Link\", \"\")\n            if \"rel=\\\"last\\\"\" in link_header:\n                # Parse last page number from Link header\n                import re\n                last_page_match = re.search(r'page=(\\d+)>; rel=\"last\"', link_header)\n                if last_page_match:\n                    last_page = int(last_page_match.group(1))\n                    # Estimate total (this is approximate)\n                    total = last_page * per_page\n\n            # If we got fewer items than requested and no last page, this is all\n            if len(issues) < per_page and \"rel=\\\"last\\\"\" not in link_header:\n                total = (page - 1) * per_page + len(issues)\n\n            logger.debug(\n                f\"Fetched {len(issues)} issues (estimated total: {total})\"\n            )\n\n            return issues, total\n\n        elif response.status_code == 401:\n            raise Exception(\"Authentication failed - token may be expired\")\n\n        elif response.status_code == 403:\n            # Check for rate limiting\n            if \"X-RateLimit-Remaining\" in response.headers:\n                remaining = response.headers.get(\"X-RateLimit-Remaining\", \"0\")\n                if remaining == \"0\":\n                    reset_time = response.headers.get(\"X-RateLimit-Reset\", \"unknown\")\n                    raise Exception(\n                        f\"GitHub API rate limit exceeded. Resets at: {reset_time}\"\n                    )\n            raise Exception(\"Access denied - check repository permissions and token scopes\")\n\n        elif response.status_code == 404:\n            raise Exception(f\"Repository '{self.config.repository}' not found\")\n\n        elif response.status_code == 422:\n            error_msg = \"Invalid query parameters\"\n            try:\n                error_data = response.json()\n                if \"message\" in error_data:\n                    error_msg = error_data[\"message\"]\n            except Exception:\n                pass\n            raise Exception(error_msg)\n\n        else:\n            raise Exception(f\"Failed to fetch issues: HTTP {response.status_code}\")\n\n    def _transform_to_preview_item(self, issue: Dict[str, Any]) -> PreviewItem:\n        \"\"\"\n        Transform a GitHub issue to a PreviewItem.\n\n        Args:\n            issue: GitHub issue data from API\n\n        Returns:\n            PreviewItem for display\n        \"\"\"\n        # Parse dates\n        created_at = None\n        updated_at = None\n\n        if issue.get(\"created_at\"):\n            try:\n                created_at = datetime.fromisoformat(\n                    issue[\"created_at\"].replace(\"Z\", \"+00:00\")\n                )\n            except Exception:\n                pass\n\n        if issue.get(\"updated_at\"):\n            try:\n                updated_at = datetime.fromisoformat(\n                    issue[\"updated_at\"].replace(\"Z\", \"+00:00\")\n                )\n            except Exception:\n                pass\n\n        # Get assignee\n        assignee = None\n        if issue.get(\"assignee\"):\n            assignee = issue[\"assignee\"].get(\"login\")\n        elif issue.get(\"assignees\") and len(issue[\"assignees\"]) > 0:\n            assignee = issue[\"assignees\"][0].get(\"login\")\n\n        # Get status (GitHub uses state: open/closed)\n        status = issue.get(\"state\", \"open\")\n\n        # Get labels\n        labels = [label.get(\"name\", \"\") for label in issue.get(\"labels\", [])]\n\n        # Determine item type (issue or pull request)\n        item_type = \"Pull Request\" if \"pull_request\" in issue else \"Issue\"\n\n        return PreviewItem(\n            external_id=str(issue.get(\"number\", \"\")),\n            item_type=item_type,\n            title=issue.get(\"title\", \"Untitled\"),\n            status=status,\n            assignee=assignee,\n            created_at=created_at,\n            updated_at=updated_at,\n            labels=labels,\n            metadata={\n                \"author\": issue.get(\"user\", {}).get(\"login\") if issue.get(\"user\") else None,\n                \"comments\": issue.get(\"comments\", 0),\n                \"milestone\": issue.get(\"milestone\", {}).get(\"title\") if issue.get(\"milestone\") else None,\n                \"locked\": issue.get(\"locked\", False),\n                \"html_url\": issue.get(\"html_url\"),\n            },\n        )\n\n    def _transform_to_imported_item(self, issue: Dict[str, Any]) -> ImportedItem:\n        \"\"\"\n        Transform a GitHub issue to an ImportedItem.\n\n        Args:\n            issue: GitHub issue data from API\n\n        Returns:\n            ImportedItem for import processing\n        \"\"\"\n        # Determine item type (issue or pull request)\n        item_type = \"Pull Request\" if \"pull_request\" in issue else \"Issue\"\n\n        return ImportedItem(\n            external_id=str(issue.get(\"number\", \"\")),\n            internal_id=None,  # Will be set during import\n            item_type=item_type,\n            title=issue.get(\"title\", \"Untitled\"),\n            status=\"pending\",  # Initial import status\n            error_message=None,\n        )\n\n    async def close(self) -> None:\n        \"\"\"Close the HTTP client and cleanup resources.\"\"\"\n        if self._client is not None:\n            await self._client.aclose()\n            self._client = None\n        logger.debug(\"GitHub import service closed\")\n\n\nasync def create_github_import_service(\n    source_config: SourceConfig,\n) -> GitHubImportService:\n    \"\"\"\n    Factory function to create a GitHubImportService from SourceConfig.\n\n    Args:\n        source_config: Generic source configuration\n\n    Returns:\n        Configured GitHubImportService\n\n    Raises:\n        ValueError: If required GitHub configuration is missing\n    \"\"\"\n    # Validate required fields for GitHub\n    if not source_config.api_token:\n        raise ValueError(\"api_token is required for GitHub import\")\n\n    if not source_config.repository:\n        raise ValueError(\"repository is required for GitHub import\")\n\n    # Build GitHub config\n    config = GitHubImportConfig(\n        api_token=source_config.api_token,\n        repository=source_config.repository,\n    )\n\n    # Apply filters if provided\n    if source_config.status_filter:\n        # Map to GitHub state (open, closed, all)\n        states = [s.lower() for s in source_config.status_filter if s.lower() in [\"open\", \"closed\"]]\n        if states:\n            config.state = states[0]\n        elif \"all\" in [s.lower() for s in source_config.status_filter]:\n            config.state = \"all\"\n\n    if source_config.label_filter:\n        config.labels = source_config.label_filter\n\n    return GitHubImportService(config)\n",
        "last_modified": "2026-01-03T19:09:00.299042"
      },
      "task_intent": {
        "title": "003-import-your-data",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2026-01-03T17:00:00.303944",
  "last_updated": "2026-01-03T17:00:00.305694"
}