# NGINX Load Balancer Configuration for ACGS-2 Horizontal Scaling
# Distributes traffic across multiple API Gateway instances for 20K+ RPS
#
# Key Features:
# - Round-robin load balancing with connection keepalive
# - Health checks for automatic failover
# - Optimized for low-latency (P99 < 1ms target)
# - Status endpoint for monitoring load distribution

worker_processes auto;
worker_rlimit_nofile 65535;

events {
    worker_connections 65535;
    use epoll;
    multi_accept on;
}

http {
    # Performance optimizations for high throughput
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    keepalive_requests 10000;
    types_hash_max_size 2048;

    # Logging optimizations (reduce I/O for performance testing)
    access_log off;
    error_log /var/log/nginx/error.log warn;

    # Buffer optimizations
    client_body_buffer_size 16k;
    client_header_buffer_size 1k;
    client_max_body_size 10m;
    large_client_header_buffers 4 8k;

    # Upstream configuration for API Gateway instances
    upstream api_gateway_cluster {
        # Round-robin load balancing (default)
        # Use least_conn for better distribution under varying load
        least_conn;

        # API Gateway instances with health monitoring
        server api-gateway-1:8080 weight=1 max_fails=3 fail_timeout=10s;
        server api-gateway-2:8080 weight=1 max_fails=3 fail_timeout=10s;

        # Connection keepalive for performance
        keepalive 256;
        keepalive_requests 10000;
        keepalive_timeout 60s;
    }

    # Rate limiting zone (optional, for protection)
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=1000r/s;

    server {
        listen 8090;
        server_name localhost;

        # Proxy settings for upstream
        location / {
            proxy_pass http://api_gateway_cluster;

            # HTTP/1.1 for keepalive support
            proxy_http_version 1.1;
            proxy_set_header Connection "";

            # Pass client information
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Instance tracking for debugging
            proxy_set_header X-Request-ID $request_id;
            add_header X-Upstream-Addr $upstream_addr always;

            # Timeouts optimized for low latency
            proxy_connect_timeout 5s;
            proxy_send_timeout 10s;
            proxy_read_timeout 30s;

            # Buffer settings
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
        }

        # Health check endpoint (direct, not proxied)
        location = /lb_health {
            access_log off;
            return 200 '{"status": "healthy", "service": "nginx-lb"}';
            add_header Content-Type application/json;
        }

        # NGINX status for monitoring
        location = /nginx_status {
            stub_status;
            access_log off;
            allow 127.0.0.1;
            allow 172.30.0.0/16;  # Docker network
            deny all;
        }

        # Upstream health status (requires nginx-module-vts or similar)
        location = /upstream_status {
            access_log off;
            return 200 '{"upstream": "api_gateway_cluster", "servers": ["api-gateway-1:8080", "api-gateway-2:8080"]}';
            add_header Content-Type application/json;
        }
    }
}
